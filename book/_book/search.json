[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contenedores al Alcance de Todos",
    "section": "",
    "text": "1 Prefacio\nEste libro te enseñará a manejar y comprender contenedores con herramientas modernas como Docker y Podman. Aprenderás desde los fundamentos hasta el despliegue de aplicaciones en entornos reales, pasando por la construcción de imágenes, gestión de redes y almacenamiento, todo a través de ejemplos prácticos y proyectos aplicados. Sin embargo, este no es un manual introductorio típico. Mi objetivo es ayudarte a convertirte en un profesional capaz de utilizar contenedores no solo para ejecutar aplicaciones, sino para integrarlos en procesos de desarrollo y despliegue ágiles.\nLos capítulos del libro están organizados en torno a tres proyectos principales, diseñados para abarcar aspectos clave de Docker y Podman. Estos proyectos no solo cubren la construcción y gestión de contenedores, sino también prácticas avanzadas como la integración con CI/CD, optimización de recursos y resolución de problemas comunes. He seleccionado estos proyectos por dos razones: primero, porque representan el rango completo de funcionalidades de estas herramientas; segundo, porque están diseñados para ayudarte a abordar los desafíos reales del desarrollo y despliegue moderno de software.\nMás allá de las características técnicas, los contenedores resuelven problemas logísticos importantes en el desarrollo. Permiten crear entornos reproducibles, escalar aplicaciones de manera eficiente y minimizar errores relacionados con dependencias o configuraciones. A través de este libro, no solo aprenderás a usar Docker y Podman, sino también a integrar estas habilidades en tu trabajo como desarrollador, maximizando tu productividad y mejorando tu flujo de trabajo.\nEste libro está dirigido a los siguientes perfiles: - Estudiantes y profesionales interesados en aprender sobre contenedores desde cero. - Desarrolladores que buscan integrar prácticas modernas de DevOps y microservicios. - Ingenieros que desean optimizar procesos de despliegue y escalabilidad en la nube.\nHe diseñado este libro para que sea accesible y práctico, centrándome en conceptos aplicados y dejando de lado teorías avanzadas que pueden ser un obstáculo al inicio. Mi objetivo es proporcionarte las herramientas y el conocimiento para que puedas enfrentarte a problemas reales en el desarrollo de software.\nAprender a manejar contenedores es una habilidad esencial para cualquier profesional en tecnología hoy en día. Es como pasar de usar un sistema tradicional, donde todo está predeterminado, a un sistema donde tienes la flexibilidad y el control total para crear lo que necesitas. Como dijo Greg Snow al referirse a otro contexto, los contenedores son como un vehículo todoterreno que te llevará a lugares donde las herramientas tradicionales no pueden llegar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#convenciones-utilizadas-en-este-libro",
    "href": "index.html#convenciones-utilizadas-en-este-libro",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.1 Convenciones Utilizadas en Este Libro",
    "text": "1.1 Convenciones Utilizadas en Este Libro\n\nCursiva: Indica términos nuevos, URLs y nombres de archivos.\nTexto de ancho fijo: Representa comandos, nombres de variables o elementos de código.\nTexto en negrita: Muestra comandos que deben ser escritos literalmente por el lector.\n\nPara realizar comentarios o preguntas técnicas sobre este libro, por favor abre un issue en github.com/tu-repositorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.2 Agradecimientos",
    "text": "1.2 Agradecimientos\nQuiero agradecer a todas las personas que me han ayudado a escribir este libro, desde mis colegas y estudiantes que han probado este contenido, hasta quienes contribuyeron con ideas y retroalimentación. También agradezco a las comunidades de Docker y Podman por proporcionar recursos invaluables y fomentar el aprendizaje continuo. Finalmente, gracias a mi familia por su apoyo incondicional durante este proceso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "prework.html",
    "href": "prework.html",
    "title": "2  First steps with Polars",
    "section": "",
    "text": "2.1 Requisitos de Docker antes de instalar.\nocker destaca por su compatibilidad entre sistemas. Las máquinas virtuales o la virtualización de hardware clásica emulan un sistema operativo invitado entero, mientras que los contenedores Docker comparten el núcleo del sistema anfitrión, ejecutándose como procesos aislados en el espacio del usuario. En sus inicios, Docker se utilizaba exclusivamente en sistemas Linux o en sistemas operativos basados en Linux. Hoy en día, el software de código abierto se caracteriza por su completa independencia de los sistemas operativos. Docker utiliza el kernel local de Linux en las variantes de 64 bits de los sistemas operativos de Linux, los sistemas que no son de Linux utilizan simplemente una imagen del sistema Linux a través de un hypervisor o una máquina virtual.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First steps with Polars</span>"
    ]
  },
  {
    "objectID": "introduccion_docker.html",
    "href": "introduccion_docker.html",
    "title": "3  Introducción a Docker",
    "section": "",
    "text": "3.0.1 Introducción\nDocker surge como una solución innovadora al problema de la virtualización tradicional, ya que en el enfoque clásico, se utilizan máquinas virtuales (VMs), las cuales requieren de un sistema operativo completo para su creación y ejecución, además de que consumen una gran cantidad de espacio y recursos, incluso si solo se necesita ejecutar una tarea específica, por lo que este enfoque en la actualidad es ineficiente y poco flexible.\nDocker se centra en solucionar este problema mediante el uso de contenedores, definidos por archivos Dockerfile. Estos archivos especifican únicamente lo necesario para que una aplicación funcione, eliminando la necesidad de instalar sistemas operativos completos, basta con tener una imagen base y las dependencias necesarias; Docker optimiza el uso del espacio y acelera en gran medida el despliegue de aplicaciones.\nUna de las principales ventajas de Docker es su portabilidad, ya que permite que las aplicaciones se ejecuten de manera consistente en diferentes sistemas operativos y entornos, como desarrollo, pruebas y producción. Esto lo convierte en una herramienta fundamental para implementar arquitecturas modernas, como los microservicios, facilitando la gestión y escalabilidad de aplicaciones complejas.\n\n\n3.0.2 ¿Qué es Docker?\nDocker es una tecnología de virtualización basada en contenedores que permite empaquetar aplicaciones junto con sus dependencias y frameworks necesarios para su ejecución, esto garantiza que las aplicaciones funcionen de manera consistente y uniforme, sin importar el entorno en el que se ejecuten, resolviendo los problemas de compatibilidad y configuración de dependencias que suelen surgir al migrar entre sistemas operativos o entornos.\n\n\n3.0.3 Componente de Docker\nDocker engine: Es el motor de Docker y se encarga de la gestión de todos los contenedores que se ejecutan en Docker.\nDocker images: Es la plantilla donde se ecuentra la aplicación, la imagen base del sistema operativo y las dependencias necesarias para la ejecución de la aplicación, estas imágenes son reutilizables y permiten crear contenedores de manera rápida y eficiente.\nDocker container: Es la ejecución de una instancia de la imagen de Docker, donde cada contenedor opera en un entorno completamente aislado, compartiendo únicamente el kernel del sistema operativo anfitrión pero manteniendo independencia en cuanto a procesos, redes y almacenamiento.\nRedes: Las redes sirven para la comunicación entre los contenedores, permitiendo que se comuniquen entre sí o con el host, por lo que existen diferentes modelos de red que son las redes de puente, las redes de host y las redes de superposición.\nVolúmenes: Los volúmenes sirven para almacenar los datos que se desea que persistan en el tiempo, es decir cuando el contenedorer termine de ejecutarse, se reinicie o se elimine, esto es ideal para manejar aplicaciones que requieren de una base de datos o almacenamiento persistente.\nDocker Hub: Es el repositorio central que utiliza Docker para que los desarrolladores puedan compartir y descargar imágenes tanto públicas como privadas, lo que facilita la colaboración y la reutilización de imágenes.\n\n\n3.0.4 Diferencias entre Docker y Máquinas Virtuales\n\n3.0.4.1 Docker\n\nLos contenedores de Docker solo comparten el núcleo del sistema operativo host.\nLos contenedores son más ligeros.\nArrancan en segundos.\nSon más portables y fáciles de gestionar.\nPresentan menos sobrecarga sobre el hardware del host.\nPermiten la ejecución de múltiples contenedores en un mismo host.\nSon ideales para aplicaciones basadas en microservicios.\n\n\n\n3.0.4.2 Máquinas Virtuales\n\nLas máquinas virtuales necesitan de la virtuaización de todo el hardware del host.\nLas máquinas virtuales ocupan gran cantidad de espacio y recursos para su creación y ejecución.\nSu arranque es lento, por lo general tardan minutos.\nSon más complejas de administrar y su portabilidad es compleja.\nPresentan mayor sobrecarga sobre el hardware del host.\nSe puede ejecutar multiples máquinas virtuales en un mismo host, pero esto requiere de más recursos.\nSon ideales para aplicaciones con una arquitectura monolítica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a Docker</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html",
    "href": "understanding_cloud_concepts.html",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "4.1 Ecosistema del Cloud Computing\nEl concepto de cloud computing está transformando la manera en que las empresas operan, permitiéndoles acceder a recursos de cómputo y almacenamiento bajo demanda, escalar sin límites y adoptar modelos de precios flexibles. Esta tecnología ha revolucionado tanto a empresas emergentes como a grandes corporaciones.\nEl ecosistema de cloud computing consta de tres principales actores:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "Consumidores de servicios: Usan aplicaciones y herramientas en la nube sin preocuparse por su ubicación o diseño.\nProveedores de servicios: Ofrecen infraestructura, aplicaciones y herramientas basadas en la nube.\nDiseñadores de servicios: Construyen herramientas o aplicaciones optimizadas para ecosistemas específicos de nube.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "4.2 Conceptos Fundamentales del Cloud Computing",
    "text": "4.2 Conceptos Fundamentales del Cloud Computing\nEl cloud computing implica la provisión de recursos compartidos como aplicaciones, almacenamiento y plataformas de desarrollo a través de estándares y automatización. Los servicios comunes incluyen:\n\nAutomatización: Procesos gestionados automáticamente para optimizar la eficiencia.\nAutoservicio: Permite a los usuarios aprovisionar recursos por sí mismos.\nElasticidad: Capacidad de ajustar automáticamente recursos según las necesidades.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-nube",
    "href": "understanding_cloud_concepts.html#modelos-de-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.3 Modelos de Nube",
    "text": "4.3 Modelos de Nube\nExisten diferentes modelos de despliegue en la nube, cada uno adaptado a distintas necesidades empresariales:\n\n4.3.1 Nube Pública\n\nDefinición: Recursos compartidos y gestionados por un proveedor externo. Los usuarios pagan por el uso bajo demanda.\nCaracterísticas:\n\nEscalabilidad masiva y elasticidad automática.\nAcceso a servicios avanzados, como análisis de datos y aprendizaje automático.\nDisponibilidad global, ideal para empresas que requieren operaciones en múltiples regiones.\n\nCasos de uso: Aplicaciones de comercio electrónico, almacenamiento masivo, pruebas y desarrollo.\n\n\n\n4.3.2 Nube Privada\n\nDefinición: Recursos dedicados y gestionados por una sola organización, ya sea internamente o a través de un proveedor externo.\nCaracterísticas:\n\nControl total sobre los recursos.\nMayor seguridad y personalización.\nCumplimiento normativo y gobernanza específica.\n\nCasos de uso: Datos sensibles, aplicaciones con requisitos legales estrictos o sistemas heredados.\n\n\n\n4.3.3 Nube Híbrida\n\nDefinición: Combina nubes públicas y privadas, permitiendo la interoperabilidad y la transferencia de datos entre ambas.\nCaracterísticas:\n\nBalanceo de cargas de trabajo entre entornos.\nFlexibilidad para mover datos según necesidades de costo, rendimiento o seguridad.\n\nCasos de uso: Migraciones graduales hacia la nube, recuperación ante desastres, análisis de datos en múltiples ubicaciones.\n\n\n\n4.3.4 Multicloud\n\nDefinición: Uso simultáneo de múltiples nubes públicas para satisfacer distintas necesidades empresariales.\nCaracterísticas:\n\nEvita la dependencia de un solo proveedor.\nFlexibilidad para aprovechar lo mejor de cada plataforma.\nGestión centralizada para controlar costos y rendimiento.\n\nCasos de uso: Desarrollo de aplicaciones en plataformas específicas o maximización de servicios según región.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-entrega",
    "href": "understanding_cloud_concepts.html#modelos-de-entrega",
    "title": "4  Comprendiendo la Nube",
    "section": "4.4 Modelos de Entrega",
    "text": "4.4 Modelos de Entrega\nLos modelos de entrega en cloud computing son fundamentales para entender cómo se ofrecen los servicios a los usuarios. Cada uno proporciona un nivel distinto de abstracción y control:\n\n4.4.1 Infraestructura como Servicio (IaaS)\n\nDefinición: Provisión de recursos básicos, como servidores virtuales, almacenamiento y redes, sobre los cuales los usuarios pueden construir sus propias aplicaciones.\nCaracterísticas:\n\nControl total sobre el sistema operativo y las aplicaciones.\nAlta flexibilidad para personalizar entornos según las necesidades.\nPago por uso, permitiendo reducir costos operativos.\n\nEjemplos de servicios: Amazon EC2, Google Compute Engine, Microsoft Azure VMs.\nCasos de uso:\n\nMigración de centros de datos físicos a la nube.\nEscenarios de desarrollo y pruebas.\nImplementación de aplicaciones personalizadas.\n\n\n\n\n4.4.2 Plataforma como Servicio (PaaS)\n\nDefinición: Provisión de una capa de abstracción que incluye herramientas de desarrollo, middleware y bases de datos, optimizada para la creación y despliegue de aplicaciones.\nCaracterísticas:\n\nEntorno preconfigurado para desarrollo rápido.\nIntegración de herramientas como frameworks y APIs.\nGestión automatizada de recursos y actualizaciones.\n\nEjemplos de servicios: Google App Engine, Microsoft Azure App Service, Heroku.\nCasos de uso:\n\nDesarrollo de aplicaciones web y móviles.\nCreación de aplicaciones en entornos colaborativos.\nEscenarios donde se busca acelerar el tiempo de desarrollo.\n\n\n\n\n4.4.3 Software como Servicio (SaaS)\n\nDefinición: Provisión de aplicaciones completas accesibles a través de internet. Los usuarios no gestionan ni la infraestructura ni las plataformas subyacentes.\nCaracterísticas:\n\nFacilidad de uso y acceso desde cualquier dispositivo.\nModelos de suscripción mensual o anual.\nAlta disponibilidad y actualizaciones automáticas.\n\nEjemplos de servicios: Google Workspace, Salesforce, Zoom.\nCasos de uso:\n\nHerramientas de colaboración y productividad.\nGestión de relaciones con clientes (CRM).\nServicios de recursos humanos y contabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "href": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.5 Ciclo de Vida de Recursos en la Nube",
    "text": "4.5 Ciclo de Vida de Recursos en la Nube\nEn contraste con los centros de datos tradicionales, la nube permite a los usuarios:\n\nAlquilar recursos bajo demanda.\nPagar únicamente por el uso real.\nLiberar recursos automáticamente cuando ya no se necesitan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "href": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "title": "4  Comprendiendo la Nube",
    "section": "4.6 Gestión de Nubes Híbridas y Multicloud",
    "text": "4.6 Gestión de Nubes Híbridas y Multicloud\nUna nube híbrida efectiva debe integrar múltiples entornos de forma automatizada y bien gestionada. Los entornos multicloud requieren visibilidad, control y capacidad para mover datos y cargas de trabajo según convenga.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "href": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "title": "4  Comprendiendo la Nube",
    "section": "4.7 Cambios en el Rol del Centro de Datos",
    "text": "4.7 Cambios en el Rol del Centro de Datos\nAunque los centros de datos no desaparecerán, la adopción de la nube les exige modernizarse. Las estrategias incluyen:\n\nVirtualización: Separar software de hardware para mejorar la eficiencia.\nNubes privadas: Crear entornos altamente automatizados con capacidades de autoservicio.\nNubes híbridas: Combinar servicios en la nube con infraestructura local.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "virtualbox and docker containers for developments.html",
    "href": "virtualbox and docker containers for developments.html",
    "title": "5  VirtualBox y Contenedores Docker para el Desarrollo",
    "section": "",
    "text": "5.0.1 Introducción\nDentro del desarrollo de software de la actualidad se requieren entornos flexibles, escalables y consistentes. La configuración manual para cada proyecto puede ser tedioso y con tendencia a errores, en especial cuando las dependencias del sistema o sus versiones de software son críticas. Para esto, existen herramientas como VirtualBox y Docker juegan un papel importante.\n\n\n5.0.2 VirtualBox:\nLa herramienta de VirtualBox nos proporciona un software de hipervisor el cual nos permite la ejecución de máquinas virtuales dentro de un sistema host o anfitrión. Cada una de estas máquinas virtuales imitan entornos completos, incluso el de los sistemas operativos, de configuraciones y de aplicaciones que se requieren para el desarrollo. Se puede usar virtualbox para realizar pruebas de software en múltiples sistemas operativos o para poner en aislamineto un entorno de desarrollo.\nGuest Additions\nDentro de los sistemas invitados como Windows y Linux, se puede instalar controladores que permitan integrar los sistemas operativos de invitado y host. Tales controladores se conocen como Guest Additions y se los puede bajar desde el sitio web de VirtualBox.\nSon instalables dentro de la máquina virtual como cualquier programa que se vaya a instalar para Windows o Linux. La integración con el host es bastante útil.\nInstalación VirtualBox\n\nDescargue VirtualBox desde el sitio web oficial.\nInstale el software utilizando el instalador proporcionado.\nInicie VirtualBox y verifique que se esté ejecutando correctamente.\n\n\n\n5.0.3 Contenedores Docker:\nLa tecnología Docker hace el uso de contenedores ligeros para poder empaquetar aplicaciones incluidas sus dependencias utilizando un solo entorno ejecutable. En contraparte con las máquinas virtuales, los contenedores tienen compartición del núcleo del sistema operativo anfitrión, permitiendoles ser más eficientes en términos de recursos. Docker ayuda a que los desarrolladores puedan crear entornos reproducibles y escalables en cuestión de segundos, haciendo fácil y fluida la colaboración y la integración continua.\nConfiguración Contenedor Docker Básico Docker nos proporciona una manera eficiente de empaquetar, enviar y poder ejecutar software. En esta parte, se analizaran los pasos básicos para crear un contenedor para el desarrollo.\n\nEscribiendo el Dockerfile:\n\nUn archivo Dockerfile específica el entorno de configuración y todos los comandos para poder tener nuestro contenedor, ejemplo:\n# Usso de ina imagen oficial de PHP\nFROM php:7.4-apache\n\n# Habilitar módulos de Apache requeridos\nRUN a2enmod userdir \\\n    && a2enmod php7.4\n\n# Copiar el archivo de configuración para Apache\nCOPY php.conf /etc/apache2/mods-available/php7.4.conf\n\n# Definir el entry point\nENTRYPOINT [\"/entrypoint.sh\"]\n\nConstruyendo el Docker Image:\n\nPara crear la imagen del contenedor se hace uso del script build.sh, ejemplo:\n#!/usr/bin/env bash\n\n# Se construye el Docker Image\n\ndocker build -t chapter2 .\n\nCorriendo el Docker Container:\n\nPara lanzar el contenedor, se hace uso del script run.sh, ejemplo:\n#!/usr/bin/env bash\n\ndocker run -d --name chapter2 chapter2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>VirtualBox y Contenedores Docker para el Desarrollo</span>"
    ]
  },
  {
    "objectID": "scaling_and_load_testing_docker_applications.html",
    "href": "scaling_and_load_testing_docker_applications.html",
    "title": "6  Escalado y Pruebas de Carga de Aplicaciones Docker",
    "section": "",
    "text": "#Autor:Pool Ochoa\nEl escalado y las pruebas de carga son esenciales para garantizar que las aplicaciones en contenedores puedan manejar el tráfico creciente de manera eficiente y continuar funcionando bajo presión. Este proceso es particularmente relevante para infraestructuras basadas en Kubernetes, donde se pueden implementar estrategias de escalado tanto manuales como automáticas.\n\n6.0.1 Escalado en Kubernetes\nKubernetes permite escalar las aplicaciones en dos niveles principales:\n1. Escalado de Pods: Incrementar o reducir el número de réplicas de una aplicación según la demanda.\n2. Escalado del Clúster: Ajustar el número de nodos disponibles en el clúster para manejar los pods adicionales cuando los recursos se limitan.\nPara automatizar el escalado, Kubernetes ofrece herramientas como:\n- Cluster Autoscaler: Escala los nodos del clúster según la carga actual.\n- Horizontal Pod Autoscaler (HPA): Ajusta el número de pods basándose en métricas como el uso de CPU.\n- Vertical Pod Autoscaler (VPA): Modifica dinámicamente las solicitudes de CPU y memoria de los pods para optimizar los recursos.\n\n\n6.0.2 Pruebas de Carga\nLas pruebas de carga evalúan cómo responde una aplicación bajo diferentes niveles de tráfico. Estas pruebas permiten identificar cuellos de botella y garantizar que los mecanismos de escalado funcionen como se espera. Herramientas como Apache Bench (ab) y k6 son comunes para realizar estas pruebas.\n\n\n6.0.3 Ejemplo 1: Escalado Horizontal de Pods\n\nConfigurar el HPA en Kubernetes con un comando como:\nkubectl autoscale deployment app-deployment --cpu-percent=50 --min=2 --max=10\nAquí, el número de pods de la aplicación se ajustará automáticamente entre 2 y 10, según el uso de CPU.\nEjecutar una prueba de carga con Apache Bench para simular tráfico:\nab -n 1000 -c 50 http://app-url/\nEsto genera 1000 solicitudes concurrentes para evaluar si los pods adicionales se crean al aumentar el uso de CPU.\n\n\n\n6.0.4 Ejemplo 2: Pruebas de Escalabilidad con k6\n\nEscribir un script de carga en JavaScript para simular usuarios concurrentes:\nimport http from 'k6/http';\n\nexport default function() {\n    http.get('http://app-url/');\n}\nEjecutar el script con 50 usuarios virtuales durante 30 segundos:\ndocker run --rm -i loadimpact/k6 run --vus 50 --duration 30s - &lt; script.js\nEsto mide el rendimiento de la aplicación y verifica si el Cluster Autoscaler añade nodos para manejar el incremento de pods.\n\nCon estas estrategias, puedes optimizar el desempeño de aplicaciones contenedorizadas y garantizar una experiencia de usuario confiable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Escalado y Pruebas de Carga de Aplicaciones Docker</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html",
    "href": "deploying_docker_compose.html",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "",
    "text": "7.1 Requisitos para su implementación.\nEl escenario de implementación práctico más simple posible de una aplicación empaquetada con Docker implica ejecutar Docker Compose en un solo host, sin embargo, tiene algunas desventajas importantes en términos de rendimiento y disponibilidad.\nPara continuar con la implementación, necesitará una computadora que ejecute un sistema operativo Linux moderno de la misma arquitectura que su sistema de desarrollo, con suficiente memoria, procesador y capacidad de almacenamiento para ejecutar su aplicación.\nDeberá tener alguno de estos sistemas operativos linux que admitan Docker:  - Red Hat\n- Ubuntu 16.04 o superior\n- Amazon Linux 2\n- Debian\no alguna distribución centrada en Docker como Container Linux o CoreOS.\nAdemás, antes de configurar el software en el host, debe asegurarse de que tenga una dirección IP estable. A veces, se las denomina direcciones IP estáticas o direcciones IP elásticas en un contexto de AWS.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "href": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.2 Implementación mediante archivos de configuración y scripts de soporte.",
    "text": "7.2 Implementación mediante archivos de configuración y scripts de soporte.\nPara implementar nuestra aplicación en un servidor de producción, utilizaremos una combinación de comandos simples y scripts de soporte que inician o actualizan el conjunto de contenedores en ejecución. Comencemos por analizar en detalle los dos archivos más importantes necesarios para la implementación: Dockerfile y docker­compose.yml.\nEste es un ejemplo de Dockerfile basado en la producción de un juego, deberás adaptar tu Dockerfile según las necesidades de tu aplicación: FROM alpine:20191114\nRUN apk update &&\napk add nodejs nodejs-npm\nRUN addgroup -S app && adduser -S -G app app\nRUN mkdir -p /app/public /app/server\nADD src/package.json* /app/\nWORKDIR /app\nRUN npm -s install\nCOPY src/public/ /app/public/\nCOPY src/server/ /app/server/\nCOPY src/.babelrc /app/\nRUN npm run compile\nUSER app\nEXPOSE 3000\nENTRYPOINT [“npm”, “start”]\n\nEste es un ejemplo de un archivo de docker-compose:\nversion: ‘3’\nservices:\nshipit-clicker-web-v2:\nbuild: .\nenvironment:\n- APP_ID=shipit-clicker-v2\n- OPENAPI_SPEC=/api/v1/spec\n- OPENAPI_ENABLE_RESPONSE_VALIDATION=false\n- PORT=3000\n- LOG_LEVEL={LOG_LEVEL:-debug}\n- REQUEST_LIMIT=100kb\n- REDIS_HOST=\\({REDIS_HOST:-redis} \\\n- REDIS_PORT=\\){REDIS_PORT:-6379}\n- SESSION_SECRET=${SESSION_SECRET:-mySecret-v2}\n\nAhora, es necesario definir una configuración de red para el contenedor principal para luego vincularlos a los demás contenedores. Un ejemplo es: ports: - {PORT:-3006}:3000\nnetworks:\n- private-redis-shipit-clicker-v2\nlinks:\n- redis\ndepends_on:\n- redis\n\nAhora bien, al ejecutar un sitio en producción, es posible que deba realizar algunas operaciones con frecuencia como reiniciarlo o actualizarlo. Para resolver esto puede agregar scripts con el objetivo de automatizar procesos, los más comunes son aquellos para reiniciar la aplicación y implementar cambios.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación",
    "href": "deploying_docker_compose.html#implementación",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.3 Implementación",
    "text": "7.3 Implementación\nPara iniciar los servicios en segundo plano, use el siguiente comando: $ docker-compose up -d\nVerifique que los servicios se están ejecutando con: $ docker-compose ps\nCompruebe si los registros del sistema muestran algún error: $ docker-compose logs\nMientras no veas una secuencia de mensajes de error en los registros, deberías poder acceder al sitio web en la dirección IP del servidor (por ejemplo, en http://192.0.2.10)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "href": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.4 Limitaciones de implementación en un solo host",
    "text": "7.4 Limitaciones de implementación en un solo host\nSi el contenedor del servidor de base de datos o el contenedor del servicio web fallan y no se pueden reiniciar automáticamente, el sitio no funcionará y será necesaria una intervención manual. La solución puede ser tan simple como conectarse por SSH y reiniciar el servidor. Pero, a veces, un solo servidor tendrá tan poca memoria que deberá reiniciarse manualmente desde una consola de nivel superior o incluso apagar y encender manualmente.\nDependiendo de su proveedor de alojamiento, el sistema operativo base con el que comience y cómo estén configurados los contenedores Docker, puede experimentar inestabilidad que sea difícil de rastrear. Tal vez su host se reinicie con frecuencia debido a que la red del proveedor detecta hardware inestable o condiciones de red inestables. Tal vez haya configurado su sistema operativo para instalar actualizaciones automáticas y aplicarlas provoque períodos de interrupciones. Tal vez la aplicación crezca en la memoria hasta que provoque una falla de algún tipo.\nSi ha alojado su aplicación en un único servidor físico o virtual, debe asegurarse de realizar copias de seguridad del sistema con regularidad, la pérdida del host podría provocar que se pierda toda la información.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html",
    "href": "sharing_containers_used_docker_hub.html",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "8.1 ¿Qué es Docker Hub?\nDocker Hub es una plataforma centralizada que permite a los desarrolladores almacenar, compartir y gestionar imágenes de contenedores. Es el repositorio oficial de Docker, donde se pueden encontrar imágenes públicas y privadas, facilitando la colaboración y la reutilización de contenedores en diferentes entornos.\nDocker Hub es un servicio basado en la nube que proporciona un registro de imágenes de Docker. Permite a los desarrolladores:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "Almacenar Imágenes: Guardar imágenes de contenedores en un lugar centralizado.\nCompartir Imágenes: Hacer que las imágenes estén disponibles para otros desarrolladores.\nAutomatizar Builds: Configurar pipelines de CI/CD para construir y desplegar imágenes automáticamente.\nGestionar Repositorios: Organizar imágenes en repositorios públicos o privados.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.2 Beneficios de Usar Docker Hub",
    "text": "8.2 Beneficios de Usar Docker Hub\n\nColaboración: Facilita el trabajo en equipo al permitir compartir imágenes de contenedores fácilmente.\nReutilización: Permite reutilizar imágenes existentes, ahorrando tiempo y esfuerzo en la configuración de entornos.\nDistribución: Facilita la distribución de aplicaciones y servicios en diferentes entornos y plataformas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.3 Pasos para Compartir Contenedores en Docker Hub",
    "text": "8.3 Pasos para Compartir Contenedores en Docker Hub\n\nCrear una Cuenta en Docker Hub: Regístrate en Docker Hub para crear una cuenta gratuita.\nIniciar Sesión desde la Línea de Comandos: Usa el comando docker login para iniciar sesión en Docker Hub desde tu terminal.\nConstruir una Imagen de Docker: Crea una imagen de Docker usando un Dockerfile y el comando docker build.\nEtiquetar la Imagen: Etiqueta la imagen con tu nombre de usuario de Docker Hub y el nombre del repositorio.\nSubir la Imagen a Docker Hub: Usa el comando docker push para subir la imagen etiquetada a Docker Hub.\nCompartir la Imagen: Comparte el enlace del repositorio de Docker Hub con otros desarrolladores para que puedan descargar y usar la imagen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "href": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.4 Ejemplo Práctico",
    "text": "8.4 Ejemplo Práctico\nA continuación, se muestra un ejemplo práctico de cómo compartir una imagen de contenedores en Docker Hub:\n\nConstruir la Imagen: sh docker build -t myapp:late  st .\nEtiquetar la Imagen: sh docker tag myapp:latest your-dockerhub-username/myapp:latest\nIniciar Sesión en Docker Hub: sh docker login\nSubir la Imagen: sh docker push your-dockerhub-username/myapp:latest\nCompartir el Enlace: Comparte el enlace https://hub.docker.com/r/your-dockerhub-username/myapp con otros desarrolladores.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "href": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.5 Consideraciones de Seguridad",
    "text": "8.5 Consideraciones de Seguridad\n\nImágenes Privadas: Si no deseas que tus imágenes sean públicas, puedes configurar repositorios privados en Docker Hub.\nAutenticación: Asegúrate de usar autenticación segura y gestionar tus credenciales de Docker Hub de manera adecuada.\nActualizaciones: Mantén tus imágenes actualizadas para incluir las últimas mejoras y parches de seguridad.\n\nAl finalizar este capítulo, tendrás las habilidades necesarias para compartir tus contenedores con otros desarrolladores y utilizar imágenes de contenedores de la comunidad, mejorando así tu flujo de trabajo y la colaboración en proyectos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html",
    "href": "advanced_docker_security.html",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "",
    "text": "9.1 Introducción\nEn este capítulo, exploraremos temas avanzados de seguridad en Docker, enfocándonos en la gestión segura de datos sensibles y etiquetado de metadatos. Los temas clave incluyen: - Almacenamiento seguro de secrets en Docker - El concepto y utilidad del registro Raft - Cómo agregar, inspeccionar y eliminar secrets - Uso efectivo de etiquetas para imágenes seguras - Implementación de etiquetas de metadatos y el archivo security.txt",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#almacenamiento-seguro-de-secrets-en-docker",
    "href": "advanced_docker_security.html#almacenamiento-seguro-de-secrets-en-docker",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "9.2 Almacenamiento Seguro de Secrets en Docker",
    "text": "9.2 Almacenamiento Seguro de Secrets en Docker\n\n9.2.1 ¿Qué son los Secrets?\nLos secrets se refieren a datos sensibles como:\n\nTokens de API\nCredenciales de bases de datos\nClaves privadas (por ejemplo, SSH, Azure, etc)\n\nAlmacenar secrets de manera segura evita que los atacantes accedan a ellos. La funcionalidad de secrets en Docker cifra estos datos y los comparte de manera segura con los contenedores en un Swarm.\n\n\n9.2.2 Registro Raft\nEl registro Raft asegura consenso y tolerancia a fallos entre los nodos de Swarm. Los secrets se almacenan de manera segura en este registro y se comparten entre nodos. Por ejemplo, un secret puede ser accedido a través del sistema de archivos temporal:\n/run/secrets/&lt;nombre_del_secret&gt;\nSe puede habilitar el bloqueo automático de Swarm para mayor seguridad con:\ndocker swarm init --autolock",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#agregar-inspeccionar-y-eliminar-secrets",
    "href": "advanced_docker_security.html#agregar-inspeccionar-y-eliminar-secrets",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "9.3 Agregar, Inspeccionar y Eliminar Secrets",
    "text": "9.3 Agregar, Inspeccionar y Eliminar Secrets\n\n9.3.1 Agregar Secrets\nCrea un secret utilizando el siguiente comando:\ndocker secret create &lt;nombre_del_secret&gt; &lt;ruta_del_archivo&gt;\nComo ejemplo de ello:\ndocker secret create my_key ./id_rsa\n\n\n9.3.2 Inspeccionar Secrets\nLista todos los secrets:\ndocker secret ls\nInspeccionar un secret especifico:\ndocker secret inspect &lt;nombre_del_secret&gt;\n\n\n9.3.3 Eliminar Secrets\nElimina un secret:\ndocker secret rm &lt;nombre_del_secret&gt;\nElimina un secreto de un servicio en ejecución:\ndocker service update --secret-rm &lt;nombre_del_secret&gt; &lt;nombre_del_servicio&gt;",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#secrets-en-acción-ejemplo",
    "href": "advanced_docker_security.html#secrets-en-acción-ejemplo",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "9.4 Secrets en Acción – Ejemplo",
    "text": "9.4 Secrets en Acción – Ejemplo\n\n9.4.1 Ejemplo de Flujo de Trabajo\n\nInicializa un Swarm:\n\ndocker swarm init\n\nCrea un secret:\n\ndocker secret create ssh_key ~/.ssh/id_rsa\n\nVerifica el secret:\n\ndocker secret ls\n\nUsa el secret en un servicio:\n\ndocker service create --name my_service \\ --secret ssh_key &lt;nombre_de_la_imagen&gt;\n\nAccede al secret dentro del contenedor:\n\ncat /run/secrets/ssh_key",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#etiquetas-de-docker-para-seguridad",
    "href": "advanced_docker_security.html#etiquetas-de-docker-para-seguridad",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "9.5 Etiquetas de Docker para Seguridad",
    "text": "9.5 Etiquetas de Docker para Seguridad\nLas etiquetas son esenciales para identificar y usar la imagen correcta de Docker. Para mejorar la seguridad se debe seguir los siguientes consejos:\n\nUsa etiquetas específicas para cada entorno (por ejemplo, 1.0.0-dev, 1.0.0-prod).\nEmplea versionado semántico.\n\nSi no tiene conocimiento sobre versionado semantico puede acceder a Información sobre versionado semántico.\nEjemplo de creación de un secret con etiquetas de versión:\ndocker secret create --label env=dev --label ver=1.0.0 ssh_key ~/.ssh/id_rsa",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#uso-de-etiquetas-para-la-aplicación-de-metadatos",
    "href": "advanced_docker_security.html#uso-de-etiquetas-para-la-aplicación-de-metadatos",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "9.6 Uso de Etiquetas para la Aplicación de Metadatos",
    "text": "9.6 Uso de Etiquetas para la Aplicación de Metadatos\nLas etiquetas anotan contenedores con metadatos para una gestión más sencilla. Agrega etiquetas en un Dockerfile:\nLABEL \"version\"=\"1.0.0\"\nLABEL \"description\"=\"Contenedor de desarrollo.\"\nLABEL \"security.txt\"=\"https://example.com/security.txt\"\nVisualizar etiquetas:\ndocker inspect &lt;id_del_contenedor&gt;",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#resumen-final",
    "href": "advanced_docker_security.html#resumen-final",
    "title": "9  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "9.7 Resumen Final",
    "text": "9.7 Resumen Final\nEn este capítulo, cubrimos:\n\nEl almacenamiento seguro y la gestión de secrets utilizando Docker Swarm.\nEl rol del registro Raft en mantener consistencia y seguridad.\nLa importancia de las etiquetas de Docker y los metadatos para la gestión eficiente y segura de imágenes.\n\nAl finalizar esta seccion deberias ser capaz de manejar los secrets de tus aplicaciones correctamente, sin embargo si deseas ampliar tu conocimiento sobre el tema tratado, se recomienda ingresar a:\n\nDocumentación de Secrets de Docker.\nVersionado Semántico.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "Using Artifacts with Azure DevOps.html",
    "href": "Using Artifacts with Azure DevOps.html",
    "title": "10  Using Artifacts with Azure DevOps",
    "section": "",
    "text": "10.1 ¿Qué son los artifacts y por qué son importantes?\nEn este capítulo se detalla el uso de artifacts en Azure DevOps para mejorar la gestión de dependencias, el intercambio de paquetes y la detección de vulnerabilidades en proyectos de desarrollo. Los artifacts son componentes esenciales que pueden facilitar la reutilización de código, ahorrar tiempo y asegurar la consistencia en los proyectos.\nEn el desarrollo de software, es común utilizar paquetes o bibliotecas de terceros para agregar funcionalidades adicionales a nuestras aplicaciones. Estos paquetes pueden ser desarrollados internamente o ser parte de la comunidad de código abierto. Azure Artifacts ofrece una solución integral para almacenar, compartir y consumir estos paquetes de forma segura y eficiente.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using Artifacts with Azure DevOps</span>"
    ]
  },
  {
    "objectID": "Using Artifacts with Azure DevOps.html#qué-son-los-artifacts-y-por-qué-son-importantes",
    "href": "Using Artifacts with Azure DevOps.html#qué-son-los-artifacts-y-por-qué-son-importantes",
    "title": "10  Using Artifacts with Azure DevOps",
    "section": "",
    "text": "10.1.1 Ventajas de usar Azure Artifacts:\n\nCentralización y organización: Permite a los equipos mantener un repositorio centralizado de todas las dependencias, reduciendo la duplicación y mejorando la visibilidad.\n\nControl de versiones: Facilita el uso de versiones específicas de paquetes para evitar incompatibilidades.\n\nSeguridad mejorada: Los permisos de acceso pueden configurarse para proteger los paquetes de modificaciones no autorizadas.\n\nSoporte para múltiples tipos de paquetes: Compatible con NuGet (.NET), npm (JavaScript), Maven (Java), Python y Universal Packages.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using Artifacts with Azure DevOps</span>"
    ]
  },
  {
    "objectID": "Using Artifacts with Azure DevOps.html#creación-de-un-feed-en-azure-artifacts",
    "href": "Using Artifacts with Azure DevOps.html#creación-de-un-feed-en-azure-artifacts",
    "title": "10  Using Artifacts with Azure DevOps",
    "section": "10.2 Creación de un feed en Azure Artifacts",
    "text": "10.2 Creación de un feed en Azure Artifacts\nUn feed es un contenedor dentro de Azure Artifacts donde se agrupan y organizan paquetes. Es el primer paso para empezar a trabajar con artifacts.\n\n10.2.1 ¿Cómo crear un feed en Azure DevOps?\n\nAcceder a Azure DevOps: Inicia sesión en Azure DevOps.\n\nSeleccionar la opción Artifacts: Desde el menú lateral, haz clic en Artifacts.\n\nCrear un nuevo feed: Haz clic en + Create Feed y configura las siguientes opciones:\n\nNombre del feed: Asigna un nombre como PartsUnlimited_Feed.\n\nVisibilidad: Decide si será un feed privado o accesible a toda la organización.\n\nUpstream sources: Desactívalo para este ejemplo.\n\n\nCrear el feed: Haz clic en Create y el feed estará listo para almacenar paquetes.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using Artifacts with Azure DevOps</span>"
    ]
  },
  {
    "objectID": "Using Artifacts with Azure DevOps.html#producción-de-un-paquete-mediante-un-pipeline-de-build",
    "href": "Using Artifacts with Azure DevOps.html#producción-de-un-paquete-mediante-un-pipeline-de-build",
    "title": "10  Using Artifacts with Azure DevOps",
    "section": "10.3 Producción de un paquete mediante un pipeline de build",
    "text": "10.3 Producción de un paquete mediante un pipeline de build\nDespués de crear el feed, el siguiente paso es crear un pipeline de build para generar un paquete NuGet y almacenarlo en el feed. Un pipeline automatiza el proceso de compilación, empaquetado y publicación del código.\n\n10.3.1 Importar el proyecto de muestra\n\nAcceder a Repos: En Azure DevOps, navega a Repos &gt; Files y selecciona Import repository.\n\nEspecificar la URL del repositorio: Introduce la URL del repositorio de GitHub para el proyecto PartsUnlimited.Models.\n\nAsignar un nombre: Por ejemplo, PartsUnlimited.Models.\n\n\n\n10.3.2 Configuración del pipeline de build\n\nCrear un nuevo pipeline: Selecciona Pipelines &gt; New pipeline.\n\nSeleccionar el repositorio: Elige PartsUnlimited.Models.\n\nConfigurar el pipeline:\n\nSelecciona la plantilla ASP.NET.\n\nAñade una tarea NuGet pack para empaquetar el proyecto.\n\nConfigura el versionado automático con Semantic Versioning (por ejemplo, 1.0.0).\n\n\nGuardar y ejecutar el pipeline: Haz clic en Save & queue para iniciar la ejecución.\n\nEl resultado será un paquete NuGet almacenado en el feed, listo para ser consumido por otros proyectos.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using Artifacts with Azure DevOps</span>"
    ]
  },
  {
    "objectID": "Using Artifacts with Azure DevOps.html#publicación-del-paquete-en-el-feed",
    "href": "Using Artifacts with Azure DevOps.html#publicación-del-paquete-en-el-feed",
    "title": "10  Using Artifacts with Azure DevOps",
    "section": "10.4 Publicación del paquete en el feed",
    "text": "10.4 Publicación del paquete en el feed\nPara que el paquete esté disponible para otros desarrolladores, es necesario publicarlo en el feed.\n\n10.4.1 Configuración de permisos en el feed\n\nAcceder a la configuración del feed: Ve a Artifacts &gt; Settings.\n\nAñadir permisos: Otorga permisos de Contributor a la identidad del pipeline para que pueda publicar el paquete.\n\n\n\n10.4.2 Añadir la tarea NuGet push al pipeline\n\nEditar el pipeline: Añade una nueva tarea NuGet push.\n\nConfigurar la tarea:\n\nRuta del paquete: Especifica $(Build.ArtifactStagingDirectory)/**/*.nupkg.\n\nFeed de destino: Selecciona PartsUnlimited_Feed.\n\n\nGuardar y ejecutar: El paquete se publicará automáticamente en el feed.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using Artifacts with Azure DevOps</span>"
    ]
  },
  {
    "objectID": "Using Artifacts with Azure DevOps.html#consumo-del-paquete-en-visual-studio",
    "href": "Using Artifacts with Azure DevOps.html#consumo-del-paquete-en-visual-studio",
    "title": "10  Using Artifacts with Azure DevOps",
    "section": "10.5 Consumo del paquete en Visual Studio",
    "text": "10.5 Consumo del paquete en Visual Studio\nAhora que el paquete está publicado, puedes utilizarlo en tus proyectos de Visual Studio.\n\n10.5.1 Pasos para consumir el paquete:\n\nCrear una aplicación de consola: En Visual Studio 2019, crea un nuevo proyecto .NET Core.\n\nConectar al feed: Ve a Artifacts &gt; Connect to feed en Azure DevOps y copia la URL del feed.\n\nConfigurar Visual Studio: En NuGet Package Manager, añade la URL del feed como una nueva fuente de paquetes.\n\nInstalar el paquete: Busca PartsUnlimited.Models e instálalo.\n\nUsar el paquete: Importa el paquete y utiliza las clases del modelo en tu código.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using Artifacts with Azure DevOps</span>"
    ]
  }
]