[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contenedores al Alcance de Todos",
    "section": "",
    "text": "1 Prefacio\nEste libro te enseñará a manejar y comprender contenedores con herramientas modernas como Docker y Podman. Aprenderás desde los fundamentos hasta el despliegue de aplicaciones en entornos reales, pasando por la construcción de imágenes, gestión de redes y almacenamiento, todo a través de ejemplos prácticos y proyectos aplicados. Sin embargo, este no es un manual introductorio típico. Mi objetivo es ayudarte a convertirte en un profesional capaz de utilizar contenedores no solo para ejecutar aplicaciones, sino para integrarlos en procesos de desarrollo y despliegue ágiles.\nLos capítulos del libro están organizados en torno a tres proyectos principales, diseñados para abarcar aspectos clave de Docker y Podman. Estos proyectos no solo cubren la construcción y gestión de contenedores, sino también prácticas avanzadas como la integración con CI/CD, optimización de recursos y resolución de problemas comunes. He seleccionado estos proyectos por dos razones: primero, porque representan el rango completo de funcionalidades de estas herramientas; segundo, porque están diseñados para ayudarte a abordar los desafíos reales del desarrollo y despliegue moderno de software.\nMás allá de las características técnicas, los contenedores resuelven problemas logísticos importantes en el desarrollo. Permiten crear entornos reproducibles, escalar aplicaciones de manera eficiente y minimizar errores relacionados con dependencias o configuraciones. A través de este libro, no solo aprenderás a usar Docker y Podman, sino también a integrar estas habilidades en tu trabajo como desarrollador, maximizando tu productividad y mejorando tu flujo de trabajo.\nEste libro está dirigido a los siguientes perfiles: - Estudiantes y profesionales interesados en aprender sobre contenedores desde cero. - Desarrolladores que buscan integrar prácticas modernas de DevOps y microservicios. - Ingenieros que desean optimizar procesos de despliegue y escalabilidad en la nube.\nHe diseñado este libro para que sea accesible y práctico, centrándome en conceptos aplicados y dejando de lado teorías avanzadas que pueden ser un obstáculo al inicio. Mi objetivo es proporcionarte las herramientas y el conocimiento para que puedas enfrentarte a problemas reales en el desarrollo de software.\nAprender a manejar contenedores es una habilidad esencial para cualquier profesional en tecnología hoy en día. Es como pasar de usar un sistema tradicional, donde todo está predeterminado, a un sistema donde tienes la flexibilidad y el control total para crear lo que necesitas. Como dijo Greg Snow al referirse a otro contexto, los contenedores son como un vehículo todoterreno que te llevará a lugares donde las herramientas tradicionales no pueden llegar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#convenciones-utilizadas-en-este-libro",
    "href": "index.html#convenciones-utilizadas-en-este-libro",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.1 Convenciones Utilizadas en Este Libro",
    "text": "1.1 Convenciones Utilizadas en Este Libro\n\nCursiva: Indica términos nuevos, URLs y nombres de archivos.\nTexto de ancho fijo: Representa comandos, nombres de variables o elementos de código.\nTexto en negrita: Muestra comandos que deben ser escritos literalmente por el lector.\n\nPara realizar comentarios o preguntas técnicas sobre este libro, por favor abre un issue en github.com/tu-repositorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.2 Agradecimientos",
    "text": "1.2 Agradecimientos\nQuiero agradecer a todas las personas que me han ayudado a escribir este libro, desde mis colegas y estudiantes que han probado este contenido, hasta quienes contribuyeron con ideas y retroalimentación. También agradezco a las comunidades de Docker y Podman por proporcionar recursos invaluables y fomentar el aprendizaje continuo. Finalmente, gracias a mi familia por su apoyo incondicional durante este proceso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "prework.html",
    "href": "prework.html",
    "title": "2  First steps with Polars",
    "section": "",
    "text": "2.1 Requisitos de Docker antes de instalar.\nocker destaca por su compatibilidad entre sistemas. Las máquinas virtuales o la virtualización de hardware clásica emulan un sistema operativo invitado entero, mientras que los contenedores Docker comparten el núcleo del sistema anfitrión, ejecutándose como procesos aislados en el espacio del usuario. En sus inicios, Docker se utilizaba exclusivamente en sistemas Linux o en sistemas operativos basados en Linux. Hoy en día, el software de código abierto se caracteriza por su completa independencia de los sistemas operativos. Docker utiliza el kernel local de Linux en las variantes de 64 bits de los sistemas operativos de Linux, los sistemas que no son de Linux utilizan simplemente una imagen del sistema Linux a través de un hypervisor o una máquina virtual.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First steps with Polars</span>"
    ]
  },
  {
    "objectID": "introduccion_docker.html",
    "href": "introduccion_docker.html",
    "title": "3  Introducción a Docker",
    "section": "",
    "text": "3.0.1 Introducción\nDocker surge como una solución innovadora al problema de la virtualización tradicional, ya que en el enfoque clásico, se utilizan máquinas virtuales (VMs), las cuales requieren de un sistema operativo completo para su creación y ejecución, además de que consumen una gran cantidad de espacio y recursos, incluso si solo se necesita ejecutar una tarea específica, por lo que este enfoque en la actualidad es ineficiente y poco flexible.\nDocker se centra en solucionar este problema mediante el uso de contenedores, definidos por archivos Dockerfile. Estos archivos especifican únicamente lo necesario para que una aplicación funcione, eliminando la necesidad de instalar sistemas operativos completos, basta con tener una imagen base y las dependencias necesarias; Docker optimiza el uso del espacio y acelera en gran medida el despliegue de aplicaciones.\nUna de las principales ventajas de Docker es su portabilidad, ya que permite que las aplicaciones se ejecuten de manera consistente en diferentes sistemas operativos y entornos, como desarrollo, pruebas y producción. Esto lo convierte en una herramienta fundamental para implementar arquitecturas modernas, como los microservicios, facilitando la gestión y escalabilidad de aplicaciones complejas.\n\n\n3.0.2 ¿Qué es Docker?\nDocker es una tecnología de virtualización basada en contenedores que permite empaquetar aplicaciones junto con sus dependencias y frameworks necesarios para su ejecución, esto garantiza que las aplicaciones funcionen de manera consistente y uniforme, sin importar el entorno en el que se ejecuten, resolviendo los problemas de compatibilidad y configuración de dependencias que suelen surgir al migrar entre sistemas operativos o entornos.\n\n\n3.0.3 Componente de Docker\nDocker engine: Es el motor de Docker y se encarga de la gestión de todos los contenedores que se ejecutan en Docker.\nDocker images: Es la plantilla donde se ecuentra la aplicación, la imagen base del sistema operativo y las dependencias necesarias para la ejecución de la aplicación, estas imágenes son reutilizables y permiten crear contenedores de manera rápida y eficiente.\nDocker container: Es la ejecución de una instancia de la imagen de Docker, donde cada contenedor opera en un entorno completamente aislado, compartiendo únicamente el kernel del sistema operativo anfitrión pero manteniendo independencia en cuanto a procesos, redes y almacenamiento.\nRedes: Las redes sirven para la comunicación entre los contenedores, permitiendo que se comuniquen entre sí o con el host, por lo que existen diferentes modelos de red que son las redes de puente, las redes de host y las redes de superposición.\nVolúmenes: Los volúmenes sirven para almacenar los datos que se desea que persistan en el tiempo, es decir cuando el contenedorer termine de ejecutarse, se reinicie o se elimine, esto es ideal para manejar aplicaciones que requieren de una base de datos o almacenamiento persistente.\nDocker Hub: Es el repositorio central que utiliza Docker para que los desarrolladores puedan compartir y descargar imágenes tanto públicas como privadas, lo que facilita la colaboración y la reutilización de imágenes.\n\n\n3.0.4 Diferencias entre Docker y Máquinas Virtuales\n\n3.0.4.1 Docker\n\nLos contenedores de Docker solo comparten el núcleo del sistema operativo host.\nLos contenedores son más ligeros.\nArrancan en segundos.\nSon más portables y fáciles de gestionar.\nPresentan menos sobrecarga sobre el hardware del host.\nPermiten la ejecución de múltiples contenedores en un mismo host.\nSon ideales para aplicaciones basadas en microservicios.\n\n\n\n3.0.4.2 Máquinas Virtuales\n\nLas máquinas virtuales necesitan de la virtuaización de todo el hardware del host.\nLas máquinas virtuales ocupan gran cantidad de espacio y recursos para su creación y ejecución.\nSu arranque es lento, por lo general tardan minutos.\nSon más complejas de administrar y su portabilidad es compleja.\nPresentan mayor sobrecarga sobre el hardware del host.\nSe puede ejecutar multiples máquinas virtuales en un mismo host, pero esto requiere de más recursos.\nSon ideales para aplicaciones con una arquitectura monolítica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a Docker</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html",
    "href": "understanding_cloud_concepts.html",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "4.1 Ecosistema del Cloud Computing\nEl concepto de cloud computing está transformando la manera en que las empresas operan, permitiéndoles acceder a recursos de cómputo y almacenamiento bajo demanda, escalar sin límites y adoptar modelos de precios flexibles. Esta tecnología ha revolucionado tanto a empresas emergentes como a grandes corporaciones.\nEl ecosistema de cloud computing consta de tres principales actores:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "Consumidores de servicios: Usan aplicaciones y herramientas en la nube sin preocuparse por su ubicación o diseño.\nProveedores de servicios: Ofrecen infraestructura, aplicaciones y herramientas basadas en la nube.\nDiseñadores de servicios: Construyen herramientas o aplicaciones optimizadas para ecosistemas específicos de nube.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "4.2 Conceptos Fundamentales del Cloud Computing",
    "text": "4.2 Conceptos Fundamentales del Cloud Computing\nEl cloud computing implica la provisión de recursos compartidos como aplicaciones, almacenamiento y plataformas de desarrollo a través de estándares y automatización. Los servicios comunes incluyen:\n\nAutomatización: Procesos gestionados automáticamente para optimizar la eficiencia.\nAutoservicio: Permite a los usuarios aprovisionar recursos por sí mismos.\nElasticidad: Capacidad de ajustar automáticamente recursos según las necesidades.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-nube",
    "href": "understanding_cloud_concepts.html#modelos-de-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.3 Modelos de Nube",
    "text": "4.3 Modelos de Nube\nExisten diferentes modelos de despliegue en la nube, cada uno adaptado a distintas necesidades empresariales:\n\n4.3.1 Nube Pública\n\nDefinición: Recursos compartidos y gestionados por un proveedor externo. Los usuarios pagan por el uso bajo demanda.\nCaracterísticas:\n\nEscalabilidad masiva y elasticidad automática.\nAcceso a servicios avanzados, como análisis de datos y aprendizaje automático.\nDisponibilidad global, ideal para empresas que requieren operaciones en múltiples regiones.\n\nCasos de uso: Aplicaciones de comercio electrónico, almacenamiento masivo, pruebas y desarrollo.\n\n\n\n4.3.2 Nube Privada\n\nDefinición: Recursos dedicados y gestionados por una sola organización, ya sea internamente o a través de un proveedor externo.\nCaracterísticas:\n\nControl total sobre los recursos.\nMayor seguridad y personalización.\nCumplimiento normativo y gobernanza específica.\n\nCasos de uso: Datos sensibles, aplicaciones con requisitos legales estrictos o sistemas heredados.\n\n\n\n4.3.3 Nube Híbrida\n\nDefinición: Combina nubes públicas y privadas, permitiendo la interoperabilidad y la transferencia de datos entre ambas.\nCaracterísticas:\n\nBalanceo de cargas de trabajo entre entornos.\nFlexibilidad para mover datos según necesidades de costo, rendimiento o seguridad.\n\nCasos de uso: Migraciones graduales hacia la nube, recuperación ante desastres, análisis de datos en múltiples ubicaciones.\n\n\n\n4.3.4 Multicloud\n\nDefinición: Uso simultáneo de múltiples nubes públicas para satisfacer distintas necesidades empresariales.\nCaracterísticas:\n\nEvita la dependencia de un solo proveedor.\nFlexibilidad para aprovechar lo mejor de cada plataforma.\nGestión centralizada para controlar costos y rendimiento.\n\nCasos de uso: Desarrollo de aplicaciones en plataformas específicas o maximización de servicios según región.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-entrega",
    "href": "understanding_cloud_concepts.html#modelos-de-entrega",
    "title": "4  Comprendiendo la Nube",
    "section": "4.4 Modelos de Entrega",
    "text": "4.4 Modelos de Entrega\nLos modelos de entrega en cloud computing son fundamentales para entender cómo se ofrecen los servicios a los usuarios. Cada uno proporciona un nivel distinto de abstracción y control:\n\n4.4.1 Infraestructura como Servicio (IaaS)\n\nDefinición: Provisión de recursos básicos, como servidores virtuales, almacenamiento y redes, sobre los cuales los usuarios pueden construir sus propias aplicaciones.\nCaracterísticas:\n\nControl total sobre el sistema operativo y las aplicaciones.\nAlta flexibilidad para personalizar entornos según las necesidades.\nPago por uso, permitiendo reducir costos operativos.\n\nEjemplos de servicios: Amazon EC2, Google Compute Engine, Microsoft Azure VMs.\nCasos de uso:\n\nMigración de centros de datos físicos a la nube.\nEscenarios de desarrollo y pruebas.\nImplementación de aplicaciones personalizadas.\n\n\n\n\n4.4.2 Plataforma como Servicio (PaaS)\n\nDefinición: Provisión de una capa de abstracción que incluye herramientas de desarrollo, middleware y bases de datos, optimizada para la creación y despliegue de aplicaciones.\nCaracterísticas:\n\nEntorno preconfigurado para desarrollo rápido.\nIntegración de herramientas como frameworks y APIs.\nGestión automatizada de recursos y actualizaciones.\n\nEjemplos de servicios: Google App Engine, Microsoft Azure App Service, Heroku.\nCasos de uso:\n\nDesarrollo de aplicaciones web y móviles.\nCreación de aplicaciones en entornos colaborativos.\nEscenarios donde se busca acelerar el tiempo de desarrollo.\n\n\n\n\n4.4.3 Software como Servicio (SaaS)\n\nDefinición: Provisión de aplicaciones completas accesibles a través de internet. Los usuarios no gestionan ni la infraestructura ni las plataformas subyacentes.\nCaracterísticas:\n\nFacilidad de uso y acceso desde cualquier dispositivo.\nModelos de suscripción mensual o anual.\nAlta disponibilidad y actualizaciones automáticas.\n\nEjemplos de servicios: Google Workspace, Salesforce, Zoom.\nCasos de uso:\n\nHerramientas de colaboración y productividad.\nGestión de relaciones con clientes (CRM).\nServicios de recursos humanos y contabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "href": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.5 Ciclo de Vida de Recursos en la Nube",
    "text": "4.5 Ciclo de Vida de Recursos en la Nube\nEn contraste con los centros de datos tradicionales, la nube permite a los usuarios:\n\nAlquilar recursos bajo demanda.\nPagar únicamente por el uso real.\nLiberar recursos automáticamente cuando ya no se necesitan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "href": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "title": "4  Comprendiendo la Nube",
    "section": "4.6 Gestión de Nubes Híbridas y Multicloud",
    "text": "4.6 Gestión de Nubes Híbridas y Multicloud\nUna nube híbrida efectiva debe integrar múltiples entornos de forma automatizada y bien gestionada. Los entornos multicloud requieren visibilidad, control y capacidad para mover datos y cargas de trabajo según convenga.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "href": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "title": "4  Comprendiendo la Nube",
    "section": "4.7 Cambios en el Rol del Centro de Datos",
    "text": "4.7 Cambios en el Rol del Centro de Datos\nAunque los centros de datos no desaparecerán, la adopción de la nube les exige modernizarse. Las estrategias incluyen:\n\nVirtualización: Separar software de hardware para mejorar la eficiencia.\nNubes privadas: Crear entornos altamente automatizados con capacidades de autoservicio.\nNubes híbridas: Combinar servicios en la nube con infraestructura local.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "virtualbox and docker containers for developments.html",
    "href": "virtualbox and docker containers for developments.html",
    "title": "5  VirtualBox y Contenedores Docker para el Desarrollo",
    "section": "",
    "text": "5.0.1 Introducción\nDentro del desarrollo de software de la actualidad se requieren entornos flexibles, escalables y consistentes. La configuración manual para cada proyecto puede ser tedioso y con tendencia a errores, en especial cuando las dependencias del sistema o sus versiones de software son críticas. Para esto, existen herramientas como VirtualBox y Docker juegan un papel importante.\n\n\n5.0.2 VirtualBox:\nLa herramienta de VirtualBox nos proporciona un software de hipervisor el cual nos permite la ejecución de máquinas virtuales dentro de un sistema host o anfitrión. Cada una de estas máquinas virtuales imitan entornos completos, incluso el de los sistemas operativos, de configuraciones y de aplicaciones que se requieren para el desarrollo. Se puede usar virtualbox para realizar pruebas de software en múltiples sistemas operativos o para poner en aislamineto un entorno de desarrollo.\nGuest Additions\nDentro de los sistemas invitados como Windows y Linux, se puede instalar controladores que permitan integrar los sistemas operativos de invitado y host. Tales controladores se conocen como Guest Additions y se los puede bajar desde el sitio web de VirtualBox.\nSon instalables dentro de la máquina virtual como cualquier programa que se vaya a instalar para Windows o Linux. La integración con el host es bastante útil.\nInstalación VirtualBox\n\nDescargue VirtualBox desde el sitio web oficial.\nInstale el software utilizando el instalador proporcionado.\nInicie VirtualBox y verifique que se esté ejecutando correctamente.\n\n\n\n5.0.3 Contenedores Docker:\nLa tecnología Docker hace el uso de contenedores ligeros para poder empaquetar aplicaciones incluidas sus dependencias utilizando un solo entorno ejecutable. En contraparte con las máquinas virtuales, los contenedores tienen compartición del núcleo del sistema operativo anfitrión, permitiendoles ser más eficientes en términos de recursos. Docker ayuda a que los desarrolladores puedan crear entornos reproducibles y escalables en cuestión de segundos, haciendo fácil y fluida la colaboración y la integración continua.\nConfiguración Contenedor Docker Básico Docker nos proporciona una manera eficiente de empaquetar, enviar y poder ejecutar software. En esta parte, se analizaran los pasos básicos para crear un contenedor para el desarrollo.\n\nEscribiendo el Dockerfile:\n\nUn archivo Dockerfile específica el entorno de configuración y todos los comandos para poder tener nuestro contenedor, ejemplo:\n# Usso de ina imagen oficial de PHP\nFROM php:7.4-apache\n\n# Habilitar módulos de Apache requeridos\nRUN a2enmod userdir \\\n    && a2enmod php7.4\n\n# Copiar el archivo de configuración para Apache\nCOPY php.conf /etc/apache2/mods-available/php7.4.conf\n\n# Definir el entry point\nENTRYPOINT [\"/entrypoint.sh\"]\n\nConstruyendo el Docker Image:\n\nPara crear la imagen del contenedor se hace uso del script build.sh, ejemplo:\n#!/usr/bin/env bash\n\n# Se construye el Docker Image\n\ndocker build -t chapter2 .\n\nCorriendo el Docker Container:\n\nPara lanzar el contenedor, se hace uso del script run.sh, ejemplo:\n#!/usr/bin/env bash\n\ndocker run -d --name chapter2 chapter2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>VirtualBox y Contenedores Docker para el Desarrollo</span>"
    ]
  },
  {
    "objectID": "scaling_and_load_testing_docker_applications.html",
    "href": "scaling_and_load_testing_docker_applications.html",
    "title": "6  Escalado y Pruebas de Carga de Aplicaciones Docker",
    "section": "",
    "text": "#Autor:Pool Ochoa\nEl escalado y las pruebas de carga son esenciales para garantizar que las aplicaciones en contenedores puedan manejar el tráfico creciente de manera eficiente y continuar funcionando bajo presión. Este proceso es particularmente relevante para infraestructuras basadas en Kubernetes, donde se pueden implementar estrategias de escalado tanto manuales como automáticas.\n\n6.0.1 Escalado en Kubernetes\nKubernetes permite escalar las aplicaciones en dos niveles principales:\n1. Escalado de Pods: Incrementar o reducir el número de réplicas de una aplicación según la demanda.\n2. Escalado del Clúster: Ajustar el número de nodos disponibles en el clúster para manejar los pods adicionales cuando los recursos se limitan.\nPara automatizar el escalado, Kubernetes ofrece herramientas como:\n- Cluster Autoscaler: Escala los nodos del clúster según la carga actual.\n- Horizontal Pod Autoscaler (HPA): Ajusta el número de pods basándose en métricas como el uso de CPU.\n- Vertical Pod Autoscaler (VPA): Modifica dinámicamente las solicitudes de CPU y memoria de los pods para optimizar los recursos.\n\n\n6.0.2 Pruebas de Carga\nLas pruebas de carga evalúan cómo responde una aplicación bajo diferentes niveles de tráfico. Estas pruebas permiten identificar cuellos de botella y garantizar que los mecanismos de escalado funcionen como se espera. Herramientas como Apache Bench (ab) y k6 son comunes para realizar estas pruebas.\n\n\n6.0.3 Ejemplo 1: Escalado Horizontal de Pods\n\nConfigurar el HPA en Kubernetes con un comando como:\nkubectl autoscale deployment app-deployment --cpu-percent=50 --min=2 --max=10\nAquí, el número de pods de la aplicación se ajustará automáticamente entre 2 y 10, según el uso de CPU.\nEjecutar una prueba de carga con Apache Bench para simular tráfico:\nab -n 1000 -c 50 http://app-url/\nEsto genera 1000 solicitudes concurrentes para evaluar si los pods adicionales se crean al aumentar el uso de CPU.\n\n\n\n6.0.4 Ejemplo 2: Pruebas de Escalabilidad con k6\n\nEscribir un script de carga en JavaScript para simular usuarios concurrentes:\nimport http from 'k6/http';\n\nexport default function() {\n    http.get('http://app-url/');\n}\nEjecutar el script con 50 usuarios virtuales durante 30 segundos:\ndocker run --rm -i loadimpact/k6 run --vus 50 --duration 30s - &lt; script.js\nEsto mide el rendimiento de la aplicación y verifica si el Cluster Autoscaler añade nodos para manejar el incremento de pods.\n\nCon estas estrategias, puedes optimizar el desempeño de aplicaciones contenedorizadas y garantizar una experiencia de usuario confiable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Escalado y Pruebas de Carga de Aplicaciones Docker</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html",
    "href": "deploying_docker_compose.html",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "",
    "text": "7.1 Requisitos para su implementación.\nEl escenario de implementación práctico más simple posible de una aplicación empaquetada con Docker implica ejecutar Docker Compose en un solo host, sin embargo, tiene algunas desventajas importantes en términos de rendimiento y disponibilidad.\nPara continuar con la implementación, necesitará una computadora que ejecute un sistema operativo Linux moderno de la misma arquitectura que su sistema de desarrollo, con suficiente memoria, procesador y capacidad de almacenamiento para ejecutar su aplicación.\nDeberá tener alguno de estos sistemas operativos linux que admitan Docker:  - Red Hat\n- Ubuntu 16.04 o superior\n- Amazon Linux 2\n- Debian\no alguna distribución centrada en Docker como Container Linux o CoreOS.\nAdemás, antes de configurar el software en el host, debe asegurarse de que tenga una dirección IP estable. A veces, se las denomina direcciones IP estáticas o direcciones IP elásticas en un contexto de AWS.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "href": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.2 Implementación mediante archivos de configuración y scripts de soporte.",
    "text": "7.2 Implementación mediante archivos de configuración y scripts de soporte.\nPara implementar nuestra aplicación en un servidor de producción, utilizaremos una combinación de comandos simples y scripts de soporte que inician o actualizan el conjunto de contenedores en ejecución. Comencemos por analizar en detalle los dos archivos más importantes necesarios para la implementación: Dockerfile y docker­compose.yml.\nEste es un ejemplo de Dockerfile basado en la producción de un juego, deberás adaptar tu Dockerfile según las necesidades de tu aplicación: FROM alpine:20191114\nRUN apk update &&\napk add nodejs nodejs-npm\nRUN addgroup -S app && adduser -S -G app app\nRUN mkdir -p /app/public /app/server\nADD src/package.json* /app/\nWORKDIR /app\nRUN npm -s install\nCOPY src/public/ /app/public/\nCOPY src/server/ /app/server/\nCOPY src/.babelrc /app/\nRUN npm run compile\nUSER app\nEXPOSE 3000\nENTRYPOINT [“npm”, “start”]\n\nEste es un ejemplo de un archivo de docker-compose:\nversion: ‘3’\nservices:\nshipit-clicker-web-v2:\nbuild: .\nenvironment:\n- APP_ID=shipit-clicker-v2\n- OPENAPI_SPEC=/api/v1/spec\n- OPENAPI_ENABLE_RESPONSE_VALIDATION=false\n- PORT=3000\n- LOG_LEVEL={LOG_LEVEL:-debug}\n- REQUEST_LIMIT=100kb\n- REDIS_HOST=\\({REDIS_HOST:-redis} \\\n- REDIS_PORT=\\){REDIS_PORT:-6379}\n- SESSION_SECRET=${SESSION_SECRET:-mySecret-v2}\n\nAhora, es necesario definir una configuración de red para el contenedor principal para luego vincularlos a los demás contenedores. Un ejemplo es: ports: - {PORT:-3006}:3000\nnetworks:\n- private-redis-shipit-clicker-v2\nlinks:\n- redis\ndepends_on:\n- redis\n\nAhora bien, al ejecutar un sitio en producción, es posible que deba realizar algunas operaciones con frecuencia como reiniciarlo o actualizarlo. Para resolver esto puede agregar scripts con el objetivo de automatizar procesos, los más comunes son aquellos para reiniciar la aplicación y implementar cambios.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación",
    "href": "deploying_docker_compose.html#implementación",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.3 Implementación",
    "text": "7.3 Implementación\nPara iniciar los servicios en segundo plano, use el siguiente comando: $ docker-compose up -d\nVerifique que los servicios se están ejecutando con: $ docker-compose ps\nCompruebe si los registros del sistema muestran algún error: $ docker-compose logs\nMientras no veas una secuencia de mensajes de error en los registros, deberías poder acceder al sitio web en la dirección IP del servidor (por ejemplo, en http://192.0.2.10)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "href": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.4 Limitaciones de implementación en un solo host",
    "text": "7.4 Limitaciones de implementación en un solo host\nSi el contenedor del servidor de base de datos o el contenedor del servicio web fallan y no se pueden reiniciar automáticamente, el sitio no funcionará y será necesaria una intervención manual. La solución puede ser tan simple como conectarse por SSH y reiniciar el servidor. Pero, a veces, un solo servidor tendrá tan poca memoria que deberá reiniciarse manualmente desde una consola de nivel superior o incluso apagar y encender manualmente.\nDependiendo de su proveedor de alojamiento, el sistema operativo base con el que comience y cómo estén configurados los contenedores Docker, puede experimentar inestabilidad que sea difícil de rastrear. Tal vez su host se reinicie con frecuencia debido a que la red del proveedor detecta hardware inestable o condiciones de red inestables. Tal vez haya configurado su sistema operativo para instalar actualizaciones automáticas y aplicarlas provoque períodos de interrupciones. Tal vez la aplicación crezca en la memoria hasta que provoque una falla de algún tipo.\nSi ha alojado su aplicación en un único servidor físico o virtual, debe asegurarse de realizar copias de seguridad del sistema con regularidad, la pérdida del host podría provocar que se pierda toda la información.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html",
    "href": "sharing_containers_used_docker_hub.html",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "8.1 ¿Qué es Docker Hub?\nDocker Hub es una plataforma centralizada que permite a los desarrolladores almacenar, compartir y gestionar imágenes de contenedores. Es el repositorio oficial de Docker, donde se pueden encontrar imágenes públicas y privadas, facilitando la colaboración y la reutilización de contenedores en diferentes entornos.\nDocker Hub es un servicio basado en la nube que proporciona un registro de imágenes de Docker. Permite a los desarrolladores:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "Almacenar Imágenes: Guardar imágenes de contenedores en un lugar centralizado.\nCompartir Imágenes: Hacer que las imágenes estén disponibles para otros desarrolladores.\nAutomatizar Builds: Configurar pipelines de CI/CD para construir y desplegar imágenes automáticamente.\nGestionar Repositorios: Organizar imágenes en repositorios públicos o privados.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.2 Beneficios de Usar Docker Hub",
    "text": "8.2 Beneficios de Usar Docker Hub\n\nColaboración: Facilita el trabajo en equipo al permitir compartir imágenes de contenedores fácilmente.\nReutilización: Permite reutilizar imágenes existentes, ahorrando tiempo y esfuerzo en la configuración de entornos.\nDistribución: Facilita la distribución de aplicaciones y servicios en diferentes entornos y plataformas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.3 Pasos para Compartir Contenedores en Docker Hub",
    "text": "8.3 Pasos para Compartir Contenedores en Docker Hub\n\nCrear una Cuenta en Docker Hub: Regístrate en Docker Hub para crear una cuenta gratuita.\nIniciar Sesión desde la Línea de Comandos: Usa el comando docker login para iniciar sesión en Docker Hub desde tu terminal.\nConstruir una Imagen de Docker: Crea una imagen de Docker usando un Dockerfile y el comando docker build.\nEtiquetar la Imagen: Etiqueta la imagen con tu nombre de usuario de Docker Hub y el nombre del repositorio.\nSubir la Imagen a Docker Hub: Usa el comando docker push para subir la imagen etiquetada a Docker Hub.\nCompartir la Imagen: Comparte el enlace del repositorio de Docker Hub con otros desarrolladores para que puedan descargar y usar la imagen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "href": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.4 Ejemplo Práctico",
    "text": "8.4 Ejemplo Práctico\nA continuación, se muestra un ejemplo práctico de cómo compartir una imagen de contenedores en Docker Hub:\n\nConstruir la Imagen: sh docker build -t myapp:late  st .\nEtiquetar la Imagen: sh docker tag myapp:latest your-dockerhub-username/myapp:latest\nIniciar Sesión en Docker Hub: sh docker login\nSubir la Imagen: sh docker push your-dockerhub-username/myapp:latest\nCompartir el Enlace: Comparte el enlace https://hub.docker.com/r/your-dockerhub-username/myapp con otros desarrolladores.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "href": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.5 Consideraciones de Seguridad",
    "text": "8.5 Consideraciones de Seguridad\n\nImágenes Privadas: Si no deseas que tus imágenes sean públicas, puedes configurar repositorios privados en Docker Hub.\nAutenticación: Asegúrate de usar autenticación segura y gestionar tus credenciales de Docker Hub de manera adecuada.\nActualizaciones: Mantén tus imágenes actualizadas para incluir las últimas mejoras y parches de seguridad.\n\nAl finalizar este capítulo, tendrás las habilidades necesarias para compartir tus contenedores con otros desarrolladores y utilizar imágenes de contenedores de la comunidad, mejorando así tu flujo de trabajo y la colaboración en proyectos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "",
    "text": "9.1 Registro de Docker y registro de tiempo de ejecución de contenedores\nPara entender el comportamiento de una aplicación en producción, los desarrolladores y operadores confían en herramientas de registro, monitoreo y alertas, las cuales permiten identificar si el sistema funciona correctamente y facilitan la solución de problemas cuando surgen inconvenientes. Con la creciente complejidad de los sistemas, aumenta la necesidad de una observabilidad más profunda sin alterar el código, en este apartado se vera el cómo instrumentar aplicaciones y entornos para mejorar la observabilidad, incluyendo el uso de Kubernetes, CloudWatch, S3, Prometheus y Grafana para gestionar registros, métricas y alertas, así como explorar datos específicos de código y base de datos con Jaeger.\nCada contenedor Docker, ya sea que se ejecute localmente o en la nube, produce sus propios registros los cuales se puede consultar. en el caso de Kubernetes cada contenedor Docker en un pod genera registros, que el sistema almacena temporalmente hasta 10 MB por contenedor, estos registros se pueden consultar con la herramienta kubectl logs, pero son eliminados cuando un pod se elimina o un contenedor se reinicia, lo que impide su retención permanente, esto puede dificultar la solución de problemas si los registros necesarios ya no están disponibles. Por ello, es importante considerar soluciones que superen estas limitaciones y mejoren la gestión y retención de registros.\nUn sistema de gestión de registros ideal debe incluir características como la visualización centralizada de mensajes, baja latencia para acceder a eventos recientes, recopilación de registros de diversas fuentes (pods, nodos, despliegues y contenedores Docker en Kubernetes), una interfaz de búsqueda intuitiva con opciones para guardar consultas, visualización de histogramas interactivos para explorar datos, alertas basadas en el contenido de los registros y la posibilidad de configurar el tiempo de retención de los mensajes.\nAlgunos de los sistemas de gestion de registros de terceros, son:\nEn cuanto a proveedores en la nube, existen:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-actividad-preparación-y-puesta-en-marcha-en-kubernetes",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-actividad-preparación-y-puesta-en-marcha-en-kubernetes",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "9.2 Uso de las sondas de actividad, preparación y puesta en marcha en Kubernetes",
    "text": "9.2 Uso de las sondas de actividad, preparación y puesta en marcha en Kubernetes",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#recopilación-de-métricas-y-envío-de-alertas-con-prometheus",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#recopilación-de-métricas-y-envío-de-alertas-con-prometheus",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "9.3 Recopilación de métricas y envío de alertas con Prometheus",
    "text": "9.3 Recopilación de métricas y envío de alertas con Prometheus\nPrometheus es una herramienta clave en Kubernetes para recopilar y analizar métricas del sistema. Recoge datos sobre el uso de CPU, almacenamiento y estado de las aplicaciones, entre otros, a través de endpoints como /metrics. Funciona consultando estos puntos y almacenando la información con etiquetas y marcas de tiempo para facilitar su búsqueda, también permite crear alertas y visualizar el rendimiento, ayudando a los operadores a monitorear y mejorar la salud del sistema. Si bien Prometheus puede representar gráficamente los resultados de las consultas por sí solo, los usuarios de Kubernetes suelen utilizar Grafana en conjunto con Prometheus para proporcionar gráficos más sofisticados y tableros de instrumentos.\n\n9.3.1 Recopilación de métricas\n\nModelo de recolección (Pull): Prometheus utiliza un modelo de “pull” para obtener datos, es decir, periódicamente consulta endpoints HTTP expuestos por las aplicaciones y servicios para recopilar métricas. Endpoint estándar: Generalmente, las métricas están disponibles en el endpoint /metrics.\nDatos recopilados: Incluyen el uso de CPU, memoria, almacenamiento, estado de las aplicaciones, entre otros.\nInstrumentación de aplicaciones Las aplicaciones se instrumentan para exponer sus métricas, esto se logra utilizando bibliotecas específicas de Prometheus disponibles para varios lenguajes de programación como Python, Java, entre otros.\nIntegración con Kubernetes: En un clúster de Kubernetes: Anotaciones: Recursos como pods y DaemonSets usan anotaciones para indicar a Prometheus qué endpoints consultar.\nNode Exporter: Un DaemonSet llamado node_exporter se ejecuta en cada nodo para exponer métricas específicas del sistema, como el uso del disco o la carga del CPU.\nEtiquetas y almacenamiento: Prometheus asocia cada métrica con: Un nombre descriptivo. Etiquetas en formato clave-valor Una marca de tiempo precisa a nivel de milisegundos.\n\nEstas características permiten almacenar métricas de manera eficiente y realizar consultas rápidas en su base de datos de series temporales.\n\n\n9.3.2 Envío de alertas\n\nAdministrador de alertas: Prometheus incluye Alertmanager, un componente que gestiona las alertas generadas a partir de las reglas definidas en Prometheus.\nReglas de alerta: Se configuran en archivos YAML y definen condiciones específicas para generar alertas.\nCanales de notificación: Alertmanager puede enviar alertas a múltiples canales, como correo electrónico, Slack, Microsoft Teams o PagerDuty.\nFlujo de trabajo de alertas Prometheus evalúa las métricas recolectadas en tiempo real según las reglas definidas, cuando una condición se cumple, Prometheus envía la alerta a Alertmanager, el cual agrupa, silencia o enruta las alertas a los destinatarios según las configuraciones definidas.\nVisualización de métricas para prevenir alertas: Herramientas como Grafana suelen integrarse con Prometheus para proporcionar dashboards interactivos, estos permiten monitorear tendencias y detectar posibles problemas antes de que se generen alertas.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#visualización-de-datos-operativos-con-grafana",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#visualización-de-datos-operativos-con-grafana",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "9.4 Visualización de datos operativos con Grafana",
    "text": "9.4 Visualización de datos operativos con Grafana\nGrafana se instala y está disponible a través de un LoadBalancer en Kubernetes, que en EKS utiliza un Elastic Load Balancer de AWS. Una vez que se ingresa a la consola de Grafana, se puede explorar los paneles y consultar datos con Prometheus, aunque algunos paneles, como el de “Kubernetes All nodes”, podrían no mostrar toda la información, para solucionar eso se puede agregar paneles de la comunidad con estadísticas más completas, para ello es necesario revisar el panel de “Kubernetes pods”, aqui se puede ajustae el rango de tiempo para observar datos de un día o una semana, además, se puede hacer zoom en áreas específicas para analizar detalles.\nGrafana ofrece una variedad de paneles tanto oficiales como de la comunidad en su sitio web, para añadir uno, se puede usar la opción “Importar” e ingresar un ID de panel o una URL. Algunos paneles recomendados son:\n\nCluster Monitoring para Kubernetes : Muestra el consumo de CPU, memoria y recursos de red por los pods.\nKubernetes Cluster (Prometheus) : Presenta métricas críticas del clúster.\n1 Node Exporter for Prometheus Dashboard ES : Proporciona métricas detalladas de CPU, disco y red del clúster.\nNode Exporter Full : Muestra todas las métricas posibles de Prometheus.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#monitoreo-del-rendimiento-de-aplicaciones-con-jaeger",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#monitoreo-del-rendimiento-de-aplicaciones-con-jaeger",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "9.5 Monitoreo del rendimiento de aplicaciones con Jaeger",
    "text": "9.5 Monitoreo del rendimiento de aplicaciones con Jaeger\nJaeger es un marco de seguimiento de aplicaciones de código abierto que permite a los desarrolladores y operadores del sistema recopilar información de una aplicación en ejecución y determinar cómo la aplicación pasa su tiempo y cómo interactúa con otros componentes del sistema distribuido, utilizando la API OpenTracing.\n\n9.5.1 Componentes de Jaeger\nAlgunos de los componentes importantes que conforman el ecosistema de Jaeger son los siguientes:\n\nLas librerías cliente disponibles como paquetes o directamente desde GitHub\nLos agentes Jaeger, utilizados para escuchar los spans\nEl recolector, encargado de agregar los datos enviados desde los agentes\nJaeger query, para analizar los datos a través de una interfaz de usuario\nEl Ingester, que nos permite recopilar datos de temas Kafka y luego escribir los datos a servicios como AWS Elasticsearch.\n\nLo que vimos anteriormente es cómo instalar Jaeger localmente, sin embargo, también es posible desplegarlo en un entorno de Kubernetes utilizando Kubernetes Operator, que es un recurso especializado para gestionar la instalación y operación de aplicaciones complejas. Para instalar Jaeger en Kubernetes, se puede seguir las instrucciones del repositorio oficial y ejecutar los comandos kubectl proporcionados. Esto incluye la creación del espacio de nombres del operador y la configuración de los permisos adecuados a través de una vinculación de roles, lo que garantiza que Jaeger funcione correctamente en todos los espacios de nombres del clúster.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#registro-de-docker-y-registro-de-tiempo-de-ejecución-de-contenedores",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#registro-de-docker-y-registro-de-tiempo-de-ejecución-de-contenedores",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "",
    "text": "Splunk\nElasticsearch\nLoggly\nPapertrail\n\n\n\nAWS CloudWatch\nGoogle Cloud Logging\nMicrosoft Azure Monitor Logs",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-liveness-readiness-y-startup-en-kubernetes",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-liveness-readiness-y-startup-en-kubernetes",
    "title": "9  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "9.2 Uso de las sondas de Liveness, Readiness y Startup en Kubernetes",
    "text": "9.2 Uso de las sondas de Liveness, Readiness y Startup en Kubernetes\nKubernetes tiene varios tipos de controles de salud, llamados sondas , para garantizar que los contenedores que maneja Docker están en condiciones de procesar el tráfico. Los tipos de sondas abordan inquietudes como:\n\nLiveness: Determina si una aplicación puede procesar solicitudes\nReadiness: Determina si un contenedor está listo para recibir tráfico real, especialmente si depende de recursos externos que tienen que ser accesibles.\nStartup: Determina si un contenedor está listo para empezar a tomar los otros dos tipos de tráfico, destinado a aplicaciones heredadas de inicio lento para darles tiempo para iniciarse.\n\n\n9.2.1 Usar una sonda Liveness para ver si un contenedor puede responder\nA continuación, se muestra un fragmento de configuración YAML, el cual define una sonda de “liveness” para un contenedor en Kubernetes, utilizada para verificar si el contenedor está funcionando correctamente\nlivenessProbe:\nhttpGet:\npath: /\nport: http\nUna sonda de liveness es importante porque permite que Kubernetes detecte si el contenedor está en un estado no funcional. Si la sonda falla, Kubernetes reiniciará el contenedor automáticamente para intentar restaurar su funcionalidad.\n\n\n9.2.2 Usar una sonda Readiness para garantizar que un servicio pueda recibir trafico\nEl uso de una sonda de readiness en Kubernetes asegura que una aplicación esté completamente lista para manejar tráfico antes de ser incluida en el balanceador de carga del clúster.\nreadinessProbe:\nhttpGet:\npath: /api/v2/games/ready\nport: http\nEste fragmento de configuración YAML define una sonda de “readiness” en Kubernetes, que se utiliza para determinar si un contenedor está listo para aceptar tráfico.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  }
]