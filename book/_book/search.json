[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contenedores al Alcance de Todos",
    "section": "",
    "text": "1 Prefacio\nEste libro te enseñará a manejar y comprender contenedores con herramientas modernas como Docker y Podman. Aprenderás desde los fundamentos hasta el despliegue de aplicaciones en entornos reales, pasando por la construcción de imágenes, gestión de redes y almacenamiento, todo a través de ejemplos prácticos y proyectos aplicados. Sin embargo, este no es un manual introductorio típico. Mi objetivo es ayudarte a convertirte en un profesional capaz de utilizar contenedores no solo para ejecutar aplicaciones, sino para integrarlos en procesos de desarrollo y despliegue ágiles.\nLos capítulos del libro están organizados en torno a tres proyectos principales, diseñados para abarcar aspectos clave de Docker y Podman. Estos proyectos no solo cubren la construcción y gestión de contenedores, sino también prácticas avanzadas como la integración con CI/CD, optimización de recursos y resolución de problemas comunes. He seleccionado estos proyectos por dos razones: primero, porque representan el rango completo de funcionalidades de estas herramientas; segundo, porque están diseñados para ayudarte a abordar los desafíos reales del desarrollo y despliegue moderno de software.\nMás allá de las características técnicas, los contenedores resuelven problemas logísticos importantes en el desarrollo. Permiten crear entornos reproducibles, escalar aplicaciones de manera eficiente y minimizar errores relacionados con dependencias o configuraciones. A través de este libro, no solo aprenderás a usar Docker y Podman, sino también a integrar estas habilidades en tu trabajo como desarrollador, maximizando tu productividad y mejorando tu flujo de trabajo.\nEste libro está dirigido a los siguientes perfiles: - Estudiantes y profesionales interesados en aprender sobre contenedores desde cero. - Desarrolladores que buscan integrar prácticas modernas de DevOps y microservicios. - Ingenieros que desean optimizar procesos de despliegue y escalabilidad en la nube.\nHe diseñado este libro para que sea accesible y práctico, centrándome en conceptos aplicados y dejando de lado teorías avanzadas que pueden ser un obstáculo al inicio. Mi objetivo es proporcionarte las herramientas y el conocimiento para que puedas enfrentarte a problemas reales en el desarrollo de software.\nAprender a manejar contenedores es una habilidad esencial para cualquier profesional en tecnología hoy en día. Es como pasar de usar un sistema tradicional, donde todo está predeterminado, a un sistema donde tienes la flexibilidad y el control total para crear lo que necesitas. Como dijo Greg Snow al referirse a otro contexto, los contenedores son como un vehículo todoterreno que te llevará a lugares donde las herramientas tradicionales no pueden llegar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#convenciones-utilizadas-en-este-libro",
    "href": "index.html#convenciones-utilizadas-en-este-libro",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.1 Convenciones Utilizadas en Este Libro",
    "text": "1.1 Convenciones Utilizadas en Este Libro\n\nCursiva: Indica términos nuevos, URLs y nombres de archivos.\nTexto de ancho fijo: Representa comandos, nombres de variables o elementos de código.\nTexto en negrita: Muestra comandos que deben ser escritos literalmente por el lector.\n\nPara realizar comentarios o preguntas técnicas sobre este libro, por favor abre un issue en github.com/tu-repositorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.2 Agradecimientos",
    "text": "1.2 Agradecimientos\nQuiero agradecer a todas las personas que me han ayudado a escribir este libro, desde mis colegas y estudiantes que han probado este contenido, hasta quienes contribuyeron con ideas y retroalimentación. También agradezco a las comunidades de Docker y Podman por proporcionar recursos invaluables y fomentar el aprendizaje continuo. Finalmente, gracias a mi familia por su apoyo incondicional durante este proceso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "prework.html",
    "href": "prework.html",
    "title": "2  First steps with Polars",
    "section": "",
    "text": "2.1 Requisitos de Docker antes de instalar.\nocker destaca por su compatibilidad entre sistemas. Las máquinas virtuales o la virtualización de hardware clásica emulan un sistema operativo invitado entero, mientras que los contenedores Docker comparten el núcleo del sistema anfitrión, ejecutándose como procesos aislados en el espacio del usuario. En sus inicios, Docker se utilizaba exclusivamente en sistemas Linux o en sistemas operativos basados en Linux. Hoy en día, el software de código abierto se caracteriza por su completa independencia de los sistemas operativos. Docker utiliza el kernel local de Linux en las variantes de 64 bits de los sistemas operativos de Linux, los sistemas que no son de Linux utilizan simplemente una imagen del sistema Linux a través de un hypervisor o una máquina virtual.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First steps with Polars</span>"
    ]
  },
  {
    "objectID": "introduccion_docker.html",
    "href": "introduccion_docker.html",
    "title": "3  Introducción a Docker",
    "section": "",
    "text": "3.0.1 Introducción\nDocker surge como una solución innovadora al problema de la virtualización tradicional, ya que en el enfoque clásico, se utilizan máquinas virtuales (VMs), las cuales requieren de un sistema operativo completo para su creación y ejecución, además de que consumen una gran cantidad de espacio y recursos, incluso si solo se necesita ejecutar una tarea específica, por lo que este enfoque en la actualidad es ineficiente y poco flexible.\nDocker se centra en solucionar este problema mediante el uso de contenedores, definidos por archivos Dockerfile. Estos archivos especifican únicamente lo necesario para que una aplicación funcione, eliminando la necesidad de instalar sistemas operativos completos, basta con tener una imagen base y las dependencias necesarias; Docker optimiza el uso del espacio y acelera en gran medida el despliegue de aplicaciones.\nUna de las principales ventajas de Docker es su portabilidad, ya que permite que las aplicaciones se ejecuten de manera consistente en diferentes sistemas operativos y entornos, como desarrollo, pruebas y producción. Esto lo convierte en una herramienta fundamental para implementar arquitecturas modernas, como los microservicios, facilitando la gestión y escalabilidad de aplicaciones complejas.\n\n\n3.0.2 ¿Qué es Docker?\nDocker es una tecnología de virtualización basada en contenedores que permite empaquetar aplicaciones junto con sus dependencias y frameworks necesarios para su ejecución, esto garantiza que las aplicaciones funcionen de manera consistente y uniforme, sin importar el entorno en el que se ejecuten, resolviendo los problemas de compatibilidad y configuración de dependencias que suelen surgir al migrar entre sistemas operativos o entornos.\n\n\n3.0.3 Componente de Docker\nDocker engine: Es el motor de Docker y se encarga de la gestión de todos los contenedores que se ejecutan en Docker.\nDocker images: Es la plantilla donde se ecuentra la aplicación, la imagen base del sistema operativo y las dependencias necesarias para la ejecución de la aplicación, estas imágenes son reutilizables y permiten crear contenedores de manera rápida y eficiente.\nDocker container: Es la ejecución de una instancia de la imagen de Docker, donde cada contenedor opera en un entorno completamente aislado, compartiendo únicamente el kernel del sistema operativo anfitrión pero manteniendo independencia en cuanto a procesos, redes y almacenamiento.\nRedes: Las redes sirven para la comunicación entre los contenedores, permitiendo que se comuniquen entre sí o con el host, por lo que existen diferentes modelos de red que son las redes de puente, las redes de host y las redes de superposición.\nVolúmenes: Los volúmenes sirven para almacenar los datos que se desea que persistan en el tiempo, es decir cuando el contenedorer termine de ejecutarse, se reinicie o se elimine, esto es ideal para manejar aplicaciones que requieren de una base de datos o almacenamiento persistente.\nDocker Hub: Es el repositorio central que utiliza Docker para que los desarrolladores puedan compartir y descargar imágenes tanto públicas como privadas, lo que facilita la colaboración y la reutilización de imágenes.\n\n\n3.0.4 Diferencias entre Docker y Máquinas Virtuales\n\n3.0.4.1 Docker\n\nLos contenedores de Docker solo comparten el núcleo del sistema operativo host.\nLos contenedores son más ligeros.\nArrancan en segundos.\nSon más portables y fáciles de gestionar.\nPresentan menos sobrecarga sobre el hardware del host.\nPermiten la ejecución de múltiples contenedores en un mismo host.\nSon ideales para aplicaciones basadas en microservicios.\n\n\n\n3.0.4.2 Máquinas Virtuales\n\nLas máquinas virtuales necesitan de la virtuaización de todo el hardware del host.\nLas máquinas virtuales ocupan gran cantidad de espacio y recursos para su creación y ejecución.\nSu arranque es lento, por lo general tardan minutos.\nSon más complejas de administrar y su portabilidad es compleja.\nPresentan mayor sobrecarga sobre el hardware del host.\nSe puede ejecutar multiples máquinas virtuales en un mismo host, pero esto requiere de más recursos.\nSon ideales para aplicaciones con una arquitectura monolítica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a Docker</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html",
    "href": "understanding_cloud_concepts.html",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "4.1 Ecosistema del Cloud Computing\nEl concepto de cloud computing está transformando la manera en que las empresas operan, permitiéndoles acceder a recursos de cómputo y almacenamiento bajo demanda, escalar sin límites y adoptar modelos de precios flexibles. Esta tecnología ha revolucionado tanto a empresas emergentes como a grandes corporaciones.\nEl ecosistema de cloud computing consta de tres principales actores:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "Consumidores de servicios: Usan aplicaciones y herramientas en la nube sin preocuparse por su ubicación o diseño.\nProveedores de servicios: Ofrecen infraestructura, aplicaciones y herramientas basadas en la nube.\nDiseñadores de servicios: Construyen herramientas o aplicaciones optimizadas para ecosistemas específicos de nube.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "4.2 Conceptos Fundamentales del Cloud Computing",
    "text": "4.2 Conceptos Fundamentales del Cloud Computing\nEl cloud computing implica la provisión de recursos compartidos como aplicaciones, almacenamiento y plataformas de desarrollo a través de estándares y automatización. Los servicios comunes incluyen:\n\nAutomatización: Procesos gestionados automáticamente para optimizar la eficiencia.\nAutoservicio: Permite a los usuarios aprovisionar recursos por sí mismos.\nElasticidad: Capacidad de ajustar automáticamente recursos según las necesidades.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-nube",
    "href": "understanding_cloud_concepts.html#modelos-de-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.3 Modelos de Nube",
    "text": "4.3 Modelos de Nube\nExisten diferentes modelos de despliegue en la nube, cada uno adaptado a distintas necesidades empresariales:\n\n4.3.1 Nube Pública\n\nDefinición: Recursos compartidos y gestionados por un proveedor externo. Los usuarios pagan por el uso bajo demanda.\nCaracterísticas:\n\nEscalabilidad masiva y elasticidad automática.\nAcceso a servicios avanzados, como análisis de datos y aprendizaje automático.\nDisponibilidad global, ideal para empresas que requieren operaciones en múltiples regiones.\n\nCasos de uso: Aplicaciones de comercio electrónico, almacenamiento masivo, pruebas y desarrollo.\n\n\n\n4.3.2 Nube Privada\n\nDefinición: Recursos dedicados y gestionados por una sola organización, ya sea internamente o a través de un proveedor externo.\nCaracterísticas:\n\nControl total sobre los recursos.\nMayor seguridad y personalización.\nCumplimiento normativo y gobernanza específica.\n\nCasos de uso: Datos sensibles, aplicaciones con requisitos legales estrictos o sistemas heredados.\n\n\n\n4.3.3 Nube Híbrida\n\nDefinición: Combina nubes públicas y privadas, permitiendo la interoperabilidad y la transferencia de datos entre ambas.\nCaracterísticas:\n\nBalanceo de cargas de trabajo entre entornos.\nFlexibilidad para mover datos según necesidades de costo, rendimiento o seguridad.\n\nCasos de uso: Migraciones graduales hacia la nube, recuperación ante desastres, análisis de datos en múltiples ubicaciones.\n\n\n\n4.3.4 Multicloud\n\nDefinición: Uso simultáneo de múltiples nubes públicas para satisfacer distintas necesidades empresariales.\nCaracterísticas:\n\nEvita la dependencia de un solo proveedor.\nFlexibilidad para aprovechar lo mejor de cada plataforma.\nGestión centralizada para controlar costos y rendimiento.\n\nCasos de uso: Desarrollo de aplicaciones en plataformas específicas o maximización de servicios según región.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-entrega",
    "href": "understanding_cloud_concepts.html#modelos-de-entrega",
    "title": "4  Comprendiendo la Nube",
    "section": "4.4 Modelos de Entrega",
    "text": "4.4 Modelos de Entrega\nLos modelos de entrega en cloud computing son fundamentales para entender cómo se ofrecen los servicios a los usuarios. Cada uno proporciona un nivel distinto de abstracción y control:\n\n4.4.1 Infraestructura como Servicio (IaaS)\n\nDefinición: Provisión de recursos básicos, como servidores virtuales, almacenamiento y redes, sobre los cuales los usuarios pueden construir sus propias aplicaciones.\nCaracterísticas:\n\nControl total sobre el sistema operativo y las aplicaciones.\nAlta flexibilidad para personalizar entornos según las necesidades.\nPago por uso, permitiendo reducir costos operativos.\n\nEjemplos de servicios: Amazon EC2, Google Compute Engine, Microsoft Azure VMs.\nCasos de uso:\n\nMigración de centros de datos físicos a la nube.\nEscenarios de desarrollo y pruebas.\nImplementación de aplicaciones personalizadas.\n\n\n\n\n4.4.2 Plataforma como Servicio (PaaS)\n\nDefinición: Provisión de una capa de abstracción que incluye herramientas de desarrollo, middleware y bases de datos, optimizada para la creación y despliegue de aplicaciones.\nCaracterísticas:\n\nEntorno preconfigurado para desarrollo rápido.\nIntegración de herramientas como frameworks y APIs.\nGestión automatizada de recursos y actualizaciones.\n\nEjemplos de servicios: Google App Engine, Microsoft Azure App Service, Heroku.\nCasos de uso:\n\nDesarrollo de aplicaciones web y móviles.\nCreación de aplicaciones en entornos colaborativos.\nEscenarios donde se busca acelerar el tiempo de desarrollo.\n\n\n\n\n4.4.3 Software como Servicio (SaaS)\n\nDefinición: Provisión de aplicaciones completas accesibles a través de internet. Los usuarios no gestionan ni la infraestructura ni las plataformas subyacentes.\nCaracterísticas:\n\nFacilidad de uso y acceso desde cualquier dispositivo.\nModelos de suscripción mensual o anual.\nAlta disponibilidad y actualizaciones automáticas.\n\nEjemplos de servicios: Google Workspace, Salesforce, Zoom.\nCasos de uso:\n\nHerramientas de colaboración y productividad.\nGestión de relaciones con clientes (CRM).\nServicios de recursos humanos y contabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "href": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.5 Ciclo de Vida de Recursos en la Nube",
    "text": "4.5 Ciclo de Vida de Recursos en la Nube\nEn contraste con los centros de datos tradicionales, la nube permite a los usuarios:\n\nAlquilar recursos bajo demanda.\nPagar únicamente por el uso real.\nLiberar recursos automáticamente cuando ya no se necesitan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "href": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "title": "4  Comprendiendo la Nube",
    "section": "4.6 Gestión de Nubes Híbridas y Multicloud",
    "text": "4.6 Gestión de Nubes Híbridas y Multicloud\nUna nube híbrida efectiva debe integrar múltiples entornos de forma automatizada y bien gestionada. Los entornos multicloud requieren visibilidad, control y capacidad para mover datos y cargas de trabajo según convenga.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "href": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "title": "4  Comprendiendo la Nube",
    "section": "4.7 Cambios en el Rol del Centro de Datos",
    "text": "4.7 Cambios en el Rol del Centro de Datos\nAunque los centros de datos no desaparecerán, la adopción de la nube les exige modernizarse. Las estrategias incluyen:\n\nVirtualización: Separar software de hardware para mejorar la eficiencia.\nNubes privadas: Crear entornos altamente automatizados con capacidades de autoservicio.\nNubes híbridas: Combinar servicios en la nube con infraestructura local.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "virtualbox and docker containers for developments.html",
    "href": "virtualbox and docker containers for developments.html",
    "title": "5  VirtualBox y Contenedores Docker para el Desarrollo",
    "section": "",
    "text": "5.0.1 Introducción\nDentro del desarrollo de software de la actualidad se requieren entornos flexibles, escalables y consistentes. La configuración manual para cada proyecto puede ser tedioso y con tendencia a errores, en especial cuando las dependencias del sistema o sus versiones de software son críticas. Para esto, existen herramientas como VirtualBox y Docker juegan un papel importante.\n\n\n5.0.2 VirtualBox:\nLa herramienta de VirtualBox nos proporciona un software de hipervisor el cual nos permite la ejecución de máquinas virtuales dentro de un sistema host o anfitrión. Cada una de estas máquinas virtuales imitan entornos completos, incluso el de los sistemas operativos, de configuraciones y de aplicaciones que se requieren para el desarrollo. Se puede usar virtualbox para realizar pruebas de software en múltiples sistemas operativos o para poner en aislamineto un entorno de desarrollo.\nGuest Additions\nDentro de los sistemas invitados como Windows y Linux, se puede instalar controladores que permitan integrar los sistemas operativos de invitado y host. Tales controladores se conocen como Guest Additions y se los puede bajar desde el sitio web de VirtualBox.\nSon instalables dentro de la máquina virtual como cualquier programa que se vaya a instalar para Windows o Linux. La integración con el host es bastante útil.\nInstalación VirtualBox\n\nDescargue VirtualBox desde el sitio web oficial.\nInstale el software utilizando el instalador proporcionado.\nInicie VirtualBox y verifique que se esté ejecutando correctamente.\n\n\n\n5.0.3 Contenedores Docker:\nLa tecnología Docker hace el uso de contenedores ligeros para poder empaquetar aplicaciones incluidas sus dependencias utilizando un solo entorno ejecutable. En contraparte con las máquinas virtuales, los contenedores tienen compartición del núcleo del sistema operativo anfitrión, permitiendoles ser más eficientes en términos de recursos. Docker ayuda a que los desarrolladores puedan crear entornos reproducibles y escalables en cuestión de segundos, haciendo fácil y fluida la colaboración y la integración continua.\nConfiguración Contenedor Docker Básico Docker nos proporciona una manera eficiente de empaquetar, enviar y poder ejecutar software. En esta parte, se analizaran los pasos básicos para crear un contenedor para el desarrollo.\n\nEscribiendo el Dockerfile:\n\nUn archivo Dockerfile específica el entorno de configuración y todos los comandos para poder tener nuestro contenedor, ejemplo:\n# Usso de ina imagen oficial de PHP\nFROM php:7.4-apache\n\n# Habilitar módulos de Apache requeridos\nRUN a2enmod userdir \\\n    && a2enmod php7.4\n\n# Copiar el archivo de configuración para Apache\nCOPY php.conf /etc/apache2/mods-available/php7.4.conf\n\n# Definir el entry point\nENTRYPOINT [\"/entrypoint.sh\"]\n\nConstruyendo el Docker Image:\n\nPara crear la imagen del contenedor se hace uso del script build.sh, ejemplo:\n#!/usr/bin/env bash\n\n# Se construye el Docker Image\n\ndocker build -t chapter2 .\n\nCorriendo el Docker Container:\n\nPara lanzar el contenedor, se hace uso del script run.sh, ejemplo:\n#!/usr/bin/env bash\n\ndocker run -d --name chapter2 chapter2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>VirtualBox y Contenedores Docker para el Desarrollo</span>"
    ]
  },
  {
    "objectID": "scaling_and_load_testing_docker_applications.html",
    "href": "scaling_and_load_testing_docker_applications.html",
    "title": "6  Escalado y Pruebas de Carga de Aplicaciones Docker",
    "section": "",
    "text": "#Autor:Pool Ochoa\nEl escalado y las pruebas de carga son esenciales para garantizar que las aplicaciones en contenedores puedan manejar el tráfico creciente de manera eficiente y continuar funcionando bajo presión. Este proceso es particularmente relevante para infraestructuras basadas en Kubernetes, donde se pueden implementar estrategias de escalado tanto manuales como automáticas.\n\n6.0.1 Escalado en Kubernetes\nKubernetes permite escalar las aplicaciones en dos niveles principales:\n1. Escalado de Pods: Incrementar o reducir el número de réplicas de una aplicación según la demanda.\n2. Escalado del Clúster: Ajustar el número de nodos disponibles en el clúster para manejar los pods adicionales cuando los recursos se limitan.\nPara automatizar el escalado, Kubernetes ofrece herramientas como:\n- Cluster Autoscaler: Escala los nodos del clúster según la carga actual.\n- Horizontal Pod Autoscaler (HPA): Ajusta el número de pods basándose en métricas como el uso de CPU.\n- Vertical Pod Autoscaler (VPA): Modifica dinámicamente las solicitudes de CPU y memoria de los pods para optimizar los recursos.\n\n\n6.0.2 Pruebas de Carga\nLas pruebas de carga evalúan cómo responde una aplicación bajo diferentes niveles de tráfico. Estas pruebas permiten identificar cuellos de botella y garantizar que los mecanismos de escalado funcionen como se espera. Herramientas como Apache Bench (ab) y k6 son comunes para realizar estas pruebas.\n\n\n6.0.3 Ejemplo 1: Escalado Horizontal de Pods\n\nConfigurar el HPA en Kubernetes con un comando como:\nkubectl autoscale deployment app-deployment --cpu-percent=50 --min=2 --max=10\nAquí, el número de pods de la aplicación se ajustará automáticamente entre 2 y 10, según el uso de CPU.\nEjecutar una prueba de carga con Apache Bench para simular tráfico:\nab -n 1000 -c 50 http://app-url/\nEsto genera 1000 solicitudes concurrentes para evaluar si los pods adicionales se crean al aumentar el uso de CPU.\n\n\n\n6.0.4 Ejemplo 2: Pruebas de Escalabilidad con k6\n\nEscribir un script de carga en JavaScript para simular usuarios concurrentes:\nimport http from 'k6/http';\n\nexport default function() {\n    http.get('http://app-url/');\n}\nEjecutar el script con 50 usuarios virtuales durante 30 segundos:\ndocker run --rm -i loadimpact/k6 run --vus 50 --duration 30s - &lt; script.js\nEsto mide el rendimiento de la aplicación y verifica si el Cluster Autoscaler añade nodos para manejar el incremento de pods.\n\nCon estas estrategias, puedes optimizar el desempeño de aplicaciones contenedorizadas y garantizar una experiencia de usuario confiable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Escalado y Pruebas de Carga de Aplicaciones Docker</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html",
    "href": "deploying_docker_compose.html",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "",
    "text": "7.1 Requisitos para su implementación.\nEl escenario de implementación práctico más simple posible de una aplicación empaquetada con Docker implica ejecutar Docker Compose en un solo host, sin embargo, tiene algunas desventajas importantes en términos de rendimiento y disponibilidad.\nPara continuar con la implementación, necesitará una computadora que ejecute un sistema operativo Linux moderno de la misma arquitectura que su sistema de desarrollo, con suficiente memoria, procesador y capacidad de almacenamiento para ejecutar su aplicación.\nDeberá tener alguno de estos sistemas operativos linux que admitan Docker:  - Red Hat\n- Ubuntu 16.04 o superior\n- Amazon Linux 2\n- Debian\no alguna distribución centrada en Docker como Container Linux o CoreOS.\nAdemás, antes de configurar el software en el host, debe asegurarse de que tenga una dirección IP estable. A veces, se las denomina direcciones IP estáticas o direcciones IP elásticas en un contexto de AWS.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "href": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.2 Implementación mediante archivos de configuración y scripts de soporte.",
    "text": "7.2 Implementación mediante archivos de configuración y scripts de soporte.\nPara implementar nuestra aplicación en un servidor de producción, utilizaremos una combinación de comandos simples y scripts de soporte que inician o actualizan el conjunto de contenedores en ejecución. Comencemos por analizar en detalle los dos archivos más importantes necesarios para la implementación: Dockerfile y docker­compose.yml.\nEste es un ejemplo de Dockerfile basado en la producción de un juego, deberás adaptar tu Dockerfile según las necesidades de tu aplicación: FROM alpine:20191114\nRUN apk update &&\napk add nodejs nodejs-npm\nRUN addgroup -S app && adduser -S -G app app\nRUN mkdir -p /app/public /app/server\nADD src/package.json* /app/\nWORKDIR /app\nRUN npm -s install\nCOPY src/public/ /app/public/\nCOPY src/server/ /app/server/\nCOPY src/.babelrc /app/\nRUN npm run compile\nUSER app\nEXPOSE 3000\nENTRYPOINT [“npm”, “start”]\n\nEste es un ejemplo de un archivo de docker-compose:\nversion: ‘3’\nservices:\nshipit-clicker-web-v2:\nbuild: .\nenvironment:\n- APP_ID=shipit-clicker-v2\n- OPENAPI_SPEC=/api/v1/spec\n- OPENAPI_ENABLE_RESPONSE_VALIDATION=false\n- PORT=3000\n- LOG_LEVEL={LOG_LEVEL:-debug}\n- REQUEST_LIMIT=100kb\n- REDIS_HOST=\\({REDIS_HOST:-redis} \\\n- REDIS_PORT=\\){REDIS_PORT:-6379}\n- SESSION_SECRET=${SESSION_SECRET:-mySecret-v2}\n\nAhora, es necesario definir una configuración de red para el contenedor principal para luego vincularlos a los demás contenedores. Un ejemplo es: ports: - {PORT:-3006}:3000\nnetworks:\n- private-redis-shipit-clicker-v2\nlinks:\n- redis\ndepends_on:\n- redis\n\nAhora bien, al ejecutar un sitio en producción, es posible que deba realizar algunas operaciones con frecuencia como reiniciarlo o actualizarlo. Para resolver esto puede agregar scripts con el objetivo de automatizar procesos, los más comunes son aquellos para reiniciar la aplicación y implementar cambios.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación",
    "href": "deploying_docker_compose.html#implementación",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.3 Implementación",
    "text": "7.3 Implementación\nPara iniciar los servicios en segundo plano, use el siguiente comando: $ docker-compose up -d\nVerifique que los servicios se están ejecutando con: $ docker-compose ps\nCompruebe si los registros del sistema muestran algún error: $ docker-compose logs\nMientras no veas una secuencia de mensajes de error en los registros, deberías poder acceder al sitio web en la dirección IP del servidor (por ejemplo, en http://192.0.2.10)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "href": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "title": "7  Desplegar aplicaciones con Docker Compose.",
    "section": "7.4 Limitaciones de implementación en un solo host",
    "text": "7.4 Limitaciones de implementación en un solo host\nSi el contenedor del servidor de base de datos o el contenedor del servicio web fallan y no se pueden reiniciar automáticamente, el sitio no funcionará y será necesaria una intervención manual. La solución puede ser tan simple como conectarse por SSH y reiniciar el servidor. Pero, a veces, un solo servidor tendrá tan poca memoria que deberá reiniciarse manualmente desde una consola de nivel superior o incluso apagar y encender manualmente.\nDependiendo de su proveedor de alojamiento, el sistema operativo base con el que comience y cómo estén configurados los contenedores Docker, puede experimentar inestabilidad que sea difícil de rastrear. Tal vez su host se reinicie con frecuencia debido a que la red del proveedor detecta hardware inestable o condiciones de red inestables. Tal vez haya configurado su sistema operativo para instalar actualizaciones automáticas y aplicarlas provoque períodos de interrupciones. Tal vez la aplicación crezca en la memoria hasta que provoque una falla de algún tipo.\nSi ha alojado su aplicación en un único servidor físico o virtual, debe asegurarse de realizar copias de seguridad del sistema con regularidad, la pérdida del host podría provocar que se pierda toda la información.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html",
    "href": "sharing_containers_used_docker_hub.html",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "8.1 ¿Qué es Docker Hub?\nDocker Hub es una plataforma centralizada que permite a los desarrolladores almacenar, compartir y gestionar imágenes de contenedores. Es el repositorio oficial de Docker, donde se pueden encontrar imágenes públicas y privadas, facilitando la colaboración y la reutilización de contenedores en diferentes entornos.\nDocker Hub es un servicio basado en la nube que proporciona un registro de imágenes de Docker. Permite a los desarrolladores:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "Almacenar Imágenes: Guardar imágenes de contenedores en un lugar centralizado.\nCompartir Imágenes: Hacer que las imágenes estén disponibles para otros desarrolladores.\nAutomatizar Builds: Configurar pipelines de CI/CD para construir y desplegar imágenes automáticamente.\nGestionar Repositorios: Organizar imágenes en repositorios públicos o privados.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.2 Beneficios de Usar Docker Hub",
    "text": "8.2 Beneficios de Usar Docker Hub\n\nColaboración: Facilita el trabajo en equipo al permitir compartir imágenes de contenedores fácilmente.\nReutilización: Permite reutilizar imágenes existentes, ahorrando tiempo y esfuerzo en la configuración de entornos.\nDistribución: Facilita la distribución de aplicaciones y servicios en diferentes entornos y plataformas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.3 Pasos para Compartir Contenedores en Docker Hub",
    "text": "8.3 Pasos para Compartir Contenedores en Docker Hub\n\nCrear una Cuenta en Docker Hub: Regístrate en Docker Hub para crear una cuenta gratuita.\nIniciar Sesión desde la Línea de Comandos: Usa el comando docker login para iniciar sesión en Docker Hub desde tu terminal.\nConstruir una Imagen de Docker: Crea una imagen de Docker usando un Dockerfile y el comando docker build.\nEtiquetar la Imagen: Etiqueta la imagen con tu nombre de usuario de Docker Hub y el nombre del repositorio.\nSubir la Imagen a Docker Hub: Usa el comando docker push para subir la imagen etiquetada a Docker Hub.\nCompartir la Imagen: Comparte el enlace del repositorio de Docker Hub con otros desarrolladores para que puedan descargar y usar la imagen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "href": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.4 Ejemplo Práctico",
    "text": "8.4 Ejemplo Práctico\nA continuación, se muestra un ejemplo práctico de cómo compartir una imagen de contenedores en Docker Hub:\n\nConstruir la Imagen: sh docker build -t myapp:late  st .\nEtiquetar la Imagen: sh docker tag myapp:latest your-dockerhub-username/myapp:latest\nIniciar Sesión en Docker Hub: sh docker login\nSubir la Imagen: sh docker push your-dockerhub-username/myapp:latest\nCompartir el Enlace: Comparte el enlace https://hub.docker.com/r/your-dockerhub-username/myapp con otros desarrolladores.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "href": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "title": "8  Compartir Contenedores Usando Docker Hub",
    "section": "8.5 Consideraciones de Seguridad",
    "text": "8.5 Consideraciones de Seguridad\n\nImágenes Privadas: Si no deseas que tus imágenes sean públicas, puedes configurar repositorios privados en Docker Hub.\nAutenticación: Asegúrate de usar autenticación segura y gestionar tus credenciales de Docker Hub de manera adecuada.\nActualizaciones: Mantén tus imágenes actualizadas para incluir las últimas mejoras y parches de seguridad.\n\nAl finalizar este capítulo, tendrás las habilidades necesarias para compartir tus contenedores con otros desarrolladores y utilizar imágenes de contenedores de la comunidad, mejorando así tu flujo de trabajo y la colaboración en proyectos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html",
    "href": "conclusionfindecamino.html",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "",
    "text": "9.0.1 Para terminar, comencemos\n#Autor:Cristian Yaguana\nEl libro se destacó por tres áreas clave las cuales son:\nLa tecnología se ve presente en la mayoría de empresas y proyectos de todo el mundo. Es por ello que se deben tener los conceptos básicos y conocer las diferentes herramientas que respaldan los contenedores, volviéndose más útiles. Todo esto está basado en el entorno de Docker.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#líder-y-elecciones-añadiendo-redundancia",
    "href": "conclusionfindecamino.html#líder-y-elecciones-añadiendo-redundancia",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.1 Líder y elecciones: añadiendo redundancia",
    "text": "9.1 Líder y elecciones: añadiendo redundancia\nLos sistemas de alta disponibilidad son los más óptimos, y herramientas como Kubernetes pueden ayudarnos a lograr este objetivo mediante la orquestación de múltiples contenedores en pods.\nUn patrón de diseño común que se utiliza junto a Kubernetes es Líder y elecciones: añadiendo redundancia. En este patrón, los datos se pueden dividir en varios nodos para proporcionar redundancia. Por ejemplo, los datos se pueden replicar en varios contenedores.\nSi un contenedor falla, los otros contenedores elegirán un nuevo líder y Kubernetes creará un nuevo nodo para cubrir la brecha.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#el-patrón-de-diseño-del-embajador-un-enfoque-hacia-la-representación",
    "href": "conclusionfindecamino.html#el-patrón-de-diseño-del-embajador-un-enfoque-hacia-la-representación",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.2 El patrón de diseño del embajador: un enfoque hacia la representación",
    "text": "9.2 El patrón de diseño del embajador: un enfoque hacia la representación\nEl proxy es una parte importante de muchos sistemas, especialmente en arquitecturas de microservicios. En Docker, se pueden tener varios contenedores en la misma red virtual, y a cada uno de los contenedores se les asigna un nombre, permitiendo que se comuniquen entre sí.\nUn ejemplo de este patrón es la comunicación entre un servicio de almacenamiento en caché del back-end, como Redis, y un conjunto de aplicaciones. En este caso, las aplicaciones se comunican con un solo nodo proxy de Redis, pero este nodo luego distribuye el tráfico entre los otros nodos de Redis en la red.\nRedis es un sistema de almacenamiento en caché y gestión de mensajes de código abierto en memoria. Permite almacenar una variedad de estructuras de datos en la memoria, como listas, hashes y conjuntos. Además, se puede usar como base de datos. Redis también está disponible en Docker Hub.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#patrón-de-diseño-del-adaptador-reutilización-de-soluciones",
    "href": "conclusionfindecamino.html#patrón-de-diseño-del-adaptador-reutilización-de-soluciones",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.3 Patrón de diseño del adaptador: reutilización de soluciones",
    "text": "9.3 Patrón de diseño del adaptador: reutilización de soluciones\nEs importante contar con una forma consistente de comunicar información entre contenedores. Este patrón se puede utilizar para desarrollar una interfaz uniforme, recibir archivos de registro de múltiples contenedores, estandarizarlos y luego almacenar los datos en un servicio de monitoreo centralizado.\nEn el capítulo 10, exploramos el monitoreo de Docker con Prometheus, una herramienta útil para la supervisión de contenedores. Sin embargo, Prometheus requiere una interfaz uniforme a través de API de métricas. Cuando una aplicación no expone puntos finales compatibles con Prometheus, este patrón permite implementar una interfaz que envuelve los contenedores de servicio de destino con un conjunto de puntos finales compatibles con Prometheus.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#leer-más-sobre-patrones-de-diseño",
    "href": "conclusionfindecamino.html#leer-más-sobre-patrones-de-diseño",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.4 Leer más sobre patrones de diseño",
    "text": "9.4 Leer más sobre patrones de diseño\nEl uso de patrones de diseño basados en contenedores ayuda a garantizar que se utilice un modelo adecuado para el sistema, introduciendo solo la complejidad necesaria y asegurando al mismo tiempo que el sistema sea resistente y más fácil de administrar.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#próximos-pasos-para-ampliar-tus-conocimientos-sobre-devops",
    "href": "conclusionfindecamino.html#próximos-pasos-para-ampliar-tus-conocimientos-sobre-devops",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.5 Próximos pasos para ampliar tus conocimientos sobre DevOps",
    "text": "9.5 Próximos pasos para ampliar tus conocimientos sobre DevOps\nLa ejecución de contenedores en producción está orientada a prácticas de DevOps como integración continua y despliegue continuo (CI/CD), orquestación de contenedores con Kubernetes y monitorización con herramientas como Jaeger.\nVimos la opción más sencilla de ofrecer nuestras aplicaciones en un único host con Docker Compose. Después de esto, la experimentación con Jenkins nos proporcionó nuestra primera introducción a las herramientas de CI/CD y su implementación en Docker.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#ingeniería-del-caos-y-construcción-de-sistemas-de-producción-resilientes",
    "href": "conclusionfindecamino.html#ingeniería-del-caos-y-construcción-de-sistemas-de-producción-resilientes",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.6 Ingeniería del caos y construcción de sistemas de producción resilientes",
    "text": "9.6 Ingeniería del caos y construcción de sistemas de producción resilientes\nLa ingeniería del caos es una práctica que reconoce que el código y la infraestructura son inherentemente complejos, y por lo tanto, se debe abordar el proceso de ingeniería y pruebas. Existen cinco conceptos clave de ingeniería del caos que se resumen a continuación:\n\nDesarrollar una hipótesis en torno al comportamiento en estado estacionario: Medir los resultados del sistema durante un período corto de tiempo para obtener una línea de base. Esta línea de base se conoce como estado estable e incluye métricas como la tasa de error, los tiempos de respuesta, la latencia y las cargas de tráfico.\nProbar una variedad de eventos del mundo real: Evaluar eventos reales que podrían afectar un sistema de producción, como fallas de software, entradas alteradas, fallas de contenedores y otros eventos que podrían degradar el rendimiento.\nExperimentar en producción: Aunque probar en producción puede parecer controversial, cada entorno es único, y para obtener resultados auténticos, es imprescindible realizar pruebas en producción.\nMinimizar el impacto, también conocido como radio de explosión: Asegurarse de que cualquier degradación del rendimiento sea temporal y de fácil recuperación. Los experimentos deben estar bien controlados.\nEjecutar experimentos automatizados de forma continua: El uso de enfoques automatizados reduce la carga de trabajo y permite que las pruebas y experimentos se ejecuten continuamente.\n\n\n9.6.1 Herramientas de ingeniería del caos\nUna de las herramientas más destacadas es Chaos Monkey, desarrollada por Netflix. Esta plataforma implementa la infraestructura que finaliza aleatoriamente los contenedores en un entorno de producción, con el objetivo de probar cómo se recupera el sistema de producción. Chaos Monkey también funciona con AWS y Kubernetes, permitiendo a los ingenieros ajustar el sistema para que sea más resistente.\nOtras herramientas para construir y probar sistemas resilientes incluyen:\n\nDuendecillo: Una plataforma de ingeniería del caos compatible con Kubernetes, Mesos, ECS y Docker Swarm.\nMutilar: Una plataforma de código abierto de VMware para orquestar la ingeniería del caos, compatible con Kubernetes y Docker.\nMalla del caos: Una plataforma de ingeniería del caos nativa de la nube orientada a entornos Kubernetes.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "conclusionfindecamino.html#un-resumen-sobre-seguridad-y-qué-hacer-a-continuación",
    "href": "conclusionfindecamino.html#un-resumen-sobre-seguridad-y-qué-hacer-a-continuación",
    "title": "9  CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE",
    "section": "9.7 Un resumen sobre seguridad y qué hacer a continuación",
    "text": "9.7 Un resumen sobre seguridad y qué hacer a continuación\nLos aspectos básicos de seguridad y las mejores prácticas nos brindan orientación sobre el mejor enfoque para manejar Dockerfile y crear imágenes base mínimas. Además, existen funciones de seguridad de contenedores proporcionadas por proveedores como Google, Amazon y Microsoft en la nube.\n\n9.7.1 Metasploit: pruebas de penetración basadas en contenedores\nLas pruebas de penetración son el proceso de búsqueda de fallas de seguridad en un sistema que luego se pueden aprovechar para obtener acceso, exfiltrar datos, alterar el rendimiento o convertir el sistema comprometido en una plataforma para lanzar otros ataques.\nMetasploit es un marco de código abierto para desarrollar e implementar código de explotación de seguridad contra un objetivo remoto, como un contenedor que se ejecuta en su entorno. Metasploit está disponible en formato de contenedor en Docker Hub.\nCon esta herramienta, se pueden probar las vulnerabilidades encontradas en los contenedores utilizando herramientas como Anchore. Las vulnerabilidades pueden incluir, por ejemplo, versiones antiguas de software instaladas en un contenedor que podrían estar expuestas a ataques.\n\n\n9.7.2 Prueba de contenedores vulnerables de terceros: Apache Struts\nApache Struts es un popular framework creado en Java para desarrollar aplicaciones web. En 2017, se descubrió una vulnerabilidad en el framework que permitía a un atacante ejecutar código de forma remota en el servidor que lo ejecutaba. Una de las víctimas más conocidas de esta vulnerabilidad fue Equifax, que sufrió una catastrófica filtración de datos.\n\n\n9.7.3 Resumen\nEl objetivo era proporcionar una guía completa para el desarrollo de Docker, tanto localmente como en la nube. A lo largo de estos 16 capítulos, nuestro propósito fue demostrar no solo cómo desarrollar aplicaciones en contenedores, sino también cómo se pueden crear, implementar, escanear y monitorear.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>CONCLUSIÓN – FIN DE EL CAMINO, PERO NO EL VIAJE</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html",
    "title": "10  Azure DevOps Descripción General",
    "section": "",
    "text": "11 Introducción a DevOps\n#Autor:Cristian Yaguana # Azure DevOps Descripción General\nDurante un largo período, el desarrollo y las operaciones se mantuvieron separados en módulos independientes, cada uno con sus propias responsabilidades y enfoques. Los desarrolladores se encargaban de escribir el código y garantizar su correcto funcionamiento en sus entornos de desarrollo, mientras que los administradores de sistemas asumían la tarea de implementar e integrar dicho código en la infraestructura de TI de la organización.\nEste enfoque se alineaba perfectamente con la metodología en cascada, ampliamente utilizada en la mayoría de los proyectos. La metodología en cascada se basa en el Ciclo de Vida del Desarrollo de Software, el cual establece procesos claramente definidos para la creación de software. Consiste en la división del proyecto en fases secuenciales y lineales, en las que cada etapa depende directamente de los resultados obtenidos en la fase anterior. La secuencia de estos eventos puede representarse de la siguiente manera:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-1-acción-centrada-en-el-cliente",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-1-acción-centrada-en-el-cliente",
    "title": "10  Azure DevOps Descripción General",
    "section": "12.1 Principio 1 – Acción centrada en el cliente",
    "text": "12.1 Principio 1 – Acción centrada en el cliente\nEn la actualidad, los proyectos de desarrollo de software deben contar con ciclos cortos y bucles de retroalimentación, integrando a los usuarios finales y clientes reales dentro del equipo.\nLos equipos y organizaciones que adoptan DevOps deben invertir de manera constante en productos y servicios que maximicen el valor para el cliente. Al mismo tiempo, deben mantener la eficiencia necesaria para fomentar la innovación continua y ajustar su estrategia cuando esta deje de ser efectiva.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-2-crear-con-el-fin-en-mente",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-2-crear-con-el-fin-en-mente",
    "title": "10  Azure DevOps Descripción General",
    "section": "12.2 Principio 2 – Crear con el fin en mente",
    "text": "12.2 Principio 2 – Crear con el fin en mente\nEl enfoque principal debe estar en desarrollar productos funcionales y comercializables para clientes reales. Para lograrlo, es fundamental que todos los miembros de la organización adopten una mentalidad de ingeniería compartida, permitiéndoles contribuir de manera efectiva a la materialización de estos productos.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-3-responsabilidad-de-extremo-a-extremo",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-3-responsabilidad-de-extremo-a-extremo",
    "title": "10  Azure DevOps Descripción General",
    "section": "12.3 Principio 3 – Responsabilidad de extremo a extremo",
    "text": "12.3 Principio 3 – Responsabilidad de extremo a extremo\nEn los proyectos de desarrollo de software tradicionales, una vez finalizado el proceso de desarrollo, el software y los servicios creados se transfieren al departamento de operaciones, que se encarga de su implementación y mantenimiento. Sin embargo, en un enfoque DevOps, los equipos asumen la responsabilidad total del ciclo de vida del software, garantizando su calidad, estabilidad y evolución continua desde el desarrollo hasta la producción.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-4-equipos-autónomos-multifuncionales",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-4-equipos-autónomos-multifuncionales",
    "title": "10  Azure DevOps Descripción General",
    "section": "12.4 Principio 4 – Equipos autónomos multifuncionales",
    "text": "12.4 Principio 4 – Equipos autónomos multifuncionales\nLas organizaciones que adoptan equipos verticales y con plena responsabilidad deben garantizar que estos puedan operar de manera totalmente autónoma a lo largo de todo el ciclo de vida del desarrollo. Para lograr esta independencia, es fundamental contar con un equipo compuesto por un conjunto diverso y equilibrado de habilidades, permitiendo así la autogestión y la toma de decisiones eficiente sin depender de otras áreas.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-5-mejora-continua",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-5-mejora-continua",
    "title": "10  Azure DevOps Descripción General",
    "section": "12.5 Principio 5 – Mejora continua",
    "text": "12.5 Principio 5 – Mejora continua\nLas organizaciones deben adaptarse constantemente a los cambios, ya sea por nuevas tecnologías o ajustes en los requisitos del cliente. En DevOps, la mejora continua es clave para optimizar costos, acelerar la entrega y perfeccionar el software y los servicios de manera constante.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-6-automatizar-todo",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#principio-6-automatizar-todo",
    "title": "10  Azure DevOps Descripción General",
    "section": "12.6 Principio 6 – Automatizar todo",
    "text": "12.6 Principio 6 – Automatizar todo\nPara adoptar una cultura de mejora continua, las organizaciones deben eliminar desperdicios y optimizar el uso de tecnología avanzada. La automatización permite manejar ciclos de desarrollo rápidos, procesar retroalimentación en tiempo real y mejorar la entrega de servicios. Es clave para renovar la forma en que los equipos ofrecen valor a sus clientes.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#fases-del-ciclo-de-vida-de-la-aplicación",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#fases-del-ciclo-de-vida-de-la-aplicación",
    "title": "10  Azure DevOps Descripción General",
    "section": "13.1 Fases del ciclo de vida de la aplicación",
    "text": "13.1 Fases del ciclo de vida de la aplicación\nLas fases del ciclo de vida de la aplicación incluyen:\n\nPlan → Planificar\nDevelop → Desarrollar\nDeliver → Entregar\nOperate → Operar\n\n\n13.1.1 1. Planificación\nEn esta fase, los equipos pueden usar Azure Boards para definir, rastrear y organizar el trabajo a través de tableros Kanban y registros de tareas pendientes. También es posible utilizar GitHub para gestionar el flujo de trabajo y la colaboración.\n\n\n13.1.2 2. Desarrollo\nEl desarrollo está respaldado por herramientas como Visual Studio Code (editor multiplataforma) y Visual Studio (IDE para Windows y Mac). Azure DevOps permite realizar pruebas automatizadas y utilizar Azure Pipelines para generar compilaciones automáticas del código fuente.\n\n\n13.1.3 3. Entrega\nEsta fase implica la implementación de aplicaciones y servicios en entornos específicos. Azure Pipelines facilita la entrega automatizada del código a Azure o entornos locales. Para la creación de entornos de infraestructura, se pueden usar Azure Resource Manager o Terraform.\n\n\n13.1.4 4. Operación\nAquí se implementa la supervisión de pila completa para rastrear el rendimiento de las aplicaciones y servicios. Se pueden usar herramientas como Azure Automation o Chef para administrar entornos en la nube. La seguridad de las aplicaciones también es una prioridad en esta etapa, con funciones integradas accesibles desde cualquier navegador web.\nAzure DevOps ofrece un conjunto de herramientas flexibles y soluciones que permiten personalizar flujos de trabajo en cada fase del ciclo de vida de la aplicación, optimizando el desarrollo, la entrega y la operación del software.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#integración-continua-y-entrega-continua-cicd-en-azure-devops",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#integración-continua-y-entrega-continua-cicd-en-azure-devops",
    "title": "10  Azure DevOps Descripción General",
    "section": "13.2 Integración Continua y Entrega Continua (CI/CD) en Azure DevOps",
    "text": "13.2 Integración Continua y Entrega Continua (CI/CD) en Azure DevOps\nAzure DevOps permite automatizar cada proceso de DevOps mediante Integración Continua (CI) y Entrega Continua (CD), junto con la Implementación Continua.\n\nIntegración Continua (CI) se aplica en la fase de desarrollo y automatiza la creación y prueba del código. Cada vez que se realizan cambios en la rama principal, estos se validan automáticamente y se empaquetan en un artefacto de compilación.\nEntrega Continua (CD) extiende la automatización al proceso de implementación. Con Azure Pipelines, es posible automatizar desde la confirmación del código hasta su despliegue en producción, reduciendo errores manuales y acelerando la entrega de software.\n\nEste enfoque garantiza ciclos de desarrollo más ágiles, con mayor estabilidad y eficiencia en la entrega de aplicaciones y servicios.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#soporte-de-desarrollo-ágil-en-azure-devops",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#soporte-de-desarrollo-ágil-en-azure-devops",
    "title": "10  Azure DevOps Descripción General",
    "section": "13.3 Soporte de Desarrollo Ágil en Azure DevOps",
    "text": "13.3 Soporte de Desarrollo Ágil en Azure DevOps\nAzure DevOps ofrece herramientas para planificación, seguimiento y generación de informes, ayudando a los equipos que adoptan metodologías ágiles. Esto permite ciclos de lanzamiento más cortos y una mayor visibilidad en el proceso de desarrollo.\n\nSe pueden utilizar análisis avanzados e informes para evaluar el progreso.\nEs posible crear paneles personalizados para monitorear el estado del proyecto en tiempo real.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#control-de-versiones-en-azure-devops",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#control-de-versiones-en-azure-devops",
    "title": "10  Azure DevOps Descripción General",
    "section": "13.4 Control de Versiones en Azure DevOps",
    "text": "13.4 Control de Versiones en Azure DevOps\nEl control de versiones es fundamental para la colaboración entre desarrolladores y el seguimiento de cambios en el código. Permite revertir versiones anteriores en caso de errores y facilita el desarrollo en equipo.\nAzure DevOps admite dos tipos de control de versiones:\n\nGit (Distribuido) – Cada desarrollador tiene una copia completa del repositorio, incluidas ramas e historial. Los cambios se sincronizan entre el repositorio local y el de origen de manera independiente.\nTeam Foundation Version Control (TFVC) – Solo se almacena una versión del archivo en la máquina local, mientras que el historial y las ramas permanecen en el servidor.\n\nAmbas opciones permiten a los equipos gestionar eficientemente el código y garantizar la integridad del desarrollo.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#infraestructura-como-código-iac-en-azure-devops",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#infraestructura-como-código-iac-en-azure-devops",
    "title": "10  Azure DevOps Descripción General",
    "section": "13.5 Infraestructura como Código (IaC) en Azure DevOps",
    "text": "13.5 Infraestructura como Código (IaC) en Azure DevOps\nAzure DevOps permite administrar la infraestructura de un proyecto, incluyendo redes, máquinas virtuales y balanceadores de carga, utilizando las mismas herramientas de control de versiones que el código fuente.\nCuando se combina con la entrega continua (CD), la Infraestructura como Código (IaC) garantiza que cada implementación genere un entorno idéntico y reproducible.\n\n13.5.1 Ventajas de IaC:\n\nAutomatiza la configuración y gestión de entornos.\nReduce el riesgo de errores manuales y diferencias entre entornos.\nAcelera la implementación y mantenimiento de la infraestructura.\n\nSin IaC, los equipos deben configurar manualmente cada entorno, lo que consume tiempo y aumenta la probabilidad de errores. Con IaC, los entornos se despliegan de manera consistente y eficiente, optimizando todo el ciclo de vida del desarrollo.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#planes-de-pruebas-de-azure",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#planes-de-pruebas-de-azure",
    "title": "10  Azure DevOps Descripción General",
    "section": "17.1 Planes de Pruebas de Azure",
    "text": "17.1 Planes de Pruebas de Azure\nAzure Test Plans ayuda a mejorar la calidad del código mediante servicios de pruebas exploratorias y planificadas dentro de Azure DevOps. Ofrece herramientas para pruebas manuales, pruebas exploratorias, pruebas de aceptación del usuario y recopilación de comentarios de las partes interesadas.\nLas pruebas manuales permiten a los evaluadores y líderes de pruebas organizar y estructurar pruebas en planes y suites. Los equipos pueden ejecutarlas desde tableros Kanban o directamente en Work Hub. Las pruebas de aceptación del usuario garantizan que el producto cumpla con los requisitos y aporte valor al cliente.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#artefactos-de-azure",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#artefactos-de-azure",
    "title": "10  Azure DevOps Descripción General",
    "section": "17.2 Artefactos de Azure",
    "text": "17.2 Artefactos de Azure\nAzure Artifacts permite gestionar y compartir paquetes como NuGet, npm, Python y Maven, tanto desde fuentes públicas como privadas, dentro de Azure DevOps. Estos paquetes pueden ser utilizados en el código fuente y estar disponibles en las canalizaciones CI/CD. Además, permite crear múltiples fuentes para organizar y controlar el acceso a los paquetes, facilitando la gestión de dependencias en los proyectos.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#mercado-de-extensiones",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#mercado-de-extensiones",
    "title": "10  Azure DevOps Descripción General",
    "section": "17.3 Mercado de Extensiones",
    "text": "17.3 Mercado de Extensiones\nEl Visual Studio Marketplace ofrece extensiones para personalizar y ampliar Azure DevOps. Estas extensiones permiten mejorar la planificación, el seguimiento de código, las pruebas, la integración continua y la colaboración en equipo. Desarrolladas por Microsoft y la comunidad, estas herramientas ayudan a optimizar los flujos de trabajo y la experiencia del usuario en Azure DevOps.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#creando-el-proyecto-inicial-en-azure-devops",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#creando-el-proyecto-inicial-en-azure-devops",
    "title": "10  Azure DevOps Descripción General",
    "section": "17.4 Creando el Proyecto Inicial en Azure DevOps",
    "text": "17.4 Creando el Proyecto Inicial en Azure DevOps\nPara generar el proyecto de escenario, se utilizará el generador de demostración de Azure DevOps, que permite crear proyectos de muestra de forma gratuita.\nAntes de iniciar, es necesario instalar dos extensiones desde el Visual Studio Marketplace, utilizadas en el proyecto Tailwind Traders:\n\nSalidas ARM: Lee los valores de salida de las implementaciones de Azure Resource Manager (ARM) y los configura como variables en Azure Pipelines.\nProyecto de Equipo de Salud: Proporciona una visualización del estado general de las compilaciones, similar a Codify Build Light, facilitando el monitoreo del estado del proyecto.\n\nUna vez instaladas estas extensiones en la organización de Azure DevOps, se podrá generar el proyecto de muestra automáticamente.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  },
  {
    "objectID": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#pasos-para-crear-el-proyecto-en-azure-devops",
    "href": "AZURE_DEVOPS_DESCRIPCIÓN_GENERAL.html#pasos-para-crear-el-proyecto-en-azure-devops",
    "title": "10  Azure DevOps Descripción General",
    "section": "17.5 Pasos para Crear el Proyecto en Azure DevOps",
    "text": "17.5 Pasos para Crear el Proyecto en Azure DevOps\n\nAccede al sitio web del generador de demostración de Azure DevOps:\nAzure DevOps Demo Generator.\nHaz clic en Iniciar sesión. Si no tienes una cuenta de Azure, regístrate para una prueba gratuita seleccionando Empieza gratis.\nAsigna el nombre Comerciantes de Viento de Cola al proyecto, elige una organización y selecciona una plantilla haciendo clic en Elija una plantilla. Luego, selecciona Comerciantes de Viento de Cola de la lista y haz clic en Seleccionar plantilla.\nCompleta los datos requeridos y haz clic en Crear proyecto.\nUna vez creado el proyecto, ve a Azure DevOps, inicia sesión con tus credenciales y selecciona la organización donde creaste el proyecto. Luego, accede al proyecto Comerciantes de Viento de Cola para verificar que se haya generado correctamente.\nRepite estos pasos para crear el proyecto Piezas Ilimitadas en tu entorno de Azure DevOps.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Azure DevOps Descripción General</span>"
    ]
  }
]