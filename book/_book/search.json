[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contenedores al Alcance de Todos",
    "section": "",
    "text": "1 Prefacio\nEste libro te enseñará a manejar y comprender contenedores con herramientas modernas como Docker y Podman. Aprenderás desde los fundamentos hasta el despliegue de aplicaciones en entornos reales, pasando por la construcción de imágenes, gestión de redes y almacenamiento, todo a través de ejemplos prácticos y proyectos aplicados. Sin embargo, este no es un manual introductorio típico. Mi objetivo es ayudarte a convertirte en un profesional capaz de utilizar contenedores no solo para ejecutar aplicaciones, sino para integrarlos en procesos de desarrollo y despliegue ágiles.\nLos capítulos del libro están organizados en torno a tres proyectos principales, diseñados para abarcar aspectos clave de Docker y Podman. Estos proyectos no solo cubren la construcción y gestión de contenedores, sino también prácticas avanzadas como la integración con CI/CD, optimización de recursos y resolución de problemas comunes. He seleccionado estos proyectos por dos razones: primero, porque representan el rango completo de funcionalidades de estas herramientas; segundo, porque están diseñados para ayudarte a abordar los desafíos reales del desarrollo y despliegue moderno de software.\nMás allá de las características técnicas, los contenedores resuelven problemas logísticos importantes en el desarrollo. Permiten crear entornos reproducibles, escalar aplicaciones de manera eficiente y minimizar errores relacionados con dependencias o configuraciones. A través de este libro, no solo aprenderás a usar Docker y Podman, sino también a integrar estas habilidades en tu trabajo como desarrollador, maximizando tu productividad y mejorando tu flujo de trabajo.\nEste libro está dirigido a los siguientes perfiles: - Estudiantes y profesionales interesados en aprender sobre contenedores desde cero. - Desarrolladores que buscan integrar prácticas modernas de DevOps y microservicios. - Ingenieros que desean optimizar procesos de despliegue y escalabilidad en la nube.\nHe diseñado este libro para que sea accesible y práctico, centrándome en conceptos aplicados y dejando de lado teorías avanzadas que pueden ser un obstáculo al inicio. Mi objetivo es proporcionarte las herramientas y el conocimiento para que puedas enfrentarte a problemas reales en el desarrollo de software.\nAprender a manejar contenedores es una habilidad esencial para cualquier profesional en tecnología hoy en día. Es como pasar de usar un sistema tradicional, donde todo está predeterminado, a un sistema donde tienes la flexibilidad y el control total para crear lo que necesitas. Como dijo Greg Snow al referirse a otro contexto, los contenedores son como un vehículo todoterreno que te llevará a lugares donde las herramientas tradicionales no pueden llegar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#convenciones-utilizadas-en-este-libro",
    "href": "index.html#convenciones-utilizadas-en-este-libro",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.1 Convenciones Utilizadas en Este Libro",
    "text": "1.1 Convenciones Utilizadas en Este Libro\n\nCursiva: Indica términos nuevos, URLs y nombres de archivos.\nTexto de ancho fijo: Representa comandos, nombres de variables o elementos de código.\nTexto en negrita: Muestra comandos que deben ser escritos literalmente por el lector.\n\nPara realizar comentarios o preguntas técnicas sobre este libro, por favor abre un issue en github.com/tu-repositorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.2 Agradecimientos",
    "text": "1.2 Agradecimientos\nQuiero agradecer a todas las personas que me han ayudado a escribir este libro, desde mis colegas y estudiantes que han probado este contenido, hasta quienes contribuyeron con ideas y retroalimentación. También agradezco a las comunidades de Docker y Podman por proporcionar recursos invaluables y fomentar el aprendizaje continuo. Finalmente, gracias a mi familia por su apoyo incondicional durante este proceso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "prework.html",
    "href": "prework.html",
    "title": "2  First steps with Polars",
    "section": "",
    "text": "2.1 Requisitos de Docker antes de instalar.\nocker destaca por su compatibilidad entre sistemas. Las máquinas virtuales o la virtualización de hardware clásica emulan un sistema operativo invitado entero, mientras que los contenedores Docker comparten el núcleo del sistema anfitrión, ejecutándose como procesos aislados en el espacio del usuario. En sus inicios, Docker se utilizaba exclusivamente en sistemas Linux o en sistemas operativos basados en Linux. Hoy en día, el software de código abierto se caracteriza por su completa independencia de los sistemas operativos. Docker utiliza el kernel local de Linux en las variantes de 64 bits de los sistemas operativos de Linux, los sistemas que no son de Linux utilizan simplemente una imagen del sistema Linux a través de un hypervisor o una máquina virtual.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First steps with Polars</span>"
    ]
  },
  {
    "objectID": "introduccion_docker.html",
    "href": "introduccion_docker.html",
    "title": "3  Introducción a Docker",
    "section": "",
    "text": "3.0.1 Introducción\nDocker surge como una solución innovadora al problema de la virtualización tradicional, ya que en el enfoque clásico, se utilizan máquinas virtuales (VMs), las cuales requieren de un sistema operativo completo para su creación y ejecución, además de que consumen una gran cantidad de espacio y recursos, incluso si solo se necesita ejecutar una tarea específica, por lo que este enfoque en la actualidad es ineficiente y poco flexible.\nDocker se centra en solucionar este problema mediante el uso de contenedores, definidos por archivos Dockerfile. Estos archivos especifican únicamente lo necesario para que una aplicación funcione, eliminando la necesidad de instalar sistemas operativos completos, basta con tener una imagen base y las dependencias necesarias; Docker optimiza el uso del espacio y acelera en gran medida el despliegue de aplicaciones.\nUna de las principales ventajas de Docker es su portabilidad, ya que permite que las aplicaciones se ejecuten de manera consistente en diferentes sistemas operativos y entornos, como desarrollo, pruebas y producción. Esto lo convierte en una herramienta fundamental para implementar arquitecturas modernas, como los microservicios, facilitando la gestión y escalabilidad de aplicaciones complejas.\n\n\n3.0.2 ¿Qué es Docker?\nDocker es una tecnología de virtualización basada en contenedores que permite empaquetar aplicaciones junto con sus dependencias y frameworks necesarios para su ejecución, esto garantiza que las aplicaciones funcionen de manera consistente y uniforme, sin importar el entorno en el que se ejecuten, resolviendo los problemas de compatibilidad y configuración de dependencias que suelen surgir al migrar entre sistemas operativos o entornos.\n\n\n3.0.3 Componente de Docker\nDocker engine: Es el motor de Docker y se encarga de la gestión de todos los contenedores que se ejecutan en Docker.\nDocker images: Es la plantilla donde se ecuentra la aplicación, la imagen base del sistema operativo y las dependencias necesarias para la ejecución de la aplicación, estas imágenes son reutilizables y permiten crear contenedores de manera rápida y eficiente.\nDocker container: Es la ejecución de una instancia de la imagen de Docker, donde cada contenedor opera en un entorno completamente aislado, compartiendo únicamente el kernel del sistema operativo anfitrión pero manteniendo independencia en cuanto a procesos, redes y almacenamiento.\nRedes: Las redes sirven para la comunicación entre los contenedores, permitiendo que se comuniquen entre sí o con el host, por lo que existen diferentes modelos de red que son las redes de puente, las redes de host y las redes de superposición.\nVolúmenes: Los volúmenes sirven para almacenar los datos que se desea que persistan en el tiempo, es decir cuando el contenedorer termine de ejecutarse, se reinicie o se elimine, esto es ideal para manejar aplicaciones que requieren de una base de datos o almacenamiento persistente.\nDocker Hub: Es el repositorio central que utiliza Docker para que los desarrolladores puedan compartir y descargar imágenes tanto públicas como privadas, lo que facilita la colaboración y la reutilización de imágenes.\n\n\n3.0.4 Diferencias entre Docker y Máquinas Virtuales\n\n3.0.4.1 Docker\n\nLos contenedores de Docker solo comparten el núcleo del sistema operativo host.\nLos contenedores son más ligeros.\nArrancan en segundos.\nSon más portables y fáciles de gestionar.\nPresentan menos sobrecarga sobre el hardware del host.\nPermiten la ejecución de múltiples contenedores en un mismo host.\nSon ideales para aplicaciones basadas en microservicios.\n\n\n\n3.0.4.2 Máquinas Virtuales\n\nLas máquinas virtuales necesitan de la virtuaización de todo el hardware del host.\nLas máquinas virtuales ocupan gran cantidad de espacio y recursos para su creación y ejecución.\nSu arranque es lento, por lo general tardan minutos.\nSon más complejas de administrar y su portabilidad es compleja.\nPresentan mayor sobrecarga sobre el hardware del host.\nSe puede ejecutar multiples máquinas virtuales en un mismo host, pero esto requiere de más recursos.\nSon ideales para aplicaciones con una arquitectura monolítica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a Docker</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html",
    "href": "understanding_cloud_concepts.html",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "4.1 Ecosistema del Cloud Computing\nEl concepto de cloud computing está transformando la manera en que las empresas operan, permitiéndoles acceder a recursos de cómputo y almacenamiento bajo demanda, escalar sin límites y adoptar modelos de precios flexibles. Esta tecnología ha revolucionado tanto a empresas emergentes como a grandes corporaciones.\nEl ecosistema de cloud computing consta de tres principales actores:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "Consumidores de servicios: Usan aplicaciones y herramientas en la nube sin preocuparse por su ubicación o diseño.\nProveedores de servicios: Ofrecen infraestructura, aplicaciones y herramientas basadas en la nube.\nDiseñadores de servicios: Construyen herramientas o aplicaciones optimizadas para ecosistemas específicos de nube.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "4.2 Conceptos Fundamentales del Cloud Computing",
    "text": "4.2 Conceptos Fundamentales del Cloud Computing\nEl cloud computing implica la provisión de recursos compartidos como aplicaciones, almacenamiento y plataformas de desarrollo a través de estándares y automatización. Los servicios comunes incluyen:\n\nAutomatización: Procesos gestionados automáticamente para optimizar la eficiencia.\nAutoservicio: Permite a los usuarios aprovisionar recursos por sí mismos.\nElasticidad: Capacidad de ajustar automáticamente recursos según las necesidades.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-nube",
    "href": "understanding_cloud_concepts.html#modelos-de-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.3 Modelos de Nube",
    "text": "4.3 Modelos de Nube\nExisten diferentes modelos de despliegue en la nube, cada uno adaptado a distintas necesidades empresariales:\n\n4.3.1 Nube Pública\n\nDefinición: Recursos compartidos y gestionados por un proveedor externo. Los usuarios pagan por el uso bajo demanda.\nCaracterísticas:\n\nEscalabilidad masiva y elasticidad automática.\nAcceso a servicios avanzados, como análisis de datos y aprendizaje automático.\nDisponibilidad global, ideal para empresas que requieren operaciones en múltiples regiones.\n\nCasos de uso: Aplicaciones de comercio electrónico, almacenamiento masivo, pruebas y desarrollo.\n\n\n\n4.3.2 Nube Privada\n\nDefinición: Recursos dedicados y gestionados por una sola organización, ya sea internamente o a través de un proveedor externo.\nCaracterísticas:\n\nControl total sobre los recursos.\nMayor seguridad y personalización.\nCumplimiento normativo y gobernanza específica.\n\nCasos de uso: Datos sensibles, aplicaciones con requisitos legales estrictos o sistemas heredados.\n\n\n\n4.3.3 Nube Híbrida\n\nDefinición: Combina nubes públicas y privadas, permitiendo la interoperabilidad y la transferencia de datos entre ambas.\nCaracterísticas:\n\nBalanceo de cargas de trabajo entre entornos.\nFlexibilidad para mover datos según necesidades de costo, rendimiento o seguridad.\n\nCasos de uso: Migraciones graduales hacia la nube, recuperación ante desastres, análisis de datos en múltiples ubicaciones.\n\n\n\n4.3.4 Multicloud\n\nDefinición: Uso simultáneo de múltiples nubes públicas para satisfacer distintas necesidades empresariales.\nCaracterísticas:\n\nEvita la dependencia de un solo proveedor.\nFlexibilidad para aprovechar lo mejor de cada plataforma.\nGestión centralizada para controlar costos y rendimiento.\n\nCasos de uso: Desarrollo de aplicaciones en plataformas específicas o maximización de servicios según región.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-entrega",
    "href": "understanding_cloud_concepts.html#modelos-de-entrega",
    "title": "4  Comprendiendo la Nube",
    "section": "4.4 Modelos de Entrega",
    "text": "4.4 Modelos de Entrega\nLos modelos de entrega en cloud computing son fundamentales para entender cómo se ofrecen los servicios a los usuarios. Cada uno proporciona un nivel distinto de abstracción y control:\n\n4.4.1 Infraestructura como Servicio (IaaS)\n\nDefinición: Provisión de recursos básicos, como servidores virtuales, almacenamiento y redes, sobre los cuales los usuarios pueden construir sus propias aplicaciones.\nCaracterísticas:\n\nControl total sobre el sistema operativo y las aplicaciones.\nAlta flexibilidad para personalizar entornos según las necesidades.\nPago por uso, permitiendo reducir costos operativos.\n\nEjemplos de servicios: Amazon EC2, Google Compute Engine, Microsoft Azure VMs.\nCasos de uso:\n\nMigración de centros de datos físicos a la nube.\nEscenarios de desarrollo y pruebas.\nImplementación de aplicaciones personalizadas.\n\n\n\n\n4.4.2 Plataforma como Servicio (PaaS)\n\nDefinición: Provisión de una capa de abstracción que incluye herramientas de desarrollo, middleware y bases de datos, optimizada para la creación y despliegue de aplicaciones.\nCaracterísticas:\n\nEntorno preconfigurado para desarrollo rápido.\nIntegración de herramientas como frameworks y APIs.\nGestión automatizada de recursos y actualizaciones.\n\nEjemplos de servicios: Google App Engine, Microsoft Azure App Service, Heroku.\nCasos de uso:\n\nDesarrollo de aplicaciones web y móviles.\nCreación de aplicaciones en entornos colaborativos.\nEscenarios donde se busca acelerar el tiempo de desarrollo.\n\n\n\n\n4.4.3 Software como Servicio (SaaS)\n\nDefinición: Provisión de aplicaciones completas accesibles a través de internet. Los usuarios no gestionan ni la infraestructura ni las plataformas subyacentes.\nCaracterísticas:\n\nFacilidad de uso y acceso desde cualquier dispositivo.\nModelos de suscripción mensual o anual.\nAlta disponibilidad y actualizaciones automáticas.\n\nEjemplos de servicios: Google Workspace, Salesforce, Zoom.\nCasos de uso:\n\nHerramientas de colaboración y productividad.\nGestión de relaciones con clientes (CRM).\nServicios de recursos humanos y contabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "href": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.5 Ciclo de Vida de Recursos en la Nube",
    "text": "4.5 Ciclo de Vida de Recursos en la Nube\nEn contraste con los centros de datos tradicionales, la nube permite a los usuarios:\n\nAlquilar recursos bajo demanda.\nPagar únicamente por el uso real.\nLiberar recursos automáticamente cuando ya no se necesitan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "href": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "title": "4  Comprendiendo la Nube",
    "section": "4.6 Gestión de Nubes Híbridas y Multicloud",
    "text": "4.6 Gestión de Nubes Híbridas y Multicloud\nUna nube híbrida efectiva debe integrar múltiples entornos de forma automatizada y bien gestionada. Los entornos multicloud requieren visibilidad, control y capacidad para mover datos y cargas de trabajo según convenga.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "href": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "title": "4  Comprendiendo la Nube",
    "section": "4.7 Cambios en el Rol del Centro de Datos",
    "text": "4.7 Cambios en el Rol del Centro de Datos\nAunque los centros de datos no desaparecerán, la adopción de la nube les exige modernizarse. Las estrategias incluyen:\n\nVirtualización: Separar software de hardware para mejorar la eficiencia.\nNubes privadas: Crear entornos altamente automatizados con capacidades de autoservicio.\nNubes híbridas: Combinar servicios en la nube con infraestructura local.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "virtualbox and docker containers for developments.html",
    "href": "virtualbox and docker containers for developments.html",
    "title": "5  VirtualBox y Contenedores Docker para el Desarrollo",
    "section": "",
    "text": "5.0.1 Introducción\nDentro del desarrollo de software de la actualidad se requieren entornos flexibles, escalables y consistentes. La configuración manual para cada proyecto puede ser tedioso y con tendencia a errores, en especial cuando las dependencias del sistema o sus versiones de software son críticas. Para esto, existen herramientas como VirtualBox y Docker juegan un papel importante.\n\n\n5.0.2 VirtualBox:\nLa herramienta de VirtualBox nos proporciona un software de hipervisor el cual nos permite la ejecución de máquinas virtuales dentro de un sistema host o anfitrión. Cada una de estas máquinas virtuales imitan entornos completos, incluso el de los sistemas operativos, de configuraciones y de aplicaciones que se requieren para el desarrollo. Se puede usar virtualbox para realizar pruebas de software en múltiples sistemas operativos o para poner en aislamineto un entorno de desarrollo.\nGuest Additions\nDentro de los sistemas invitados como Windows y Linux, se puede instalar controladores que permitan integrar los sistemas operativos de invitado y host. Tales controladores se conocen como Guest Additions y se los puede bajar desde el sitio web de VirtualBox.\nSon instalables dentro de la máquina virtual como cualquier programa que se vaya a instalar para Windows o Linux. La integración con el host es bastante útil.\nInstalación VirtualBox\n\nDescargue VirtualBox desde el sitio web oficial.\nInstale el software utilizando el instalador proporcionado.\nInicie VirtualBox y verifique que se esté ejecutando correctamente.\n\n\n\n5.0.3 Contenedores Docker:\nLa tecnología Docker hace el uso de contenedores ligeros para poder empaquetar aplicaciones incluidas sus dependencias utilizando un solo entorno ejecutable. En contraparte con las máquinas virtuales, los contenedores tienen compartición del núcleo del sistema operativo anfitrión, permitiendoles ser más eficientes en términos de recursos. Docker ayuda a que los desarrolladores puedan crear entornos reproducibles y escalables en cuestión de segundos, haciendo fácil y fluida la colaboración y la integración continua.\nConfiguración Contenedor Docker Básico Docker nos proporciona una manera eficiente de empaquetar, enviar y poder ejecutar software. En esta parte, se analizaran los pasos básicos para crear un contenedor para el desarrollo.\n\nEscribiendo el Dockerfile:\n\nUn archivo Dockerfile específica el entorno de configuración y todos los comandos para poder tener nuestro contenedor, ejemplo:\n# Usso de ina imagen oficial de PHP\nFROM php:7.4-apache\n\n# Habilitar módulos de Apache requeridos\nRUN a2enmod userdir \\\n    && a2enmod php7.4\n\n# Copiar el archivo de configuración para Apache\nCOPY php.conf /etc/apache2/mods-available/php7.4.conf\n\n# Definir el entry point\nENTRYPOINT [\"/entrypoint.sh\"]\n\nConstruyendo el Docker Image:\n\nPara crear la imagen del contenedor se hace uso del script build.sh, ejemplo:\n#!/usr/bin/env bash\n\n# Se construye el Docker Image\n\ndocker build -t chapter2 .\n\nCorriendo el Docker Container:\n\nPara lanzar el contenedor, se hace uso del script run.sh, ejemplo:\n#!/usr/bin/env bash\n\ndocker run -d --name chapter2 chapter2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>VirtualBox y Contenedores Docker para el Desarrollo</span>"
    ]
  },
  {
    "objectID": "scaling_and_load_testing_docker_applications.html",
    "href": "scaling_and_load_testing_docker_applications.html",
    "title": "6  Escalado y Pruebas de Carga de Aplicaciones Docker",
    "section": "",
    "text": "#Autor:Pool Ochoa\nEl escalado y las pruebas de carga son esenciales para garantizar que las aplicaciones en contenedores puedan manejar el tráfico creciente de manera eficiente y continuar funcionando bajo presión. Este proceso es particularmente relevante para infraestructuras basadas en Kubernetes, donde se pueden implementar estrategias de escalado tanto manuales como automáticas.\n\n6.0.1 Escalado en Kubernetes\nKubernetes permite escalar las aplicaciones en dos niveles principales:\n1. Escalado de Pods: Incrementar o reducir el número de réplicas de una aplicación según la demanda.\n2. Escalado del Clúster: Ajustar el número de nodos disponibles en el clúster para manejar los pods adicionales cuando los recursos se limitan.\nPara automatizar el escalado, Kubernetes ofrece herramientas como:\n- Cluster Autoscaler: Escala los nodos del clúster según la carga actual.\n- Horizontal Pod Autoscaler (HPA): Ajusta el número de pods basándose en métricas como el uso de CPU.\n- Vertical Pod Autoscaler (VPA): Modifica dinámicamente las solicitudes de CPU y memoria de los pods para optimizar los recursos.\n\n\n6.0.2 Pruebas de Carga\nLas pruebas de carga evalúan cómo responde una aplicación bajo diferentes niveles de tráfico. Estas pruebas permiten identificar cuellos de botella y garantizar que los mecanismos de escalado funcionen como se espera. Herramientas como Apache Bench (ab) y k6 son comunes para realizar estas pruebas.\n\n\n6.0.3 Ejemplo 1: Escalado Horizontal de Pods\n\nConfigurar el HPA en Kubernetes con un comando como:\nkubectl autoscale deployment app-deployment --cpu-percent=50 --min=2 --max=10\nAquí, el número de pods de la aplicación se ajustará automáticamente entre 2 y 10, según el uso de CPU.\nEjecutar una prueba de carga con Apache Bench para simular tráfico:\nab -n 1000 -c 50 http://app-url/\nEsto genera 1000 solicitudes concurrentes para evaluar si los pods adicionales se crean al aumentar el uso de CPU.\n\n\n\n6.0.4 Ejemplo 2: Pruebas de Escalabilidad con k6\n\nEscribir un script de carga en JavaScript para simular usuarios concurrentes:\nimport http from 'k6/http';\n\nexport default function() {\n    http.get('http://app-url/');\n}\nEjecutar el script con 50 usuarios virtuales durante 30 segundos:\ndocker run --rm -i loadimpact/k6 run --vus 50 --duration 30s - &lt; script.js\nEsto mide el rendimiento de la aplicación y verifica si el Cluster Autoscaler añade nodos para manejar el incremento de pods.\n\nCon estas estrategias, puedes optimizar el desempeño de aplicaciones contenedorizadas y garantizar una experiencia de usuario confiable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Escalado y Pruebas de Carga de Aplicaciones Docker</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "",
    "text": "7.1 Ejecutar Docker en Producción: Muchas Rutas, Escoge Sabiamente\nIntroduce a las numerosas formas en las que se pueden desplegar aplicaciones basadas en Docker en entornos de producción. A medida que la tecnología de contenedores ha madurado, las opciones para implementarlas han crecido significativamente.\nLa ejecución de Docker en producción requiere analizar las diversas rutas disponibles, que van desde configuraciones básicas en un solo servidor hasta soluciones distribuidas con Kubernetes.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejecutar-docker-en-producción-muchas-rutas-escoge-sabiamente",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejecutar-docker-en-producción-muchas-rutas-escoge-sabiamente",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "",
    "text": "7.1.1 Aspectos importantes\n\nOrquestación de contenedores:\n\nHerramientas como Kubernetes permiten distribuir contenedores en un clúster, aumentando la tolerancia a fallos y la escalabilidad.\nGoogle desarrolló Kubernetes basándose en su experiencia con Borg, un sistema interno de orquestación.\n\nComplejidad operativa:\n\nAunque Kubernetes y otras soluciones gestionadas simplifican la orquestación, su implementación inicial puede ser desafiante.\n\nServicios gestionados como alternativa:\n\nMuchas empresas prefieren delegar la gestión de la infraestructura a proveedores en la nube para reducir la carga operativa.\n\n\nEl despliegue de Docker en producción puede variar desde configuraciones básicas hasta sistemas distribuidos complejos. La elección depende de las necesidades y prioridades del proyecto.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#cuál-es-el-entorno-de-producción-mínimo-realista",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#cuál-es-el-entorno-de-producción-mínimo-realista",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.2 ¿Cuál es el Entorno de Producción Mínimo Realista?",
    "text": "7.2 ¿Cuál es el Entorno de Producción Mínimo Realista?\nDescribe lo mínimo necesario para ejecutar una aplicación basada en Docker: un solo host con Docker y Docker Compose.\n\n7.2.1 Detalles clave\n\nConfiguración mínima:\n\nUn servidor físico o virtual que soporte Docker.\n\nCompatibilidad con sistemas operativos como Linux (Ubuntu, CentOS), macOS o Windows.\n\nLimitaciones:\n\nVulnerabilidad a fallos de hardware o conectividad.\nMenor tolerancia a fallos y escalabilidad limitada.\n\nRecomendaciones:\n\nImplementar monitoreo externo.\nTener un plan de respaldo y restauración para mitigar riesgos.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#servicios-gestionados-en-la-nube",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#servicios-gestionados-en-la-nube",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.3 Servicios Gestionados en la Nube",
    "text": "7.3 Servicios Gestionados en la Nube\nLos servicios gestionados en la nube ofrecen soluciones completas para ejecutar contenedores sin preocuparse por la infraestructura subyacente.\n\n7.3.1 Opciones destacadas\n\nGoogle Kubernetes Engine (GKE):\n\nKubernetes gestionado con soporte de Google.\nCosto competitivo y buena integración con servicios de Google Cloud.\n\nAWS Elastic Beanstalk y EKS:\n\nBeanstalk es una solución simple para principiantes, mientras que EKS es más robusto y adecuado para cargas pesadas.\n\nAzure Kubernetes Service (AKS):\n\nIntegración profunda con herramientas de Microsoft como Visual Studio Code.\n\nDigitalOcean Docker Swarm:\n\nUna solución más simple, aunque su futuro soporte es incierto.\n\n\n\n\n7.3.2 Ventajas de los servicios gestionados\n\nEscalabilidad automática.\nAlta disponibilidad.\nReducción de la complejidad operativa.\n\n\n\n7.3.3 Desafíos\n\nDependencia tecnológica (vendor lock-in).\nCostos recurrentes mayores comparados con configuraciones locales.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejecutar-tu-propio-clúster-de-kubernetes",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejecutar-tu-propio-clúster-de-kubernetes",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.4 Ejecutar tu Propio Clúster de Kubernetes",
    "text": "7.4 Ejecutar tu Propio Clúster de Kubernetes\nPara empresas que buscan mayor personalización o control, ejecutar Kubernetes en infraestructura propia es una opción viable.\n\n7.4.1 Beneficios\n\nControl completo sobre actualizaciones y configuraciones.\nIntegración con soluciones híbridas o privadas como OpenStack o VMware Tanzu.\nPosibilidad de ejecutar Kubernetes en entornos especializados (bare-metal o Raspberry Pi).\n\n\n\n7.4.2 Desafíos\n\nComplejidad técnica y operativa significativa.\nRequiere mayor inversión inicial y habilidades avanzadas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#decidiendo-la-configuración-de-producción-más-adecuada",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#decidiendo-la-configuración-de-producción-más-adecuada",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.5 Decidiendo la Configuración de Producción Más Adecuada",
    "text": "7.5 Decidiendo la Configuración de Producción Más Adecuada\nEsta sección proporciona una guía para elegir la mejor estrategia de despliegue según factores clave.\n\n7.5.1 Factores a considerar\n\nFacilidad de configuración:\n\nQué tan rápido se puede implementar desde un entorno de desarrollo local.\n\nCostos:\n\nCostos iniciales y recurrentes.\n\nElasticidad:\n\nCapacidad para escalar de manera automática o manual según la demanda.\n\nSoporte:\n\nAcceso a asistencia técnica, ya sea comercial o comunitaria.\n\nDisponibilidad:\n\nRobustez frente a fallos de hardware, red o servicio.\n\nAdhesividad:\n\nFacilidad para cambiar la infraestructura a otra solución si es necesario.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejemplo-de-aplicación-shipit-clicker",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejemplo-de-aplicación-shipit-clicker",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.6 Ejemplo de Aplicación: ShipIt Clicker",
    "text": "7.6 Ejemplo de Aplicación: ShipIt Clicker\nEl prototipo del juego “ShipIt Clicker” sirve como ejemplo práctico para experimentar con Docker y Docker Compose.\n\n7.6.1 Componentes del juego\n\nFrontend: Una interfaz simple basada en HTML.\nBackend: Un servidor Node.js con Express.\nBase de datos: Redis para manejar datos.\n\n\n\n7.6.2 Tareas sugeridas\n\nEjecutar docker-compose up para probarlo en un entorno local.\nIdentificar mejoras para optimizar su despliegue en producción.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejercicios-propuestos",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#ejercicios-propuestos",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.7 Ejercicios Propuestos",
    "text": "7.7 Ejercicios Propuestos\n\n7.7.1 Evaluar Alternativas Razonables de Despliegue\nComparar configuraciones iniciales con soluciones más avanzadas, estimar costos y beneficios a corto y largo plazo.\n\n\n7.7.2 Evaluar Dockerfile y docker-compose.yml\nRevisar configuraciones actuales para optimizar la aplicación, ajustando la base del contenedor (FROM) y mejorando escalabilidad y seguridad.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#conclusion",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#conclusion",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.8 Conclusion",
    "text": "7.8 Conclusion\n\nLas estrategias de despliegue tienen compensaciones entre costos, complejidad y capacidades.\nLas configuraciones mínimas son útiles para comenzar, pero deben evolucionar con el tiempo.\nComprender las ventajas y desventajas de cada solución es esencial para elegir la estrategia adecuada.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#tema-de-la-exposición-qué-es-docker-swarm",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#tema-de-la-exposición-qué-es-docker-swarm",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.9 Tema de la exposición, ¿Qué es Docker Swarm?",
    "text": "7.9 Tema de la exposición, ¿Qué es Docker Swarm?\nDocker Swarm es una herramienta de orquestación de contenedores que permite gestionar y escalar aplicaciones distribuidas en varios nodos mediante la creación de clústeres. Sus características principales incluyen:\n\nAlta disponibilidad y tolerancia a fallos.\nEscalabilidad vertical y horizontal.\nBalanceo de carga para distribuir el tráfico uniformemente.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#arquitectura",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#arquitectura",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.10 Arquitectura",
    "text": "7.10 Arquitectura\n\n7.10.1 Clúster\nConjunto de nodos que trabajan juntos.\n\n\n7.10.2 Nodos\n\nManager: Coordina servicios y gestiona configuraciones.\nWorker: Ejecuta tareas asignadas.\n\n\n\n7.10.3 Servicios\nDefinen las aplicaciones y políticas de estado.\n\n\n7.10.4 Tareas\nInstancias de servicios ejecutadas en nodos.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#comandos-básicos",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#comandos-básicos",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.11 Comandos básicos",
    "text": "7.11 Comandos básicos\n\n7.11.1 Crear un clúster\ndocker swarm init --advertise-addr &lt;IP-del-host&gt;\n\n\n7.11.2 Agregar nodos al clúster\ndocker swarm join --token &lt;token&gt; &lt;IP-del-host&gt;\n\n\n7.11.3 Revisar nodos\ndocker node ls\n\n\n7.11.4 Desplegar servicios\ndocker service create --name &lt;nombre_servicio&gt; --replicas &lt;número&gt; -p &lt;puerto:puerto&gt; &lt;imagen&gt;\n\n\n7.11.5 Gestionar máquinas virtuales con Docker Machine\n\nCrear nodos virtuales:\ndocker-machine create --driver virtualbox &lt;nombre_nodo&gt;\nConectar a nodos:\ndocker-machine ssh &lt;nombre_nodo&gt;\nSalir del nodo:\nexit",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#comparativa-docker-swarm-vs.-kubernetes",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#comparativa-docker-swarm-vs.-kubernetes",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.12 Comparativa Docker Swarm vs. Kubernetes",
    "text": "7.12 Comparativa Docker Swarm vs. Kubernetes\n\n\n\n\n\n\n\n\nCaracterística\nKubernetes\nDocker Swarm\n\n\n\n\nEscalabilidad\nAlta\nMedia\n\n\nFacilidad de uso\nComplejo, amplio soporte\nSencillo y fácil\n\n\nGestión de despliegues\nAvanzada\nBásica\n\n\nGestión de redes\nComplejo, con plugins\nBásica\n\n\nIntegración con ecosistema\nAmplia\nIntegrada con Docker\n\n\nActualizaciones\nSoporte avanzado\nLimitado",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#casos-de-uso",
    "href": "Alternatives_for_Deploying_and_Running_Containers_in_Production.html#casos-de-uso",
    "title": "7  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "7.13 Casos de uso",
    "text": "7.13 Casos de uso\n\nAplicaciones web: Despliegue escalable y tolerante a fallos.\nMicroservicios: Gestión de aplicaciones complejas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html",
    "href": "deploying_docker_compose.html",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "",
    "text": "8.1 Requisitos para su implementación.\nEl escenario de implementación práctico más simple posible de una aplicación empaquetada con Docker implica ejecutar Docker Compose en un solo host, sin embargo, tiene algunas desventajas importantes en términos de rendimiento y disponibilidad.\nPara continuar con la implementación, necesitará una computadora que ejecute un sistema operativo Linux moderno de la misma arquitectura que su sistema de desarrollo, con suficiente memoria, procesador y capacidad de almacenamiento para ejecutar su aplicación.\nDeberá tener alguno de estos sistemas operativos linux que admitan Docker:  - Red Hat\n- Ubuntu 16.04 o superior\n- Amazon Linux 2\n- Debian\no alguna distribución centrada en Docker como Container Linux o CoreOS.\nAdemás, antes de configurar el software en el host, debe asegurarse de que tenga una dirección IP estable. A veces, se las denomina direcciones IP estáticas o direcciones IP elásticas en un contexto de AWS.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "href": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "8.2 Implementación mediante archivos de configuración y scripts de soporte.",
    "text": "8.2 Implementación mediante archivos de configuración y scripts de soporte.\nPara implementar nuestra aplicación en un servidor de producción, utilizaremos una combinación de comandos simples y scripts de soporte que inician o actualizan el conjunto de contenedores en ejecución. Comencemos por analizar en detalle los dos archivos más importantes necesarios para la implementación: Dockerfile y docker­compose.yml.\nEste es un ejemplo de Dockerfile basado en la producción de un juego, deberás adaptar tu Dockerfile según las necesidades de tu aplicación: FROM alpine:20191114\nRUN apk update &&\napk add nodejs nodejs-npm\nRUN addgroup -S app && adduser -S -G app app\nRUN mkdir -p /app/public /app/server\nADD src/package.json* /app/\nWORKDIR /app\nRUN npm -s install\nCOPY src/public/ /app/public/\nCOPY src/server/ /app/server/\nCOPY src/.babelrc /app/\nRUN npm run compile\nUSER app\nEXPOSE 3000\nENTRYPOINT [“npm”, “start”]\n\nEste es un ejemplo de un archivo de docker-compose:\nversion: ‘3’\nservices:\nshipit-clicker-web-v2:\nbuild: .\nenvironment:\n- APP_ID=shipit-clicker-v2\n- OPENAPI_SPEC=/api/v1/spec\n- OPENAPI_ENABLE_RESPONSE_VALIDATION=false\n- PORT=3000\n- LOG_LEVEL={LOG_LEVEL:-debug}\n- REQUEST_LIMIT=100kb\n- REDIS_HOST=\\({REDIS_HOST:-redis} \\\n- REDIS_PORT=\\){REDIS_PORT:-6379}\n- SESSION_SECRET=${SESSION_SECRET:-mySecret-v2}\n\nAhora, es necesario definir una configuración de red para el contenedor principal para luego vincularlos a los demás contenedores. Un ejemplo es: ports: - {PORT:-3006}:3000\nnetworks:\n- private-redis-shipit-clicker-v2\nlinks:\n- redis\ndepends_on:\n- redis\n\nAhora bien, al ejecutar un sitio en producción, es posible que deba realizar algunas operaciones con frecuencia como reiniciarlo o actualizarlo. Para resolver esto puede agregar scripts con el objetivo de automatizar procesos, los más comunes son aquellos para reiniciar la aplicación y implementar cambios.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación",
    "href": "deploying_docker_compose.html#implementación",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "8.3 Implementación",
    "text": "8.3 Implementación\nPara iniciar los servicios en segundo plano, use el siguiente comando: $ docker-compose up -d\nVerifique que los servicios se están ejecutando con: $ docker-compose ps\nCompruebe si los registros del sistema muestran algún error: $ docker-compose logs\nMientras no veas una secuencia de mensajes de error en los registros, deberías poder acceder al sitio web en la dirección IP del servidor (por ejemplo, en http://192.0.2.10)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "href": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "8.4 Limitaciones de implementación en un solo host",
    "text": "8.4 Limitaciones de implementación en un solo host\nSi el contenedor del servidor de base de datos o el contenedor del servicio web fallan y no se pueden reiniciar automáticamente, el sitio no funcionará y será necesaria una intervención manual. La solución puede ser tan simple como conectarse por SSH y reiniciar el servidor. Pero, a veces, un solo servidor tendrá tan poca memoria que deberá reiniciarse manualmente desde una consola de nivel superior o incluso apagar y encender manualmente.\nDependiendo de su proveedor de alojamiento, el sistema operativo base con el que comience y cómo estén configurados los contenedores Docker, puede experimentar inestabilidad que sea difícil de rastrear. Tal vez su host se reinicie con frecuencia debido a que la red del proveedor detecta hardware inestable o condiciones de red inestables. Tal vez haya configurado su sistema operativo para instalar actualizaciones automáticas y aplicarlas provoque períodos de interrupciones. Tal vez la aplicación crezca en la memoria hasta que provoque una falla de algún tipo.\nSi ha alojado su aplicación en un único servidor físico o virtual, debe asegurarse de realizar copias de seguridad del sistema con regularidad, la pérdida del host podría provocar que se pierda toda la información.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html",
    "href": "Continuous_Deployment_with_Jenkins.html",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "",
    "text": "9.1 Uso de Jenkins para facilitar el despliegue continuo\nEl despliegue continuo (CD) es necesario para garantizar la calidad y velocidad en el desarrollo de software. Este proceso automatiza la construcción, pruebas y despliegue de cambios en aplicaciones, minimizando errores humanos y conflictos dentro de los equipos. Jenkins se presenta como una herramienta ideal para implementar CD gracias a su flexibilidad, soporte para plugins y capacidad de integración con servicios populares como Docker y GitHub.\nJenkins se ha convertido en una herramienta popular por su capacidad de adaptarse a multiples casos de uso. Entre sus características principales se destacan las siguientes:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html#uso-de-jenkins-para-facilitar-el-despliegue-continuo",
    "href": "Continuous_Deployment_with_Jenkins.html#uso-de-jenkins-para-facilitar-el-despliegue-continuo",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "",
    "text": "Pipeline definido por código: Los pipelines en Jenkins se describen en un archivo Jenkinsfile, lo que permite control de versiones y reproducibilidad.\nCompatibilidad con Docker: Jenkins puede contruir imágenes Docker, subirlas a respositrios como Docker Hub y desplegarlas de manera automática.\nPlugins extensivo: Permite integrar servicios como GitHub, Docker, y credenciales de SSH para automatizar flujos de trabajos.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html#configuracion-de-un-servidor-jenkins",
    "href": "Continuous_Deployment_with_Jenkins.html#configuracion-de-un-servidor-jenkins",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "9.2 Configuracion de un servidor Jenkins",
    "text": "9.2 Configuracion de un servidor Jenkins\nPara asegurar un funcionamiento óptimo de Jenkins, se deben seguir ciertas recomendaciones:\n\n9.2.1 Lo que se debe evitar:\n\nEjecutar Jenkins en servidores de producción debido al riesgo de conflictos.\nUsar estaciones de trabajo locales, ya que tienen recursos limitados y problemas de accesibilidad.\nConfigurar Jenkins como un contenedor Docker inicialmente, debido a la complejidad técnica requerida\n\n\n\n9.2.2 Recomendaciones:\n\nUtilizar un servidor dedicado o aprovechar uno ya existente en la organizacion.\n\n\n\n9.2.3 Pasos para la configuracion\n\nInstalar Docker y Jenkins en un servidor adecuado.\nConfigurar el firewall para permitir trafico en los puertos 80 y 443.\nProteger la instalacion con HTTPS y restringir el acceso por IP.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html#jenkinsfile-y-conectividad-del-host",
    "href": "Continuous_Deployment_with_Jenkins.html#jenkinsfile-y-conectividad-del-host",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "9.3 Jenkinsfile y conectividad del host",
    "text": "9.3 Jenkinsfile y conectividad del host\nEl Jenkinsfile es un script escrito en Groovy que define los pasos para construir, probar y desplegar aplicaciones. Este archivo, almacenado en un repositorio de control de versiones como GitHub, es clave para garantizar la reproducibilidad de los procesos.\n\nPrueba básica: Crear un pipeline que ejecute un contenedor Docker y muestre “Hello, World” en la consola. Esto valida la conectividad y configuración de Jenkins con el servidor de destino.\nConectividad del host: Configurar Jenkins para interactuar con los servidores de producción y prueba mediante SSH, usando claves generadas específicamente para este propósito.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html#cambios-de-configuracion-a-traves-de-jenkins",
    "href": "Continuous_Deployment_with_Jenkins.html#cambios-de-configuracion-a-traves-de-jenkins",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "9.4 Cambios de configuracion a traves de Jenkins",
    "text": "9.4 Cambios de configuracion a traves de Jenkins\nJenkins facilita la gestión de cambios en entornos de producción mediante la integración con Docker y GitHub:\n\nConstrucción de imágenes Docker: Jenkins puede construir automáticamente imágenes Docker basadas en cambios en el código fuente y subirlas a Docker Hub.\nAutomatización del despliegue: Scripts en el Jenkinsfile conectan Jenkins al servidor de producción vía SSH,lo que permite desplegar cambios de manera automatizada.\nSeguridad: Uso de credenciales seguras, como claves SSH y tokens de acceso, ayudan para proteger la interacción con servidores y repositorios.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html#despliegue-en-múltiples-entornos-con-varias-ramas",
    "href": "Continuous_Deployment_with_Jenkins.html#despliegue-en-múltiples-entornos-con-varias-ramas",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "9.5 Despliegue en múltiples entornos con varias ramas",
    "text": "9.5 Despliegue en múltiples entornos con varias ramas\nPara garantizar la calidad antes del despliegue en producción, se pueden configurar entornos adicionales, como staging: Entorno de staging:\n\nReplica las condiciones del entorno de producción.\nConfiguración en un servidor separado, con acceso controlado mediante SSH. Gestión de ramas en Git:\nCambios en la rama staging activan despliegues automáticos en el entorno de prueba.\nCambios en la rama master activan despliegues en producción.\n\nVariables de entorno en Jenkins:\n\nFacilitan configuraciones específicas para cada entorno, reduciendo la necesidad de múltiples scripts.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "Continuous_Deployment_with_Jenkins.html#complejidad-y-límites-al-escalar-despliegues",
    "href": "Continuous_Deployment_with_Jenkins.html#complejidad-y-límites-al-escalar-despliegues",
    "title": "9  Continuous Deployment with Jenkins",
    "section": "9.6 Complejidad y límites al escalar despliegues",
    "text": "9.6 Complejidad y límites al escalar despliegues\nAunque Jenkins es adecuado para proyectos pequeños y medianos, presenta desafíos al escalar:\n\nGestión de múltiples entornos: Manejar más servidores o aplicaciones requiere scripts más complejos y recursos adicionales.\nScripts complicados: La combinación de Groovy y Bash puede dificultar la implementación para equipos sin experiencia.\nAlternativas: Herramientas como Spinnaker, CodeFresh o Kubernetes ofrecen flujos de trabajo más optimizados para proyectos grandes o con requisitos avanzados.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Continuous Deployment with Jenkins</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html",
    "href": "sharing_containers_used_docker_hub.html",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "10.1 ¿Qué es Docker Hub?\nDocker Hub es una plataforma centralizada que permite a los desarrolladores almacenar, compartir y gestionar imágenes de contenedores. Es el repositorio oficial de Docker, donde se pueden encontrar imágenes públicas y privadas, facilitando la colaboración y la reutilización de contenedores en diferentes entornos.\nDocker Hub es un servicio basado en la nube que proporciona un registro de imágenes de Docker. Permite a los desarrolladores:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "Almacenar Imágenes: Guardar imágenes de contenedores en un lugar centralizado.\nCompartir Imágenes: Hacer que las imágenes estén disponibles para otros desarrolladores.\nAutomatizar Builds: Configurar pipelines de CI/CD para construir y desplegar imágenes automáticamente.\nGestionar Repositorios: Organizar imágenes en repositorios públicos o privados.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.2 Beneficios de Usar Docker Hub",
    "text": "10.2 Beneficios de Usar Docker Hub\n\nColaboración: Facilita el trabajo en equipo al permitir compartir imágenes de contenedores fácilmente.\nReutilización: Permite reutilizar imágenes existentes, ahorrando tiempo y esfuerzo en la configuración de entornos.\nDistribución: Facilita la distribución de aplicaciones y servicios en diferentes entornos y plataformas.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.3 Pasos para Compartir Contenedores en Docker Hub",
    "text": "10.3 Pasos para Compartir Contenedores en Docker Hub\n\nCrear una Cuenta en Docker Hub: Regístrate en Docker Hub para crear una cuenta gratuita.\nIniciar Sesión desde la Línea de Comandos: Usa el comando docker login para iniciar sesión en Docker Hub desde tu terminal.\nConstruir una Imagen de Docker: Crea una imagen de Docker usando un Dockerfile y el comando docker build.\nEtiquetar la Imagen: Etiqueta la imagen con tu nombre de usuario de Docker Hub y el nombre del repositorio.\nSubir la Imagen a Docker Hub: Usa el comando docker push para subir la imagen etiquetada a Docker Hub.\nCompartir la Imagen: Comparte el enlace del repositorio de Docker Hub con otros desarrolladores para que puedan descargar y usar la imagen.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "href": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.4 Ejemplo Práctico",
    "text": "10.4 Ejemplo Práctico\nA continuación, se muestra un ejemplo práctico de cómo compartir una imagen de contenedores en Docker Hub:\n\nConstruir la Imagen: sh docker build -t myapp:late  st .\nEtiquetar la Imagen: sh docker tag myapp:latest your-dockerhub-username/myapp:latest\nIniciar Sesión en Docker Hub: sh docker login\nSubir la Imagen: sh docker push your-dockerhub-username/myapp:latest\nCompartir el Enlace: Comparte el enlace https://hub.docker.com/r/your-dockerhub-username/myapp con otros desarrolladores.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "href": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.5 Consideraciones de Seguridad",
    "text": "10.5 Consideraciones de Seguridad\n\nImágenes Privadas: Si no deseas que tus imágenes sean públicas, puedes configurar repositorios privados en Docker Hub.\nAutenticación: Asegúrate de usar autenticación segura y gestionar tus credenciales de Docker Hub de manera adecuada.\nActualizaciones: Mantén tus imágenes actualizadas para incluir las últimas mejoras y parches de seguridad.\n\nAl finalizar este capítulo, tendrás las habilidades necesarias para compartir tus contenedores con otros desarrolladores y utilizar imágenes de contenedores de la comunidad, mejorando así tu flujo de trabajo y la colaboración en proyectos.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html",
    "title": "11  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "",
    "text": "11.1 Registro de Docker y registro de tiempo de ejecución de contenedores\nPara entender el comportamiento de una aplicación en producción, los desarrolladores y operadores confían en herramientas de registro, monitoreo y alertas, las cuales permiten identificar si el sistema funciona correctamente y facilitan la solución de problemas cuando surgen inconvenientes. Con la creciente complejidad de los sistemas, aumenta la necesidad de una observabilidad más profunda sin alterar el código, en este apartado se vera el cómo instrumentar aplicaciones y entornos para mejorar la observabilidad, incluyendo el uso de Kubernetes, CloudWatch, S3, Prometheus y Grafana para gestionar registros, métricas y alertas, así como explorar datos específicos de código y base de datos con Jaeger.\nCada contenedor Docker, ya sea que se ejecute localmente o en la nube, produce sus propios registros los cuales se puede consultar. en el caso de Kubernetes cada contenedor Docker en un pod genera registros, que el sistema almacena temporalmente hasta 10 MB por contenedor, estos registros se pueden consultar con la herramienta kubectl logs, pero son eliminados cuando un pod se elimina o un contenedor se reinicia, lo que impide su retención permanente, esto puede dificultar la solución de problemas si los registros necesarios ya no están disponibles. Por ello, es importante considerar soluciones que superen estas limitaciones y mejoren la gestión y retención de registros.\nUn sistema de gestión de registros ideal debe incluir características como la visualización centralizada de mensajes, baja latencia para acceder a eventos recientes, recopilación de registros de diversas fuentes (pods, nodos, despliegues y contenedores Docker en Kubernetes), una interfaz de búsqueda intuitiva con opciones para guardar consultas, visualización de histogramas interactivos para explorar datos, alertas basadas en el contenido de los registros y la posibilidad de configurar el tiempo de retención de los mensajes.\nAlgunos de los sistemas de gestion de registros de terceros, son:\nEn cuanto a proveedores en la nube, existen:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#registro-de-docker-y-registro-de-tiempo-de-ejecución-de-contenedores",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#registro-de-docker-y-registro-de-tiempo-de-ejecución-de-contenedores",
    "title": "11  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "",
    "text": "Splunk\nElasticsearch\nLoggly\nPapertrail\n\n\n\nAWS CloudWatch\nGoogle Cloud Logging\nMicrosoft Azure Monitor Logs",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-liveness-readiness-y-startup-en-kubernetes",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-liveness-readiness-y-startup-en-kubernetes",
    "title": "11  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "11.2 Uso de las sondas de Liveness, Readiness y Startup en Kubernetes",
    "text": "11.2 Uso de las sondas de Liveness, Readiness y Startup en Kubernetes\nKubernetes tiene varios tipos de controles de salud, llamados sondas , para garantizar que los contenedores que maneja Docker están en condiciones de procesar el tráfico. Los tipos de sondas abordan inquietudes como:\n\nLiveness: Determina si una aplicación puede procesar solicitudes\nReadiness: Determina si un contenedor está listo para recibir tráfico real, especialmente si depende de recursos externos que tienen que ser accesibles.\nStartup: Determina si un contenedor está listo para empezar a tomar los otros dos tipos de tráfico, destinado a aplicaciones heredadas de inicio lento para darles tiempo para iniciarse.\n\n\n11.2.1 Usar una sonda Liveness para ver si un contenedor puede responder\nA continuación, se muestra un fragmento de configuración YAML, el cual define una sonda de “liveness” para un contenedor en Kubernetes, utilizada para verificar si el contenedor está funcionando correctamente\nlivenessProbe:\nhttpGet:\npath: /\nport: http\nUna sonda de liveness es importante porque permite que Kubernetes detecte si el contenedor está en un estado no funcional. Si la sonda falla, Kubernetes reiniciará el contenedor automáticamente para intentar restaurar su funcionalidad.\n\n\n11.2.2 Usar una sonda Readiness para garantizar que un servicio pueda recibir trafico\nEl uso de una sonda de readiness en Kubernetes asegura que una aplicación esté completamente lista para manejar tráfico antes de ser incluida en el balanceador de carga del clúster.\nreadinessProbe:\nhttpGet:\npath: /api/v2/games/ready\nport: http\nEste fragmento de configuración YAML define una sonda de “readiness” en Kubernetes, que se utiliza para determinar si un contenedor está listo para aceptar tráfico.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#recopilación-de-métricas-y-envío-de-alertas-con-prometheus",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#recopilación-de-métricas-y-envío-de-alertas-con-prometheus",
    "title": "11  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "11.3 Recopilación de métricas y envío de alertas con Prometheus",
    "text": "11.3 Recopilación de métricas y envío de alertas con Prometheus\nPrometheus es una herramienta clave en Kubernetes para recopilar y analizar métricas del sistema. Recoge datos sobre el uso de CPU, almacenamiento y estado de las aplicaciones, entre otros, a través de endpoints como /metrics. Funciona consultando estos puntos y almacenando la información con etiquetas y marcas de tiempo para facilitar su búsqueda, también permite crear alertas y visualizar el rendimiento, ayudando a los operadores a monitorear y mejorar la salud del sistema. Si bien Prometheus puede representar gráficamente los resultados de las consultas por sí solo, los usuarios de Kubernetes suelen utilizar Grafana en conjunto con Prometheus para proporcionar gráficos más sofisticados y tableros de instrumentos.\n\n11.3.1 Recopilación de métricas\n\nModelo de recolección (Pull): Prometheus utiliza un modelo de “pull” para obtener datos, es decir, periódicamente consulta endpoints HTTP expuestos por las aplicaciones y servicios para recopilar métricas.\nEndpoint estándar: Generalmente, las métricas están disponibles en el endpoint /metrics.\nDatos recopilados: Incluyen el uso de CPU, memoria, almacenamiento, estado de las aplicaciones, entre otros.\nInstrumentación de aplicaciones Las aplicaciones se instrumentan para exponer sus métricas, esto se logra utilizando bibliotecas específicas de Prometheus disponibles para varios lenguajes de programación como Python, Java, entre otros.\nIntegración con Kubernetes: En un clúster de Kubernetes: Anotaciones: Recursos como pods y DaemonSets usan anotaciones para indicar a Prometheus qué endpoints consultar.\nNode Exporter: Un DaemonSet llamado node_exporter se ejecuta en cada nodo para exponer métricas específicas del sistema, como el uso del disco o la carga del CPU.\nEtiquetas y almacenamiento: Prometheus asocia cada métrica con: Un nombre descriptivo. Etiquetas en formato clave-valor Una marca de tiempo precisa a nivel de milisegundos.\n\nEstas características permiten almacenar métricas de manera eficiente y realizar consultas rápidas en su base de datos de series temporales.\n\n\n11.3.2 Envío de alertas\n\nAdministrador de alertas: Prometheus incluye Alertmanager, un componente que gestiona las alertas generadas a partir de las reglas definidas en Prometheus.\nReglas de alerta: Se configuran en archivos YAML y definen condiciones específicas para generar alertas.\nCanales de notificación: Alertmanager puede enviar alertas a múltiples canales, como correo electrónico, Slack, Microsoft Teams o PagerDuty.\nFlujo de trabajo de alertas Prometheus evalúa las métricas recolectadas en tiempo real según las reglas definidas, cuando una condición se cumple, Prometheus envía la alerta a Alertmanager, el cual agrupa, silencia o enruta las alertas a los destinatarios según las configuraciones definidas.\nVisualización de métricas para prevenir alertas: Herramientas como Grafana suelen integrarse con Prometheus para proporcionar dashboards interactivos, estos permiten monitorear tendencias y detectar posibles problemas antes de que se generen alertas.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#visualización-de-datos-operativos-con-grafana",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#visualización-de-datos-operativos-con-grafana",
    "title": "11  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "11.4 Visualización de datos operativos con Grafana",
    "text": "11.4 Visualización de datos operativos con Grafana\nGrafana se instala y está disponible a través de un LoadBalancer en Kubernetes, que en EKS utiliza un Elastic Load Balancer de AWS. Una vez que se ingresa a la consola de Grafana, se puede explorar los paneles y consultar datos con Prometheus, aunque algunos paneles, como el de “Kubernetes All nodes”, podrían no mostrar toda la información, para solucionar eso se puede agregar paneles de la comunidad con estadísticas más completas, para ello es necesario revisar el panel de “Kubernetes pods”, aqui se puede ajustae el rango de tiempo para observar datos de un día o una semana, además, se puede hacer zoom en áreas específicas para analizar detalles.\nGrafana ofrece una variedad de paneles tanto oficiales como de la comunidad en su sitio web, para añadir uno, se puede usar la opción “Importar” e ingresar un ID de panel o una URL. Algunos paneles recomendados son:\n\nCluster Monitoring para Kubernetes : Muestra el consumo de CPU, memoria y recursos de red por los pods.\nKubernetes Cluster (Prometheus) : Presenta métricas críticas del clúster.\n1 Node Exporter for Prometheus Dashboard ES : Proporciona métricas detalladas de CPU, disco y red del clúster.\nNode Exporter Full : Muestra todas las métricas posibles de Prometheus.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#monitoreo-del-rendimiento-de-aplicaciones-con-jaeger",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#monitoreo-del-rendimiento-de-aplicaciones-con-jaeger",
    "title": "11  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "11.5 Monitoreo del rendimiento de aplicaciones con Jaeger",
    "text": "11.5 Monitoreo del rendimiento de aplicaciones con Jaeger\nJaeger es un marco de seguimiento de aplicaciones de código abierto que permite a los desarrolladores y operadores del sistema recopilar información de una aplicación en ejecución y determinar cómo la aplicación pasa su tiempo y cómo interactúa con otros componentes del sistema distribuido, utilizando la API OpenTracing.\n\n11.5.1 Componentes de Jaeger\nAlgunos de los componentes importantes que conforman el ecosistema de Jaeger son los siguientes:\n\nLas librerías cliente disponibles como paquetes o directamente desde GitHub\nLos agentes Jaeger, utilizados para escuchar los spans\nEl recolector, encargado de agregar los datos enviados desde los agentes\nJaeger query, para analizar los datos a través de una interfaz de usuario\nEl Ingester, que nos permite recopilar datos de temas Kafka y luego escribir los datos a servicios como AWS Elasticsearch.\n\nLo que vimos anteriormente es cómo instalar Jaeger localmente, sin embargo, también es posible desplegarlo en un entorno de Kubernetes utilizando Kubernetes Operator, que es un recurso especializado para gestionar la instalación y operación de aplicaciones complejas. Para instalar Jaeger en Kubernetes, se puede seguir las instrucciones del repositorio oficial y ejecutar los comandos kubectl proporcionados. Esto incluye la creación del espacio de nombres del operador y la configuración de los permisos adecuados a través de una vinculación de roles, lo que garantiza que Jaeger funcione correctamente en todos los espacios de nombres del clúster.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html",
    "href": "introduccion_container_security.html",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "",
    "text": "12.1 1. Usa Imágenes de Confianza\nLa seguridad es un tema clave cuando trabajamos con contenedores. Sí, los contenedores son geniales: son ligeros, rápidos y súper prácticos para desarrollar y desplegar aplicaciones. Pero ojo, no son mágicos ni infalibles. Si no los cuidas, pueden convertirse en un dolor de cabeza.\nEntonces, ¿qué debemos saber para mantener nuestros contenedores seguros? Aquí van lo básicos:\nPiensa en las imágenes como los cimientos de tu contenedor. Si construyes sobre una base débil (o peor, comprometida), tu aplicación estará en peligro. Descarga imágenes solo de repositorios oficiales como Docker Hub o crea las tuyas asegurándote de que todo lo que incluyes sea seguro.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html#mantén-tus-imágenes-actualizadas",
    "href": "introduccion_container_security.html#mantén-tus-imágenes-actualizadas",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "12.2 2. Mantén tus Imágenes Actualizadas",
    "text": "12.2 2. Mantén tus Imágenes Actualizadas\n¿Sabías que las imágenes pueden tener vulnerabilidades? Por eso, es importante mantenerlas actualizadas. Un simple docker pull puede ahorrarte dolores de cabeza al garantizar que estás usando la versión más reciente y segura.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html#no-ejecutes-contenedores-como-root",
    "href": "introduccion_container_security.html#no-ejecutes-contenedores-como-root",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "12.3 3. No Ejecutes Contenedores como Root",
    "text": "12.3 3. No Ejecutes Contenedores como Root\nSí, es tentador porque es más fácil, pero ejecutar un contenedor con privilegios de root puede ser peligroso. Si un atacante logra acceder al contenedor, tendrá control absoluto. Mejor crea un usuario con menos permisos.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html#define-recursos-con-límites",
    "href": "introduccion_container_security.html#define-recursos-con-límites",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "12.4 4. Define Recursos con Límites",
    "text": "12.4 4. Define Recursos con Límites\nSin límites, tus contenedores podrían usar toda la memoria o CPU de tu sistema, afectando a otras aplicaciones. Usa opciones como --memory y --cpu-shares para mantener todo bajo control.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html#escanea-tus-imágenes",
    "href": "introduccion_container_security.html#escanea-tus-imágenes",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "12.5 5. Escanea tus Imágenes",
    "text": "12.5 5. Escanea tus Imágenes\nHerramientas como Trivy o Docker Scan pueden analizar tus imágenes en busca de vulnerabilidades. No cuesta nada usarlas y te pueden salvar de sorpresas.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html#configura-redes-de-forma-segura",
    "href": "introduccion_container_security.html#configura-redes-de-forma-segura",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "12.6 6. Configura Redes de Forma Segura",
    "text": "12.6 6. Configura Redes de Forma Segura\nNo conectes tus contenedores directamente a Internet sin una buena razón. Usa redes privadas de Docker para mantener tus servicios aislados y protegidos.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "introduccion_container_security.html#mantén-docker-actualizado",
    "href": "introduccion_container_security.html#mantén-docker-actualizado",
    "title": "12  Introducción a la Seguridad de los Contenedores",
    "section": "12.7 7. Mantén Docker Actualizado",
    "text": "12.7 7. Mantén Docker Actualizado\nDocker lanza actualizaciones no solo para nuevas funcionalidades, sino también para corregir problemas de seguridad. Asegúrate de usar siempre la última versión.\n\nEstos son solo algunos de los principios básicos para empezar. Recuerda: los contenedores no son automáticamente seguros. Pero con buenos hábitos y herramientas adecuadas, puedes mantenerlos protegidos y confiables. ¡Manos a la obra! 🚀",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la Seguridad de los Contenedores</span>"
    ]
  },
  {
    "objectID": "Docker_Security_Fundamentals_and_Best_Practices.html",
    "href": "Docker_Security_Fundamentals_and_Best_Practices.html",
    "title": "13  Seguridad de Docker, Fundamentos y Mejores prácticas",
    "section": "",
    "text": "13.1 Introducción\nEn el desarrollo moderno de software, Docker se ha convertido en una herramienta esencial para la creación y gestión de contenedores. Su capacidad para empaquetar aplicaciones junto con sus dependencias garantiza consistencia en entornos de desarrollo, pruebas y producción. Sin embargo, el uso de contenedores plantea desafíos relacionados con la seguridad y las buenas prácticas de implementación.\nEste documento explora los fundamentos de la seguridad en Docker y las mejores prácticas recomendadas para garantizar la protección de las imágenes y los contenedores. Se analizarán técnicas como el uso de imágenes base mínimas, restricciones de privilegios en contenedores y herramientas como DOCKER_CONTENT_TRUST para verificar la integridad de las imágenes. Además, se destacarán métodos para minimizar riesgos durante la construcción y despliegue de contenedores.\nEl objetivo es proporcionar una guía práctica para desarrollar y operar aplicaciones en entornos de contenedores de manera segura, optimizando el uso de Docker en escenarios reales.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Seguridad de Docker, Fundamentos y Mejores prácticas</span>"
    ]
  },
  {
    "objectID": "Docker_Security_Fundamentals_and_Best_Practices.html#fundamentos-de-la-seguridad-en-docker",
    "href": "Docker_Security_Fundamentals_and_Best_Practices.html#fundamentos-de-la-seguridad-en-docker",
    "title": "13  Seguridad de Docker, Fundamentos y Mejores prácticas",
    "section": "13.2 Fundamentos de la Seguridad en Docker",
    "text": "13.2 Fundamentos de la Seguridad en Docker\nLa seguridad en Docker se centra en proteger tanto las imágenes como los contenedores. Las imágenes son la base de los contenedores y, por lo tanto, su seguridad es primordial. Se recomienda utilizar imágenes base mínimas y firmadas para reducir la superficie de ataque. Docker Hub, como repositorio de imágenes, ofrece imágenes certificadas que han sido revisadas para garantizar su autenticidad. Sin embargo, es crucial que los desarrolladores verifiquen la fuente de las imágenes y estén atentos a las alertas de seguridad.\n\nSeguridad de Imágenes de Docker\nLas imágenes son el pilar sobre el cual se construyen los contenedores en Docker. Garantizar la seguridad de estas imágenes es esencial para evitar problemas de seguridad. Prácticas recomendadas:\n\nVerificación de Imágenes:Usar imágenes oficiales y certificadas de Docker Hub reduce la probabilidad de descargar imágenes comprometidas. En el pasado, se han identificado imágenes maliciosas que explotaban vulnerabilidades como el “cryptojacking”.\n\nRiesgos comunes: Las imágenes en Docker Hub pueden contener malware si no se validan. Ejemplo: en 2018, se detectaron imágenes maliciosas destinadas al cryptojacking.\nSe recomienda usar imágenes firmadas: Docker ofrece un mecanismo de firma que ayuda a verificar la autenticidad de las imágenes. Además, verificar los hashes (como sha256) de las imágenes asegura que no han sido modificadas.\n\n\nDocker Content Trust (DCT):Este mecanismo utiliza firmas digitales para garantizar que las imágenes no han sido alteradas. Aunque está deshabilitado por defecto, habilitar DCT asegura la autenticidad de las imágenes descargadas.\nUso de Imágenes Base Mínimas: A menudo, las imágenes completas incluyen muchos paquetes innecesarios que pueden contener vulnerabilidades no actualizadas.\n\nSe recomienda usar imágenes base mínimas, como Alpine, que tienen un tamaño reducido (alrededor de 5 MB) y contienen solo lo esencial para ejecutar la aplicación. Estas imágenes son más seguras porque limitan la cantidad de código vulnerable y permiten un control más detallado sobre lo que se incluye en el contenedor.\n\nArchivo .dockerignore:\n\nEste archivo excluye archivos innecesarios en el proceso de construcción, como binarios y configuraciones sensibles.\nEjemplo: Excluir claves privadas con reglas como **/*.pem o carpetas como .git.\n\n\nRestricción de Privilegios en Contenedores\nEl control de privilegios dentro de un contenedor es una de las mejores maneras de mejorar la seguridad. Docker permite configurar varios parámetros para limitar los privilegios de los contenedores, reduciendo la posibilidad de explotación.\n\nUso de –security-opt=no-new-privileges:Esta opción impide que los contenedores y sus procesos obtengan privilegios adicionales, lo cual ayuda a proteger el host subyacente y evitar que los atacantes escalen privilegios.\nSistema de archivos de solo lectura: Configurar volúmenes en modo de solo lectura protege contra modificaciones accidentales o maliciosas dentro del contenedor.\nUsuarios y grupos específicos: Asignar usuarios con permisos limitados en lugar de ejecutar procesos como usuario raíz.\n\nConstrucción Segura de Imágenes Cuando se crean imágenes personalizadas para aplicaciones, es esencial seguir ciertas prácticas para evitar posibles riesgos.\n\nUso de COPY en lugar de ADD: Mientras que ADD permite descargar archivos remotos y descomprimirlos automáticamente, esto aumenta el riesgo de incluir contenido inseguro. COPY es más seguro y controlado.\n\nRiesgo de ADD: Descargar archivos desde URLs no verificadas puede comprometer la seguridad.\n\nArchivo .dockerignore: Este archivo ayuda a excluir archivos sensibles, como claves privadas o tokens de API, durante el proceso de construcción.\nCopias recursivas: Evitar incluir accidentalmente archivos sensibles al usar copias recursivas.\n\nSolución: Actualizar .dockerignore para excluir archivos como .env o secretos de API.\n\nLimitar el Tamaño de las Imágenes: Utilizar imágenes base mínimas y eliminar paquetes o dependencias innecesarias es clave para reducir la superficie de ataque. Menos código implica menos riesgo de vulnerabilidades.\nEvitar incluir datos confidenciales: Las claves y configuraciones sensibles deben ser gestionadas mediante herramientas externas como HashiCorp Vault o servicios en la nube.\n\nMitigación de Vulnerabilidades\nEl monitoreo y la prevención son esenciales para mantener un entorno seguro:\n\nAuditorías regulares: Revisar continuamente las imágenes y contenedores para identificar vulnerabilidades.\nSistemas de detección y protección: Utilizar herramientas como escáneres de seguridad para detectar configuraciones incorrectas o imágenes maliciosas.\nCapacidades limitadas: Restringir las funciones del contenedor para que solo accedan a los recursos necesarios.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Seguridad de Docker, Fundamentos y Mejores prácticas</span>"
    ]
  },
  {
    "objectID": "Docker_Security_Fundamentals_and_Best_Practices.html#conclusión",
    "href": "Docker_Security_Fundamentals_and_Best_Practices.html#conclusión",
    "title": "13  Seguridad de Docker, Fundamentos y Mejores prácticas",
    "section": "13.3 Conclusión",
    "text": "13.3 Conclusión\nImplementar prácticas de seguridad en Docker protege los entornos de desarrollo y producción. Verificar imágenes, limitar privilegios, y optimizar construcciones reduce la exposición a vulnerabilidades. Estas medidas, junto con la restricción de recursos, aseguran un despliegue seguro y eficiente, estableciendo una base sólida para una gestión confiable de contenedores.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Seguridad de Docker, Fundamentos y Mejores prácticas</span>"
    ]
  }
]