[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contenedores al Alcance de Todos",
    "section": "",
    "text": "1 Prefacio\nEste libro te enseñará a manejar y comprender contenedores con herramientas modernas como Docker y Podman. Aprenderás desde los fundamentos hasta el despliegue de aplicaciones en entornos reales, pasando por la construcción de imágenes, gestión de redes y almacenamiento, todo a través de ejemplos prácticos y proyectos aplicados. Sin embargo, este no es un manual introductorio típico. Mi objetivo es ayudarte a convertirte en un profesional capaz de utilizar contenedores no solo para ejecutar aplicaciones, sino para integrarlos en procesos de desarrollo y despliegue ágiles.\nLos capítulos del libro están organizados en torno a tres proyectos principales, diseñados para abarcar aspectos clave de Docker y Podman. Estos proyectos no solo cubren la construcción y gestión de contenedores, sino también prácticas avanzadas como la integración con CI/CD, optimización de recursos y resolución de problemas comunes. He seleccionado estos proyectos por dos razones: primero, porque representan el rango completo de funcionalidades de estas herramientas; segundo, porque están diseñados para ayudarte a abordar los desafíos reales del desarrollo y despliegue moderno de software.\nMás allá de las características técnicas, los contenedores resuelven problemas logísticos importantes en el desarrollo. Permiten crear entornos reproducibles, escalar aplicaciones de manera eficiente y minimizar errores relacionados con dependencias o configuraciones. A través de este libro, no solo aprenderás a usar Docker y Podman, sino también a integrar estas habilidades en tu trabajo como desarrollador, maximizando tu productividad y mejorando tu flujo de trabajo.\nEste libro está dirigido a los siguientes perfiles: - Estudiantes y profesionales interesados en aprender sobre contenedores desde cero. - Desarrolladores que buscan integrar prácticas modernas de DevOps y microservicios. - Ingenieros que desean optimizar procesos de despliegue y escalabilidad en la nube.\nHe diseñado este libro para que sea accesible y práctico, centrándome en conceptos aplicados y dejando de lado teorías avanzadas que pueden ser un obstáculo al inicio. Mi objetivo es proporcionarte las herramientas y el conocimiento para que puedas enfrentarte a problemas reales en el desarrollo de software.\nAprender a manejar contenedores es una habilidad esencial para cualquier profesional en tecnología hoy en día. Es como pasar de usar un sistema tradicional, donde todo está predeterminado, a un sistema donde tienes la flexibilidad y el control total para crear lo que necesitas. Como dijo Greg Snow al referirse a otro contexto, los contenedores son como un vehículo todoterreno que te llevará a lugares donde las herramientas tradicionales no pueden llegar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#convenciones-utilizadas-en-este-libro",
    "href": "index.html#convenciones-utilizadas-en-este-libro",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.1 Convenciones Utilizadas en Este Libro",
    "text": "1.1 Convenciones Utilizadas en Este Libro\n\nCursiva: Indica términos nuevos, URLs y nombres de archivos.\nTexto de ancho fijo: Representa comandos, nombres de variables o elementos de código.\nTexto en negrita: Muestra comandos que deben ser escritos literalmente por el lector.\n\nPara realizar comentarios o preguntas técnicas sobre este libro, por favor abre un issue en github.com/tu-repositorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.2 Agradecimientos",
    "text": "1.2 Agradecimientos\nQuiero agradecer a todas las personas que me han ayudado a escribir este libro, desde mis colegas y estudiantes que han probado este contenido, hasta quienes contribuyeron con ideas y retroalimentación. También agradezco a las comunidades de Docker y Podman por proporcionar recursos invaluables y fomentar el aprendizaje continuo. Finalmente, gracias a mi familia por su apoyo incondicional durante este proceso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "prework.html",
    "href": "prework.html",
    "title": "2  First steps with Polars",
    "section": "",
    "text": "2.1 Requisitos de Docker antes de instalar.\nocker destaca por su compatibilidad entre sistemas. Las máquinas virtuales o la virtualización de hardware clásica emulan un sistema operativo invitado entero, mientras que los contenedores Docker comparten el núcleo del sistema anfitrión, ejecutándose como procesos aislados en el espacio del usuario. En sus inicios, Docker se utilizaba exclusivamente en sistemas Linux o en sistemas operativos basados en Linux. Hoy en día, el software de código abierto se caracteriza por su completa independencia de los sistemas operativos. Docker utiliza el kernel local de Linux en las variantes de 64 bits de los sistemas operativos de Linux, los sistemas que no son de Linux utilizan simplemente una imagen del sistema Linux a través de un hypervisor o una máquina virtual.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First steps with Polars</span>"
    ]
  },
  {
    "objectID": "introduccion_docker.html",
    "href": "introduccion_docker.html",
    "title": "3  Introducción a Docker",
    "section": "",
    "text": "3.0.1 Introducción\nDocker surge como una solución innovadora al problema de la virtualización tradicional, ya que en el enfoque clásico, se utilizan máquinas virtuales (VMs), las cuales requieren de un sistema operativo completo para su creación y ejecución, además de que consumen una gran cantidad de espacio y recursos, incluso si solo se necesita ejecutar una tarea específica, por lo que este enfoque en la actualidad es ineficiente y poco flexible.\nDocker se centra en solucionar este problema mediante el uso de contenedores, definidos por archivos Dockerfile. Estos archivos especifican únicamente lo necesario para que una aplicación funcione, eliminando la necesidad de instalar sistemas operativos completos, basta con tener una imagen base y las dependencias necesarias; Docker optimiza el uso del espacio y acelera en gran medida el despliegue de aplicaciones.\nUna de las principales ventajas de Docker es su portabilidad, ya que permite que las aplicaciones se ejecuten de manera consistente en diferentes sistemas operativos y entornos, como desarrollo, pruebas y producción. Esto lo convierte en una herramienta fundamental para implementar arquitecturas modernas, como los microservicios, facilitando la gestión y escalabilidad de aplicaciones complejas.\n\n\n3.0.2 ¿Qué es Docker?\nDocker es una tecnología de virtualización basada en contenedores que permite empaquetar aplicaciones junto con sus dependencias y frameworks necesarios para su ejecución, esto garantiza que las aplicaciones funcionen de manera consistente y uniforme, sin importar el entorno en el que se ejecuten, resolviendo los problemas de compatibilidad y configuración de dependencias que suelen surgir al migrar entre sistemas operativos o entornos.\n\n\n3.0.3 Componente de Docker\nDocker engine: Es el motor de Docker y se encarga de la gestión de todos los contenedores que se ejecutan en Docker.\nDocker images: Es la plantilla donde se ecuentra la aplicación, la imagen base del sistema operativo y las dependencias necesarias para la ejecución de la aplicación, estas imágenes son reutilizables y permiten crear contenedores de manera rápida y eficiente.\nDocker container: Es la ejecución de una instancia de la imagen de Docker, donde cada contenedor opera en un entorno completamente aislado, compartiendo únicamente el kernel del sistema operativo anfitrión pero manteniendo independencia en cuanto a procesos, redes y almacenamiento.\nRedes: Las redes sirven para la comunicación entre los contenedores, permitiendo que se comuniquen entre sí o con el host, por lo que existen diferentes modelos de red que son las redes de puente, las redes de host y las redes de superposición.\nVolúmenes: Los volúmenes sirven para almacenar los datos que se desea que persistan en el tiempo, es decir cuando el contenedorer termine de ejecutarse, se reinicie o se elimine, esto es ideal para manejar aplicaciones que requieren de una base de datos o almacenamiento persistente.\nDocker Hub: Es el repositorio central que utiliza Docker para que los desarrolladores puedan compartir y descargar imágenes tanto públicas como privadas, lo que facilita la colaboración y la reutilización de imágenes.\n\n\n3.0.4 Diferencias entre Docker y Máquinas Virtuales\n\n3.0.4.1 Docker\n\nLos contenedores de Docker solo comparten el núcleo del sistema operativo host.\nLos contenedores son más ligeros.\nArrancan en segundos.\nSon más portables y fáciles de gestionar.\nPresentan menos sobrecarga sobre el hardware del host.\nPermiten la ejecución de múltiples contenedores en un mismo host.\nSon ideales para aplicaciones basadas en microservicios.\n\n\n\n3.0.4.2 Máquinas Virtuales\n\nLas máquinas virtuales necesitan de la virtuaización de todo el hardware del host.\nLas máquinas virtuales ocupan gran cantidad de espacio y recursos para su creación y ejecución.\nSu arranque es lento, por lo general tardan minutos.\nSon más complejas de administrar y su portabilidad es compleja.\nPresentan mayor sobrecarga sobre el hardware del host.\nSe puede ejecutar multiples máquinas virtuales en un mismo host, pero esto requiere de más recursos.\nSon ideales para aplicaciones con una arquitectura monolítica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a Docker</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html",
    "href": "understanding_cloud_concepts.html",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "4.1 Ecosistema del Cloud Computing\nEl concepto de cloud computing está transformando la manera en que las empresas operan, permitiéndoles acceder a recursos de cómputo y almacenamiento bajo demanda, escalar sin límites y adoptar modelos de precios flexibles. Esta tecnología ha revolucionado tanto a empresas emergentes como a grandes corporaciones.\nEl ecosistema de cloud computing consta de tres principales actores:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "Consumidores de servicios: Usan aplicaciones y herramientas en la nube sin preocuparse por su ubicación o diseño.\nProveedores de servicios: Ofrecen infraestructura, aplicaciones y herramientas basadas en la nube.\nDiseñadores de servicios: Construyen herramientas o aplicaciones optimizadas para ecosistemas específicos de nube.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "4.2 Conceptos Fundamentales del Cloud Computing",
    "text": "4.2 Conceptos Fundamentales del Cloud Computing\nEl cloud computing implica la provisión de recursos compartidos como aplicaciones, almacenamiento y plataformas de desarrollo a través de estándares y automatización. Los servicios comunes incluyen:\n\nAutomatización: Procesos gestionados automáticamente para optimizar la eficiencia.\nAutoservicio: Permite a los usuarios aprovisionar recursos por sí mismos.\nElasticidad: Capacidad de ajustar automáticamente recursos según las necesidades.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-nube",
    "href": "understanding_cloud_concepts.html#modelos-de-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.3 Modelos de Nube",
    "text": "4.3 Modelos de Nube\nExisten diferentes modelos de despliegue en la nube, cada uno adaptado a distintas necesidades empresariales:\n\n4.3.1 Nube Pública\n\nDefinición: Recursos compartidos y gestionados por un proveedor externo. Los usuarios pagan por el uso bajo demanda.\nCaracterísticas:\n\nEscalabilidad masiva y elasticidad automática.\nAcceso a servicios avanzados, como análisis de datos y aprendizaje automático.\nDisponibilidad global, ideal para empresas que requieren operaciones en múltiples regiones.\n\nCasos de uso: Aplicaciones de comercio electrónico, almacenamiento masivo, pruebas y desarrollo.\n\n\n\n4.3.2 Nube Privada\n\nDefinición: Recursos dedicados y gestionados por una sola organización, ya sea internamente o a través de un proveedor externo.\nCaracterísticas:\n\nControl total sobre los recursos.\nMayor seguridad y personalización.\nCumplimiento normativo y gobernanza específica.\n\nCasos de uso: Datos sensibles, aplicaciones con requisitos legales estrictos o sistemas heredados.\n\n\n\n4.3.3 Nube Híbrida\n\nDefinición: Combina nubes públicas y privadas, permitiendo la interoperabilidad y la transferencia de datos entre ambas.\nCaracterísticas:\n\nBalanceo de cargas de trabajo entre entornos.\nFlexibilidad para mover datos según necesidades de costo, rendimiento o seguridad.\n\nCasos de uso: Migraciones graduales hacia la nube, recuperación ante desastres, análisis de datos en múltiples ubicaciones.\n\n\n\n4.3.4 Multicloud\n\nDefinición: Uso simultáneo de múltiples nubes públicas para satisfacer distintas necesidades empresariales.\nCaracterísticas:\n\nEvita la dependencia de un solo proveedor.\nFlexibilidad para aprovechar lo mejor de cada plataforma.\nGestión centralizada para controlar costos y rendimiento.\n\nCasos de uso: Desarrollo de aplicaciones en plataformas específicas o maximización de servicios según región.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-entrega",
    "href": "understanding_cloud_concepts.html#modelos-de-entrega",
    "title": "4  Comprendiendo la Nube",
    "section": "4.4 Modelos de Entrega",
    "text": "4.4 Modelos de Entrega\nLos modelos de entrega en cloud computing son fundamentales para entender cómo se ofrecen los servicios a los usuarios. Cada uno proporciona un nivel distinto de abstracción y control:\n\n4.4.1 Infraestructura como Servicio (IaaS)\n\nDefinición: Provisión de recursos básicos, como servidores virtuales, almacenamiento y redes, sobre los cuales los usuarios pueden construir sus propias aplicaciones.\nCaracterísticas:\n\nControl total sobre el sistema operativo y las aplicaciones.\nAlta flexibilidad para personalizar entornos según las necesidades.\nPago por uso, permitiendo reducir costos operativos.\n\nEjemplos de servicios: Amazon EC2, Google Compute Engine, Microsoft Azure VMs.\nCasos de uso:\n\nMigración de centros de datos físicos a la nube.\nEscenarios de desarrollo y pruebas.\nImplementación de aplicaciones personalizadas.\n\n\n\n\n4.4.2 Plataforma como Servicio (PaaS)\n\nDefinición: Provisión de una capa de abstracción que incluye herramientas de desarrollo, middleware y bases de datos, optimizada para la creación y despliegue de aplicaciones.\nCaracterísticas:\n\nEntorno preconfigurado para desarrollo rápido.\nIntegración de herramientas como frameworks y APIs.\nGestión automatizada de recursos y actualizaciones.\n\nEjemplos de servicios: Google App Engine, Microsoft Azure App Service, Heroku.\nCasos de uso:\n\nDesarrollo de aplicaciones web y móviles.\nCreación de aplicaciones en entornos colaborativos.\nEscenarios donde se busca acelerar el tiempo de desarrollo.\n\n\n\n\n4.4.3 Software como Servicio (SaaS)\n\nDefinición: Provisión de aplicaciones completas accesibles a través de internet. Los usuarios no gestionan ni la infraestructura ni las plataformas subyacentes.\nCaracterísticas:\n\nFacilidad de uso y acceso desde cualquier dispositivo.\nModelos de suscripción mensual o anual.\nAlta disponibilidad y actualizaciones automáticas.\n\nEjemplos de servicios: Google Workspace, Salesforce, Zoom.\nCasos de uso:\n\nHerramientas de colaboración y productividad.\nGestión de relaciones con clientes (CRM).\nServicios de recursos humanos y contabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "href": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.5 Ciclo de Vida de Recursos en la Nube",
    "text": "4.5 Ciclo de Vida de Recursos en la Nube\nEn contraste con los centros de datos tradicionales, la nube permite a los usuarios:\n\nAlquilar recursos bajo demanda.\nPagar únicamente por el uso real.\nLiberar recursos automáticamente cuando ya no se necesitan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "href": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "title": "4  Comprendiendo la Nube",
    "section": "4.6 Gestión de Nubes Híbridas y Multicloud",
    "text": "4.6 Gestión de Nubes Híbridas y Multicloud\nUna nube híbrida efectiva debe integrar múltiples entornos de forma automatizada y bien gestionada. Los entornos multicloud requieren visibilidad, control y capacidad para mover datos y cargas de trabajo según convenga.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "href": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "title": "4  Comprendiendo la Nube",
    "section": "4.7 Cambios en el Rol del Centro de Datos",
    "text": "4.7 Cambios en el Rol del Centro de Datos\nAunque los centros de datos no desaparecerán, la adopción de la nube les exige modernizarse. Las estrategias incluyen:\n\nVirtualización: Separar software de hardware para mejorar la eficiencia.\nNubes privadas: Crear entornos altamente automatizados con capacidades de autoservicio.\nNubes híbridas: Combinar servicios en la nube con infraestructura local.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "virtualbox and docker containers for developments.html",
    "href": "virtualbox and docker containers for developments.html",
    "title": "5  VirtualBox y Contenedores Docker para el Desarrollo",
    "section": "",
    "text": "5.0.1 Introducción\nDentro del desarrollo de software de la actualidad se requieren entornos flexibles, escalables y consistentes. La configuración manual para cada proyecto puede ser tedioso y con tendencia a errores, en especial cuando las dependencias del sistema o sus versiones de software son críticas. Para esto, existen herramientas como VirtualBox y Docker juegan un papel importante.\n\n\n5.0.2 VirtualBox:\nLa herramienta de VirtualBox nos proporciona un software de hipervisor el cual nos permite la ejecución de máquinas virtuales dentro de un sistema host o anfitrión. Cada una de estas máquinas virtuales imitan entornos completos, incluso el de los sistemas operativos, de configuraciones y de aplicaciones que se requieren para el desarrollo. Se puede usar virtualbox para realizar pruebas de software en múltiples sistemas operativos o para poner en aislamineto un entorno de desarrollo.\nGuest Additions\nDentro de los sistemas invitados como Windows y Linux, se puede instalar controladores que permitan integrar los sistemas operativos de invitado y host. Tales controladores se conocen como Guest Additions y se los puede bajar desde el sitio web de VirtualBox.\nSon instalables dentro de la máquina virtual como cualquier programa que se vaya a instalar para Windows o Linux. La integración con el host es bastante útil.\nInstalación VirtualBox\n\nDescargue VirtualBox desde el sitio web oficial.\nInstale el software utilizando el instalador proporcionado.\nInicie VirtualBox y verifique que se esté ejecutando correctamente.\n\n\n\n5.0.3 Contenedores Docker:\nLa tecnología Docker hace el uso de contenedores ligeros para poder empaquetar aplicaciones incluidas sus dependencias utilizando un solo entorno ejecutable. En contraparte con las máquinas virtuales, los contenedores tienen compartición del núcleo del sistema operativo anfitrión, permitiendoles ser más eficientes en términos de recursos. Docker ayuda a que los desarrolladores puedan crear entornos reproducibles y escalables en cuestión de segundos, haciendo fácil y fluida la colaboración y la integración continua.\nConfiguración Contenedor Docker Básico Docker nos proporciona una manera eficiente de empaquetar, enviar y poder ejecutar software. En esta parte, se analizaran los pasos básicos para crear un contenedor para el desarrollo.\n\nEscribiendo el Dockerfile:\n\nUn archivo Dockerfile específica el entorno de configuración y todos los comandos para poder tener nuestro contenedor, ejemplo:\n# Usso de ina imagen oficial de PHP\nFROM php:7.4-apache\n\n# Habilitar módulos de Apache requeridos\nRUN a2enmod userdir \\\n    && a2enmod php7.4\n\n# Copiar el archivo de configuración para Apache\nCOPY php.conf /etc/apache2/mods-available/php7.4.conf\n\n# Definir el entry point\nENTRYPOINT [\"/entrypoint.sh\"]\n\nConstruyendo el Docker Image:\n\nPara crear la imagen del contenedor se hace uso del script build.sh, ejemplo:\n#!/usr/bin/env bash\n\n# Se construye el Docker Image\n\ndocker build -t chapter2 .\n\nCorriendo el Docker Container:\n\nPara lanzar el contenedor, se hace uso del script run.sh, ejemplo:\n#!/usr/bin/env bash\n\ndocker run -d --name chapter2 chapter2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>VirtualBox y Contenedores Docker para el Desarrollo</span>"
    ]
  },
  {
    "objectID": "composing_systems_using_containers.html",
    "href": "composing_systems_using_containers.html",
    "title": "6  Componiendo sistemas utilizando contenedores.",
    "section": "",
    "text": "6.1 Archivos de configuracion para Docker Compose.\nAutor: Byron Gonzalez. ## Introduccion. En este capitulo se presenta la forma de definir y ejecutar aplicaciones multicontenedor utilizando Docker Compose, permitiendo una gestion mas sencilla de sistemas complejos de multiples servicios interconectados. ## Problema con los scripts sh. Utilizar varios archivos sh para crear diferentes servicios puede causar problemas en los puertos o en la inicializacion del servicio. Algunos problemas comunes son: - Permisos Insuficientes. Al copiar un script al contenedor, es posible que no contenga los permisos de ejecucion. Para ello se debe otorgar los servicios con: RUN chmod +x /path/to/script.sh - Formato de archivo incorrecto Muchas veces los scripts creados en windows pueden contener caracteres de fin de linea incompatibles con entornos de Unix o Linux. La forma de arreglarlo es convirtiendo el archivo a formato UNIX con dos2unix script .sh - Shell Incorrecto Algunos contenedores no usan bash por defecto en su lugar tienen sh. por lo que se debe asegurar de usar el shell correcto en el script (#!/bin/sh). - Variables de entorno no disponibles Los scripts pueden depender de variables que no estan configuradas en el contenedor, en este caso se debe declarar las variables en el docker-compose.yml o pasarlas como parametros al script.\nEstos archivos son en formato .yml los contenidos son en YAML. El archivo se llama docker-compose.yml Dentro de este se deben seguir las siguientes directivas clave. Primero se define la version. Como parte principar se debe definir cuales de las diferentes versiones se va usar ya que en estas se pueden encontrar distintas funciones que se pueden necesitar. Ejemplo: version: ‘3.9’ El bloque de servicios o services se contiene las definiciones de los servicios, estos deben poseer un nombre y configuracion especifica. En el caso de las directivas comunes en un servicio se empieza por el build que especifica el contexto para construir la imagen. Ejemplo: build: context: . dockerfile: Dockerfile\nLa parte de image se especifica el imagen que el serviciio va a usar. Ejemplo: image: nginx:latest\nEn ports se mapean los puertos internos del contenedor a los puertos externos del host. Ejemplo: ports: -“8080:80”\nLa parte de volumes se monta los directorios o archivos del host dentro del contenedor. Ejemplo: volumes: -./data:/app/data Dentro de enviroment se define las variables de entorno para el contenedor. Ejemplo: environment: -MYSQL_ROOT_PASSWORD=root La definicion de depends_on especifica las depedencias entre servicios, garantizado que uno se inicie antes que otro. Ejemplo: depends_on: -db Ejemplo de un docker-compose completo: version: ‘3.9’ services: web: image: nginx:latest ports: - “8080:80” (Mapea el puerto 80 del contenedor al puerto 8080 del host) volumes: - ./web:/usr/share/nginx/html (Monta el directorio local) ./web al contenedor depends_on: - db (El servicio web depende del servicio db) networks: -app_network db: image: mysql:8.0 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: myapp volumes: -db_data:/var/lib/mysql (Almacena datos de MySQL en un volumen) networks: -app_network volumes: db_data: (Define un volumen persistente para MySQL) networks: app_network: (Define una red personalizada para conectar los servicios) driver: bridge Dentro del servicio web se usa la imagen oficial de nginx, se expone el puerto 8080 del host, se monta el directorio local ./web para servir archivos HTML estaticos y depende del servicio db, asegurandose de que este se inicie primero. En la zona de dbse usa la imagen de MYSQL, se configura la base de datos mediante las variables de entorno, se almacena los datos en un volumen persistente db_data. Dentro de la zona de los volumenes se permite persistir datos (como los de MYSQL) para que no se pierdan al reiniciar o en un fallo de los contenedores. Por ultimo en las redes se conectan ambos servicios a una red interna llamada app_network, lo que permite la comunicacion entre ellos sin exponerse todos los puertos al host.\nLos comandos escenciales para gestionar el compose son: - docker-compose up (Usa el archivo docker compose.yml para construir e iniciar los servicios). - docker-compose up -d (Inicia los contenedores en segundo plano) - docker-compose ps (Verificar el estado de los contenedores activos) - docker-compose restart (Reinicia los servicios) - docker-compose down (Agrega y elimina los servicios) ## Redes internas Las redes internas privadas son importantes debido a la comunicacion entre los distintos a contenedores a crear. Se debe definir lel hostIp. el host de mongo y el host de redis como variables especialmente en los archivos sh. estp con el fin de ejecutarlos usando docker run ya que el DNS local de Docker no trabaja con sh. Al momento de la gestion automatica de redes internas se tiene las ventajas de un red interna por defecto para los servicios evitando errores con otros contenedores o redes en el sistema, junto tambien que se evitan conflictos de puertos. Y al usar sus nombres de servicio como hostnames se evita problemas de nombres. Se crean diferentes partes dentro del yml. para crear redes de mejor forma como una seccion de networks. Ejemplo: version: ‘3.9’ services: web: image: nginx networks: - frontend db: image: postgres networks: - backend networks: frontend: driver: bridge backend: driver: bridge\nUna de las formas mas comunes es separar la redes de frontend y backend para que no se comuniquen de forma directa. Junto a esto se debe especificar rangos de subred. Ejemplo:\nnetworks: custom_network: driver: bridge ipam: config: -subnet: “192.168.1.0/24”\nEspecificar los servicios necesarios que van a acceder, utilizar redes overlay para comunicar servicios distribuidos en varios nodos. Tener nombres claros para futuras actualizaciones o mejoras. ## Gestion de puertos Se emplean estrategias para asignar los distintos puertos a los host para evitar los conflictos con los servicios ya existentes. El uso de mapeo para los puertos internos a los externos del host. En docker cada contenedor posee su propia red aislada pero muchas veces se requiere exponer servicios del contenedor al host para que accesibles desde fuera. Esto se realiza con la directiva ports. Ejemplo: services: web: image: nginx:latest ports: - “8080:80” ( 8080 Puerto del host donde sera accesible el servicio y 80 puerto interno del contenedor donde esta configurado el servicio). Para evitar conflictos de puerto se usa: - Uso de puertos dinamicos Si no se requiere un puerto especifico del host, Docker puede asignar uno automaticamente. Ejemplo: ports: -“80” De esta forma se asigna un puerto aleatorio disponible en el host y lo enlaza con el puerto especificado (80) en el contenedor. Se usa el comando docker ps para saber el puerto asignado. - Planificacion de puertos Definir un rango especifico de puertos para cada servicio y asegurarse de que no entren en conflicto unos con otros mientras los de mas servicios estan en ejecucion. La herramienta como netstat o lsof se usa para visualizar los puertos ocupados en el host. - Asignacion de puertos por red En aplicaciones con multiples contenedores, en lugar de exponer los puertos al host, permite que los contenedores se comuniquen internamente en su red. Ejemplo: services: web: image: nginx:latest ports: - “8080:80” db: image: postgres:latest ports: - “5432:5432” networks: -backend -networks: -backend: -driver: bridge En este ejemplo el servicio web se comunica con la db internamente en la red backend, sin exponer el puerto 5432 al host. ## Variables de entorno Las variables de entorno permite la parametrizacion de las configuracion para que sean reutilizables y flexibles. Dentro de estas se pueden definir los puertos, nombres de contenedores, rutas de volumenes o contraseñas. Tambien nos presenta al uso de archivos .env para almacenar variables sensibles o configuraciones especificas.\nEjemplo: MYSQL_USER=root MYSQL_PASSWORD=secret MYSQL_DB=mydatabase PORT=8080\nEstas pueden ser accedidas mediante el archivo docker-compose.yml Ejemplo: Se usa el signo de dolar junto a la variable. version: ‘3.9’ services: db: image: mysql:latest environment: MYSQL_USER:{MYSQL_USER} MYSQL_PASSWORD:{MYSQL_PASSWORD} MYSQL_DATABASE:{MYSQL_DB] ports: -“${PORT}:3306” Cuando se ejecuta el comando docker-compose-up.yml se busca el archivo .env en el mismo directorio. Se debe mantener el archivo .env fuera del control de versiones para proteger los datos. Y utilizar distintos archivos para los distintos entornos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Componiendo sistemas utilizando contenedores.</span>"
    ]
  },
  {
    "objectID": "composing_systems_using_containers.html#despliegue-en-diferentes-entornos",
    "href": "composing_systems_using_containers.html#despliegue-en-diferentes-entornos",
    "title": "6  Componiendo sistemas utilizando contenedores.",
    "section": "6.2 Despliegue en diferentes entornos",
    "text": "6.2 Despliegue en diferentes entornos\nConfiguracion de multiples archivos compose para entornos de desarrollo, pruebas y produccion. En aplicaciones en el mundo laboral las configuraciones varian en base al entorno. Ejemplo: En desarrollo se usan imagenes locales, bd en contenedores y logs detallados. En produccion se usan imagenes optimizadas, bases de datos gestionadas y configuraciones seguras. Dentro de la carga puede crearse un archivo llamado docker-compose.override.yml el cual puede tener configuraciones adicionales o reemplazar distintos valores del archivo principal. Este permite mantener configuraciones especificas sin modificar el archivo docker compose, es ideal para los cambios en desarrollo como montar directorios locales o habilitar el modo de depuracion.\nEjemplo:\nservices: web: volumes: -./local_code:/app environment: DEBUG: “true”",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Componiendo sistemas utilizando contenedores.</span>"
    ]
  },
  {
    "objectID": "composing_systems_using_containers.html#depuracion-y-monitoreo",
    "href": "composing_systems_using_containers.html#depuracion-y-monitoreo",
    "title": "6  Componiendo sistemas utilizando contenedores.",
    "section": "6.3 Depuracion y Monitoreo",
    "text": "6.3 Depuracion y Monitoreo\nUso de logs para el diagnostico de problemas como al inicio o en la ejecucion de los servicios y permite la identificacion de comunicacion entre los contenedores. Docker-compose.logs Los comandos basicos dentro de estas son: Docker-compose logs (Muestra los logs de los contenedores en ejecucion). Docker-compose logs &lt; service-name &gt; (Muestra los logs de un servicio en especifico). –tail &lt; N &gt; muestra solo las ultimas N lineas. -f o –follow sigue los logs en tiempo real.\nIntegracion de herramientas externas para monitorear el rendimiento de los servicios. En el caso de las aplicaciones grandes se utilizan las herramientas de: Prometheus y Grafana para tener un mejor uso de la CPU, memoria y red en contenedores. Elk Stack (Elastic Search, Logstach, Kibana) para el almacenamiento y analisis de los logs de los servicios, facilita la busqueda de errores en grandes volumenes de datos. Docker Desktop interfaz grafica para las estadisticas basicas de los contenedores.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Componiendo sistemas utilizando contenedores.</span>"
    ]
  },
  {
    "objectID": "scaling_and_load_testing_docker_applications.html",
    "href": "scaling_and_load_testing_docker_applications.html",
    "title": "7  Escalado y Pruebas de Carga de Aplicaciones Docker",
    "section": "",
    "text": "#Autor:Pool Ochoa\nEl escalado y las pruebas de carga son esenciales para garantizar que las aplicaciones en contenedores puedan manejar el tráfico creciente de manera eficiente y continuar funcionando bajo presión. Este proceso es particularmente relevante para infraestructuras basadas en Kubernetes, donde se pueden implementar estrategias de escalado tanto manuales como automáticas.\n\n7.0.1 Escalado en Kubernetes\nKubernetes permite escalar las aplicaciones en dos niveles principales:\n1. Escalado de Pods: Incrementar o reducir el número de réplicas de una aplicación según la demanda.\n2. Escalado del Clúster: Ajustar el número de nodos disponibles en el clúster para manejar los pods adicionales cuando los recursos se limitan.\nPara automatizar el escalado, Kubernetes ofrece herramientas como:\n- Cluster Autoscaler: Escala los nodos del clúster según la carga actual.\n- Horizontal Pod Autoscaler (HPA): Ajusta el número de pods basándose en métricas como el uso de CPU.\n- Vertical Pod Autoscaler (VPA): Modifica dinámicamente las solicitudes de CPU y memoria de los pods para optimizar los recursos.\n\n\n7.0.2 Pruebas de Carga\nLas pruebas de carga evalúan cómo responde una aplicación bajo diferentes niveles de tráfico. Estas pruebas permiten identificar cuellos de botella y garantizar que los mecanismos de escalado funcionen como se espera. Herramientas como Apache Bench (ab) y k6 son comunes para realizar estas pruebas.\n\n\n7.0.3 Ejemplo 1: Escalado Horizontal de Pods\n\nConfigurar el HPA en Kubernetes con un comando como:\nkubectl autoscale deployment app-deployment --cpu-percent=50 --min=2 --max=10\nAquí, el número de pods de la aplicación se ajustará automáticamente entre 2 y 10, según el uso de CPU.\nEjecutar una prueba de carga con Apache Bench para simular tráfico:\nab -n 1000 -c 50 http://app-url/\nEsto genera 1000 solicitudes concurrentes para evaluar si los pods adicionales se crean al aumentar el uso de CPU.\n\n\n\n7.0.4 Ejemplo 2: Pruebas de Escalabilidad con k6\n\nEscribir un script de carga en JavaScript para simular usuarios concurrentes:\nimport http from 'k6/http';\n\nexport default function() {\n    http.get('http://app-url/');\n}\nEjecutar el script con 50 usuarios virtuales durante 30 segundos:\ndocker run --rm -i loadimpact/k6 run --vus 50 --duration 30s - &lt; script.js\nEsto mide el rendimiento de la aplicación y verifica si el Cluster Autoscaler añade nodos para manejar el incremento de pods.\n\nCon estas estrategias, puedes optimizar el desempeño de aplicaciones contenedorizadas y garantizar una experiencia de usuario confiable.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Escalado y Pruebas de Carga de Aplicaciones Docker</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "",
    "text": "8.1 Ejecutar Docker en Producción: Muchas Rutas, Escoge Sabiamente\nIntroduce a las numerosas formas en las que se pueden desplegar aplicaciones basadas en Docker en entornos de producción. A medida que la tecnología de contenedores ha madurado, las opciones para implementarlas han crecido significativamente.\nLa ejecución de Docker en producción requiere analizar las diversas rutas disponibles, que van desde configuraciones básicas en un solo servidor hasta soluciones distribuidas con Kubernetes.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejecutar-docker-en-producción-muchas-rutas-escoge-sabiamente",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejecutar-docker-en-producción-muchas-rutas-escoge-sabiamente",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "",
    "text": "8.1.1 Aspectos importantes\n\nOrquestación de contenedores:\n\nHerramientas como Kubernetes permiten distribuir contenedores en un clúster, aumentando la tolerancia a fallos y la escalabilidad.\nGoogle desarrolló Kubernetes basándose en su experiencia con Borg, un sistema interno de orquestación.\n\nComplejidad operativa:\n\nAunque Kubernetes y otras soluciones gestionadas simplifican la orquestación, su implementación inicial puede ser desafiante.\n\nServicios gestionados como alternativa:\n\nMuchas empresas prefieren delegar la gestión de la infraestructura a proveedores en la nube para reducir la carga operativa.\n\n\nEl despliegue de Docker en producción puede variar desde configuraciones básicas hasta sistemas distribuidos complejos. La elección depende de las necesidades y prioridades del proyecto.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#cuál-es-el-entorno-de-producción-mínimo-realista",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#cuál-es-el-entorno-de-producción-mínimo-realista",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.2 ¿Cuál es el Entorno de Producción Mínimo Realista?",
    "text": "8.2 ¿Cuál es el Entorno de Producción Mínimo Realista?\nDescribe lo mínimo necesario para ejecutar una aplicación basada en Docker: un solo host con Docker y Docker Compose.\n\n8.2.1 Detalles clave\n\nConfiguración mínima:\n\nUn servidor físico o virtual que soporte Docker.\n\nCompatibilidad con sistemas operativos como Linux (Ubuntu, CentOS), macOS o Windows.\n\nLimitaciones:\n\nVulnerabilidad a fallos de hardware o conectividad.\nMenor tolerancia a fallos y escalabilidad limitada.\n\nRecomendaciones:\n\nImplementar monitoreo externo.\nTener un plan de respaldo y restauración para mitigar riesgos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#servicios-gestionados-en-la-nube",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#servicios-gestionados-en-la-nube",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.3 Servicios Gestionados en la Nube",
    "text": "8.3 Servicios Gestionados en la Nube\nLos servicios gestionados en la nube ofrecen soluciones completas para ejecutar contenedores sin preocuparse por la infraestructura subyacente.\n\n8.3.1 Opciones destacadas\n\nGoogle Kubernetes Engine (GKE):\n\nKubernetes gestionado con soporte de Google.\nCosto competitivo y buena integración con servicios de Google Cloud.\n\nAWS Elastic Beanstalk y EKS:\n\nBeanstalk es una solución simple para principiantes, mientras que EKS es más robusto y adecuado para cargas pesadas.\n\nAzure Kubernetes Service (AKS):\n\nIntegración profunda con herramientas de Microsoft como Visual Studio Code.\n\nDigitalOcean Docker Swarm:\n\nUna solución más simple, aunque su futuro soporte es incierto.\n\n\n\n\n8.3.2 Ventajas de los servicios gestionados\n\nEscalabilidad automática.\nAlta disponibilidad.\nReducción de la complejidad operativa.\n\n\n\n8.3.3 Desafíos\n\nDependencia tecnológica (vendor lock-in).\nCostos recurrentes mayores comparados con configuraciones locales.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejecutar-tu-propio-clúster-de-kubernetes",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejecutar-tu-propio-clúster-de-kubernetes",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.4 Ejecutar tu Propio Clúster de Kubernetes",
    "text": "8.4 Ejecutar tu Propio Clúster de Kubernetes\nPara empresas que buscan mayor personalización o control, ejecutar Kubernetes en infraestructura propia es una opción viable.\n\n8.4.1 Beneficios\n\nControl completo sobre actualizaciones y configuraciones.\nIntegración con soluciones híbridas o privadas como OpenStack o VMware Tanzu.\nPosibilidad de ejecutar Kubernetes en entornos especializados (bare-metal o Raspberry Pi).\n\n\n\n8.4.2 Desafíos\n\nComplejidad técnica y operativa significativa.\nRequiere mayor inversión inicial y habilidades avanzadas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#decidiendo-la-configuración-de-producción-más-adecuada",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#decidiendo-la-configuración-de-producción-más-adecuada",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.5 Decidiendo la Configuración de Producción Más Adecuada",
    "text": "8.5 Decidiendo la Configuración de Producción Más Adecuada\nEsta sección proporciona una guía para elegir la mejor estrategia de despliegue según factores clave.\n\n8.5.1 Factores a considerar\n\nFacilidad de configuración:\n\nQué tan rápido se puede implementar desde un entorno de desarrollo local.\n\nCostos:\n\nCostos iniciales y recurrentes.\n\nElasticidad:\n\nCapacidad para escalar de manera automática o manual según la demanda.\n\nSoporte:\n\nAcceso a asistencia técnica, ya sea comercial o comunitaria.\n\nDisponibilidad:\n\nRobustez frente a fallos de hardware, red o servicio.\n\nAdhesividad:\n\nFacilidad para cambiar la infraestructura a otra solución si es necesario.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejemplo-de-aplicación-shipit-clicker",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejemplo-de-aplicación-shipit-clicker",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.6 Ejemplo de Aplicación: ShipIt Clicker",
    "text": "8.6 Ejemplo de Aplicación: ShipIt Clicker\nEl prototipo del juego “ShipIt Clicker” sirve como ejemplo práctico para experimentar con Docker y Docker Compose.\n\n8.6.1 Componentes del juego\n\nFrontend: Una interfaz simple basada en HTML.\nBackend: Un servidor Node.js con Express.\nBase de datos: Redis para manejar datos.\n\n\n\n8.6.2 Tareas sugeridas\n\nEjecutar docker-compose up para probarlo en un entorno local.\nIdentificar mejoras para optimizar su despliegue en producción.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejercicios-propuestos",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#ejercicios-propuestos",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.7 Ejercicios Propuestos",
    "text": "8.7 Ejercicios Propuestos\n\n8.7.1 Evaluar Alternativas Razonables de Despliegue\nComparar configuraciones iniciales con soluciones más avanzadas, estimar costos y beneficios a corto y largo plazo.\n\n\n8.7.2 Evaluar Dockerfile y docker-compose.yml\nRevisar configuraciones actuales para optimizar la aplicación, ajustando la base del contenedor (FROM) y mejorando escalabilidad y seguridad.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#conclusion",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#conclusion",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.8 Conclusion",
    "text": "8.8 Conclusion\n\nLas estrategias de despliegue tienen compensaciones entre costos, complejidad y capacidades.\nLas configuraciones mínimas son útiles para comenzar, pero deben evolucionar con el tiempo.\nComprender las ventajas y desventajas de cada solución es esencial para elegir la estrategia adecuada.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#tema-de-la-exposición-qué-es-docker-swarm",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#tema-de-la-exposición-qué-es-docker-swarm",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.9 Tema de la exposición, ¿Qué es Docker Swarm?",
    "text": "8.9 Tema de la exposición, ¿Qué es Docker Swarm?\nDocker Swarm es una herramienta de orquestación de contenedores que permite gestionar y escalar aplicaciones distribuidas en varios nodos mediante la creación de clústeres. Sus características principales incluyen:\n\nAlta disponibilidad y tolerancia a fallos.\nEscalabilidad vertical y horizontal.\nBalanceo de carga para distribuir el tráfico uniformemente.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#arquitectura",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#arquitectura",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.10 Arquitectura",
    "text": "8.10 Arquitectura\n\n8.10.1 Clúster\nConjunto de nodos que trabajan juntos.\n\n\n8.10.2 Nodos\n\nManager: Coordina servicios y gestiona configuraciones.\nWorker: Ejecuta tareas asignadas.\n\n\n\n8.10.3 Servicios\nDefinen las aplicaciones y políticas de estado.\n\n\n8.10.4 Tareas\nInstancias de servicios ejecutadas en nodos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#comandos-básicos",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#comandos-básicos",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.11 Comandos básicos",
    "text": "8.11 Comandos básicos\n\n8.11.1 Crear un clúster\ndocker swarm init --advertise-addr &lt;IP-del-host&gt;\n\n\n8.11.2 Agregar nodos al clúster\ndocker swarm join --token &lt;token&gt; &lt;IP-del-host&gt;\n\n\n8.11.3 Revisar nodos\ndocker node ls\n\n\n8.11.4 Desplegar servicios\ndocker service create --name &lt;nombre_servicio&gt; --replicas &lt;número&gt; -p &lt;puerto:puerto&gt; &lt;imagen&gt;\n\n\n8.11.5 Gestionar máquinas virtuales con Docker Machine\n\nCrear nodos virtuales:\ndocker-machine create --driver virtualbox &lt;nombre_nodo&gt;\nConectar a nodos:\ndocker-machine ssh &lt;nombre_nodo&gt;\nSalir del nodo:\nexit",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#comparativa-docker-swarm-vs.-kubernetes",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#comparativa-docker-swarm-vs.-kubernetes",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.12 Comparativa Docker Swarm vs. Kubernetes",
    "text": "8.12 Comparativa Docker Swarm vs. Kubernetes\n\n\n\n\n\n\n\n\nCaracterística\nKubernetes\nDocker Swarm\n\n\n\n\nEscalabilidad\nAlta\nMedia\n\n\nFacilidad de uso\nComplejo, amplio soporte\nSencillo y fácil\n\n\nGestión de despliegues\nAvanzada\nBásica\n\n\nGestión de redes\nComplejo, con plugins\nBásica\n\n\nIntegración con ecosistema\nAmplia\nIntegrada con Docker\n\n\nActualizaciones\nSoporte avanzado\nLimitado",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#casos-de-uso",
    "href": "Alternatives_for_Deploying_and_Running_containers_in_Production.html#casos-de-uso",
    "title": "8  Alternativas para implementar y ejecutar contenedores en producción",
    "section": "8.13 Casos de uso",
    "text": "8.13 Casos de uso\n\nAplicaciones web: Despliegue escalable y tolerante a fallos.\nMicroservicios: Gestión de aplicaciones complejas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Alternativas para implementar y ejecutar contenedores en producción</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html",
    "href": "deploying_docker_compose.html",
    "title": "9  Desplegar aplicaciones con Docker Compose.",
    "section": "",
    "text": "9.1 Requisitos para su implementación.\nEl escenario de implementación práctico más simple posible de una aplicación empaquetada con Docker implica ejecutar Docker Compose en un solo host, sin embargo, tiene algunas desventajas importantes en términos de rendimiento y disponibilidad.\nPara continuar con la implementación, necesitará una computadora que ejecute un sistema operativo Linux moderno de la misma arquitectura que su sistema de desarrollo, con suficiente memoria, procesador y capacidad de almacenamiento para ejecutar su aplicación.\nDeberá tener alguno de estos sistemas operativos linux que admitan Docker:  - Red Hat\n- Ubuntu 16.04 o superior\n- Amazon Linux 2\n- Debian\no alguna distribución centrada en Docker como Container Linux o CoreOS.\nAdemás, antes de configurar el software en el host, debe asegurarse de que tenga una dirección IP estable. A veces, se las denomina direcciones IP estáticas o direcciones IP elásticas en un contexto de AWS.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "href": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "title": "9  Desplegar aplicaciones con Docker Compose.",
    "section": "9.2 Implementación mediante archivos de configuración y scripts de soporte.",
    "text": "9.2 Implementación mediante archivos de configuración y scripts de soporte.\nPara implementar nuestra aplicación en un servidor de producción, utilizaremos una combinación de comandos simples y scripts de soporte que inician o actualizan el conjunto de contenedores en ejecución. Comencemos por analizar en detalle los dos archivos más importantes necesarios para la implementación: Dockerfile y docker­compose.yml.\nEste es un ejemplo de Dockerfile basado en la producción de un juego, deberás adaptar tu Dockerfile según las necesidades de tu aplicación: FROM alpine:20191114\nRUN apk update &&\napk add nodejs nodejs-npm\nRUN addgroup -S app && adduser -S -G app app\nRUN mkdir -p /app/public /app/server\nADD src/package.json* /app/\nWORKDIR /app\nRUN npm -s install\nCOPY src/public/ /app/public/\nCOPY src/server/ /app/server/\nCOPY src/.babelrc /app/\nRUN npm run compile\nUSER app\nEXPOSE 3000\nENTRYPOINT [“npm”, “start”]\n\nEste es un ejemplo de un archivo de docker-compose:\nversion: ‘3’\nservices:\nshipit-clicker-web-v2:\nbuild: .\nenvironment:\n- APP_ID=shipit-clicker-v2\n- OPENAPI_SPEC=/api/v1/spec\n- OPENAPI_ENABLE_RESPONSE_VALIDATION=false\n- PORT=3000\n- LOG_LEVEL={LOG_LEVEL:-debug}\n- REQUEST_LIMIT=100kb\n- REDIS_HOST=\\({REDIS_HOST:-redis} \\\n- REDIS_PORT=\\){REDIS_PORT:-6379}\n- SESSION_SECRET=${SESSION_SECRET:-mySecret-v2}\n\nAhora, es necesario definir una configuración de red para el contenedor principal para luego vincularlos a los demás contenedores. Un ejemplo es: ports: - {PORT:-3006}:3000\nnetworks:\n- private-redis-shipit-clicker-v2\nlinks:\n- redis\ndepends_on:\n- redis\n\nAhora bien, al ejecutar un sitio en producción, es posible que deba realizar algunas operaciones con frecuencia como reiniciarlo o actualizarlo. Para resolver esto puede agregar scripts con el objetivo de automatizar procesos, los más comunes son aquellos para reiniciar la aplicación y implementar cambios.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación",
    "href": "deploying_docker_compose.html#implementación",
    "title": "9  Desplegar aplicaciones con Docker Compose.",
    "section": "9.3 Implementación",
    "text": "9.3 Implementación\nPara iniciar los servicios en segundo plano, use el siguiente comando: $ docker-compose up -d\nVerifique que los servicios se están ejecutando con: $ docker-compose ps\nCompruebe si los registros del sistema muestran algún error: $ docker-compose logs\nMientras no veas una secuencia de mensajes de error en los registros, deberías poder acceder al sitio web en la dirección IP del servidor (por ejemplo, en http://192.0.2.10)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "href": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "title": "9  Desplegar aplicaciones con Docker Compose.",
    "section": "9.4 Limitaciones de implementación en un solo host",
    "text": "9.4 Limitaciones de implementación en un solo host\nSi el contenedor del servidor de base de datos o el contenedor del servicio web fallan y no se pueden reiniciar automáticamente, el sitio no funcionará y será necesaria una intervención manual. La solución puede ser tan simple como conectarse por SSH y reiniciar el servidor. Pero, a veces, un solo servidor tendrá tan poca memoria que deberá reiniciarse manualmente desde una consola de nivel superior o incluso apagar y encender manualmente.\nDependiendo de su proveedor de alojamiento, el sistema operativo base con el que comience y cómo estén configurados los contenedores Docker, puede experimentar inestabilidad que sea difícil de rastrear. Tal vez su host se reinicie con frecuencia debido a que la red del proveedor detecta hardware inestable o condiciones de red inestables. Tal vez haya configurado su sistema operativo para instalar actualizaciones automáticas y aplicarlas provoque períodos de interrupciones. Tal vez la aplicación crezca en la memoria hasta que provoque una falla de algún tipo.\nSi ha alojado su aplicación en un único servidor físico o virtual, debe asegurarse de realizar copias de seguridad del sistema con regularidad, la pérdida del host podría provocar que se pierda toda la información.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html",
    "href": "sharing_containers_used_docker_hub.html",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "10.1 ¿Qué es Docker Hub?\nDocker Hub es una plataforma centralizada que permite a los desarrolladores almacenar, compartir y gestionar imágenes de contenedores. Es el repositorio oficial de Docker, donde se pueden encontrar imágenes públicas y privadas, facilitando la colaboración y la reutilización de contenedores en diferentes entornos.\nDocker Hub es un servicio basado en la nube que proporciona un registro de imágenes de Docker. Permite a los desarrolladores:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "Almacenar Imágenes: Guardar imágenes de contenedores en un lugar centralizado.\nCompartir Imágenes: Hacer que las imágenes estén disponibles para otros desarrolladores.\nAutomatizar Builds: Configurar pipelines de CI/CD para construir y desplegar imágenes automáticamente.\nGestionar Repositorios: Organizar imágenes en repositorios públicos o privados.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.2 Beneficios de Usar Docker Hub",
    "text": "10.2 Beneficios de Usar Docker Hub\n\nColaboración: Facilita el trabajo en equipo al permitir compartir imágenes de contenedores fácilmente.\nReutilización: Permite reutilizar imágenes existentes, ahorrando tiempo y esfuerzo en la configuración de entornos.\nDistribución: Facilita la distribución de aplicaciones y servicios en diferentes entornos y plataformas.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.3 Pasos para Compartir Contenedores en Docker Hub",
    "text": "10.3 Pasos para Compartir Contenedores en Docker Hub\n\nCrear una Cuenta en Docker Hub: Regístrate en Docker Hub para crear una cuenta gratuita.\nIniciar Sesión desde la Línea de Comandos: Usa el comando docker login para iniciar sesión en Docker Hub desde tu terminal.\nConstruir una Imagen de Docker: Crea una imagen de Docker usando un Dockerfile y el comando docker build.\nEtiquetar la Imagen: Etiqueta la imagen con tu nombre de usuario de Docker Hub y el nombre del repositorio.\nSubir la Imagen a Docker Hub: Usa el comando docker push para subir la imagen etiquetada a Docker Hub.\nCompartir la Imagen: Comparte el enlace del repositorio de Docker Hub con otros desarrolladores para que puedan descargar y usar la imagen.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "href": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.4 Ejemplo Práctico",
    "text": "10.4 Ejemplo Práctico\nA continuación, se muestra un ejemplo práctico de cómo compartir una imagen de contenedores en Docker Hub:\n\nConstruir la Imagen: sh docker build -t myapp:late  st .\nEtiquetar la Imagen: sh docker tag myapp:latest your-dockerhub-username/myapp:latest\nIniciar Sesión en Docker Hub: sh docker login\nSubir la Imagen: sh docker push your-dockerhub-username/myapp:latest\nCompartir el Enlace: Comparte el enlace https://hub.docker.com/r/your-dockerhub-username/myapp con otros desarrolladores.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "href": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "title": "10  Compartir Contenedores Usando Docker Hub",
    "section": "10.5 Consideraciones de Seguridad",
    "text": "10.5 Consideraciones de Seguridad\n\nImágenes Privadas: Si no deseas que tus imágenes sean públicas, puedes configurar repositorios privados en Docker Hub.\nAutenticación: Asegúrate de usar autenticación segura y gestionar tus credenciales de Docker Hub de manera adecuada.\nActualizaciones: Mantén tus imágenes actualizadas para incluir las últimas mejoras y parches de seguridad.\n\nAl finalizar este capítulo, tendrás las habilidades necesarias para compartir tus contenedores con otros desarrolladores y utilizar imágenes de contenedores de la comunidad, mejorando así tu flujo de trabajo y la colaboración en proyectos.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "Docker_Security_Fundamentals_and_Best_Practices.html",
    "href": "Docker_Security_Fundamentals_and_Best_Practices.html",
    "title": "11  Seguridad de Docker, Fundamentos y Mejores prácticas",
    "section": "",
    "text": "11.1 Introducción\nEn el desarrollo moderno de software, Docker se ha convertido en una herramienta esencial para la creación y gestión de contenedores. Su capacidad para empaquetar aplicaciones junto con sus dependencias garantiza consistencia en entornos de desarrollo, pruebas y producción. Sin embargo, el uso de contenedores plantea desafíos relacionados con la seguridad y las buenas prácticas de implementación.\nEste documento explora los fundamentos de la seguridad en Docker y las mejores prácticas recomendadas para garantizar la protección de las imágenes y los contenedores. Se analizarán técnicas como el uso de imágenes base mínimas, restricciones de privilegios en contenedores y herramientas como DOCKER_CONTENT_TRUST para verificar la integridad de las imágenes. Además, se destacarán métodos para minimizar riesgos durante la construcción y despliegue de contenedores.\nEl objetivo es proporcionar una guía práctica para desarrollar y operar aplicaciones en entornos de contenedores de manera segura, optimizando el uso de Docker en escenarios reales.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Seguridad de Docker, Fundamentos y Mejores prácticas</span>"
    ]
  },
  {
    "objectID": "Docker_Security_Fundamentals_and_Best_Practices.html#fundamentos-de-la-seguridad-en-docker",
    "href": "Docker_Security_Fundamentals_and_Best_Practices.html#fundamentos-de-la-seguridad-en-docker",
    "title": "11  Seguridad de Docker, Fundamentos y Mejores prácticas",
    "section": "11.2 Fundamentos de la Seguridad en Docker",
    "text": "11.2 Fundamentos de la Seguridad en Docker\nLa seguridad en Docker se centra en proteger tanto las imágenes como los contenedores. Las imágenes son la base de los contenedores y, por lo tanto, su seguridad es primordial. Se recomienda utilizar imágenes base mínimas y firmadas para reducir la superficie de ataque. Docker Hub, como repositorio de imágenes, ofrece imágenes certificadas que han sido revisadas para garantizar su autenticidad. Sin embargo, es crucial que los desarrolladores verifiquen la fuente de las imágenes y estén atentos a las alertas de seguridad.\n\nSeguridad de Imágenes de Docker\nLas imágenes son el pilar sobre el cual se construyen los contenedores en Docker. Garantizar la seguridad de estas imágenes es esencial para evitar problemas de seguridad. Prácticas recomendadas:\n\nVerificación de Imágenes:Usar imágenes oficiales y certificadas de Docker Hub reduce la probabilidad de descargar imágenes comprometidas. En el pasado, se han identificado imágenes maliciosas que explotaban vulnerabilidades como el “cryptojacking”.\n\nRiesgos comunes: Las imágenes en Docker Hub pueden contener malware si no se validan. Ejemplo: en 2018, se detectaron imágenes maliciosas destinadas al cryptojacking.\nSe recomienda usar imágenes firmadas: Docker ofrece un mecanismo de firma que ayuda a verificar la autenticidad de las imágenes. Además, verificar los hashes (como sha256) de las imágenes asegura que no han sido modificadas.\n\n\nDocker Content Trust (DCT):Este mecanismo utiliza firmas digitales para garantizar que las imágenes no han sido alteradas. Aunque está deshabilitado por defecto, habilitar DCT asegura la autenticidad de las imágenes descargadas.\nUso de Imágenes Base Mínimas: A menudo, las imágenes completas incluyen muchos paquetes innecesarios que pueden contener vulnerabilidades no actualizadas.\n\nSe recomienda usar imágenes base mínimas, como Alpine, que tienen un tamaño reducido (alrededor de 5 MB) y contienen solo lo esencial para ejecutar la aplicación. Estas imágenes son más seguras porque limitan la cantidad de código vulnerable y permiten un control más detallado sobre lo que se incluye en el contenedor.\n\nArchivo .dockerignore:\n\nEste archivo excluye archivos innecesarios en el proceso de construcción, como binarios y configuraciones sensibles.\nEjemplo: Excluir claves privadas con reglas como **/*.pem o carpetas como .git.\n\n\nRestricción de Privilegios en Contenedores\nEl control de privilegios dentro de un contenedor es una de las mejores maneras de mejorar la seguridad. Docker permite configurar varios parámetros para limitar los privilegios de los contenedores, reduciendo la posibilidad de explotación.\n\nUso de –security-opt=no-new-privileges:Esta opción impide que los contenedores y sus procesos obtengan privilegios adicionales, lo cual ayuda a proteger el host subyacente y evitar que los atacantes escalen privilegios.\nSistema de archivos de solo lectura: Configurar volúmenes en modo de solo lectura protege contra modificaciones accidentales o maliciosas dentro del contenedor.\nUsuarios y grupos específicos: Asignar usuarios con permisos limitados en lugar de ejecutar procesos como usuario raíz.\n\nConstrucción Segura de Imágenes Cuando se crean imágenes personalizadas para aplicaciones, es esencial seguir ciertas prácticas para evitar posibles riesgos.\n\nUso de COPY en lugar de ADD: Mientras que ADD permite descargar archivos remotos y descomprimirlos automáticamente, esto aumenta el riesgo de incluir contenido inseguro. COPY es más seguro y controlado.\n\nRiesgo de ADD: Descargar archivos desde URLs no verificadas puede comprometer la seguridad.\n\nArchivo .dockerignore: Este archivo ayuda a excluir archivos sensibles, como claves privadas o tokens de API, durante el proceso de construcción.\nCopias recursivas: Evitar incluir accidentalmente archivos sensibles al usar copias recursivas.\n\nSolución: Actualizar .dockerignore para excluir archivos como .env o secretos de API.\n\nLimitar el Tamaño de las Imágenes: Utilizar imágenes base mínimas y eliminar paquetes o dependencias innecesarias es clave para reducir la superficie de ataque. Menos código implica menos riesgo de vulnerabilidades.\nEvitar incluir datos confidenciales: Las claves y configuraciones sensibles deben ser gestionadas mediante herramientas externas como HashiCorp Vault o servicios en la nube.\n\nMitigación de Vulnerabilidades\nEl monitoreo y la prevención son esenciales para mantener un entorno seguro:\n\nAuditorías regulares: Revisar continuamente las imágenes y contenedores para identificar vulnerabilidades.\nSistemas de detección y protección: Utilizar herramientas como escáneres de seguridad para detectar configuraciones incorrectas o imágenes maliciosas.\nCapacidades limitadas: Restringir las funciones del contenedor para que solo accedan a los recursos necesarios.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Seguridad de Docker, Fundamentos y Mejores prácticas</span>"
    ]
  },
  {
    "objectID": "Docker_Security_Fundamentals_and_Best_Practices.html#conclusión",
    "href": "Docker_Security_Fundamentals_and_Best_Practices.html#conclusión",
    "title": "11  Seguridad de Docker, Fundamentos y Mejores prácticas",
    "section": "11.3 Conclusión",
    "text": "11.3 Conclusión\nImplementar prácticas de seguridad en Docker protege los entornos de desarrollo y producción. Verificar imágenes, limitar privilegios, y optimizar construcciones reduce la exposición a vulnerabilidades. Estas medidas, junto con la restricción de recursos, aseguran un despliegue seguro y eficiente, estableciendo una base sólida para una gestión confiable de contenedores.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Seguridad de Docker, Fundamentos y Mejores prácticas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html",
    "href": "advanced_docker_security.html",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "",
    "text": "12.1 Introducción\nEn este capítulo, exploraremos temas avanzados de seguridad en Docker, enfocándonos en la gestión segura de datos sensibles y etiquetado de metadatos. Los temas clave incluyen: - Almacenamiento seguro de secrets en Docker - El concepto y utilidad del registro Raft - Cómo agregar, inspeccionar y eliminar secrets - Uso efectivo de etiquetas para imágenes seguras - Implementación de etiquetas de metadatos y el archivo security.txt",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#almacenamiento-seguro-de-secrets-en-docker",
    "href": "advanced_docker_security.html#almacenamiento-seguro-de-secrets-en-docker",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "12.2 Almacenamiento Seguro de Secrets en Docker",
    "text": "12.2 Almacenamiento Seguro de Secrets en Docker\n\n12.2.1 ¿Qué son los Secrets?\nLos secrets se refieren a datos sensibles como:\n\nTokens de API\nCredenciales de bases de datos\nClaves privadas (por ejemplo, SSH, Azure, etc)\n\nAlmacenar secrets de manera segura evita que los atacantes accedan a ellos. La funcionalidad de secrets en Docker cifra estos datos y los comparte de manera segura con los contenedores en un Swarm.\n\n\n12.2.2 Registro Raft\nEl registro Raft asegura consenso y tolerancia a fallos entre los nodos de Swarm. Los secrets se almacenan de manera segura en este registro y se comparten entre nodos. Por ejemplo, un secret puede ser accedido a través del sistema de archivos temporal:\n/run/secrets/&lt;nombre_del_secret&gt;\nSe puede habilitar el bloqueo automático de Swarm para mayor seguridad con:\ndocker swarm init --autolock",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#agregar-inspeccionar-y-eliminar-secrets",
    "href": "advanced_docker_security.html#agregar-inspeccionar-y-eliminar-secrets",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "12.3 Agregar, Inspeccionar y Eliminar Secrets",
    "text": "12.3 Agregar, Inspeccionar y Eliminar Secrets\n\n12.3.1 Agregar Secrets\nCrea un secret utilizando el siguiente comando:\ndocker secret create &lt;nombre_del_secret&gt; &lt;ruta_del_archivo&gt;\nComo ejemplo de ello:\ndocker secret create my_key ./id_rsa\n\n\n12.3.2 Inspeccionar Secrets\nLista todos los secrets:\ndocker secret ls\nInspeccionar un secret especifico:\ndocker secret inspect &lt;nombre_del_secret&gt;\n\n\n12.3.3 Eliminar Secrets\nElimina un secret:\ndocker secret rm &lt;nombre_del_secret&gt;\nElimina un secreto de un servicio en ejecución:\ndocker service update --secret-rm &lt;nombre_del_secret&gt; &lt;nombre_del_servicio&gt;",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#secrets-en-acción-ejemplo",
    "href": "advanced_docker_security.html#secrets-en-acción-ejemplo",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "12.4 Secrets en Acción – Ejemplo",
    "text": "12.4 Secrets en Acción – Ejemplo\n\n12.4.1 Ejemplo de Flujo de Trabajo\n\nInicializa un Swarm:\n\ndocker swarm init\n\nCrea un secret:\n\ndocker secret create ssh_key ~/.ssh/id_rsa\n\nVerifica el secret:\n\ndocker secret ls\n\nUsa el secret en un servicio:\n\ndocker service create --name my_service \\ --secret ssh_key &lt;nombre_de_la_imagen&gt;\n\nAccede al secret dentro del contenedor:\n\ncat /run/secrets/ssh_key",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#etiquetas-de-docker-para-seguridad",
    "href": "advanced_docker_security.html#etiquetas-de-docker-para-seguridad",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "12.5 Etiquetas de Docker para Seguridad",
    "text": "12.5 Etiquetas de Docker para Seguridad\nLas etiquetas son esenciales para identificar y usar la imagen correcta de Docker. Para mejorar la seguridad se debe seguir los siguientes consejos:\n\nUsa etiquetas específicas para cada entorno (por ejemplo, 1.0.0-dev, 1.0.0-prod).\nEmplea versionado semántico.\n\nSi no tiene conocimiento sobre versionado semantico puede acceder a Información sobre versionado semántico.\nEjemplo de creación de un secret con etiquetas de versión:\ndocker secret create --label env=dev --label ver=1.0.0 ssh_key ~/.ssh/id_rsa",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#uso-de-etiquetas-para-la-aplicación-de-metadatos",
    "href": "advanced_docker_security.html#uso-de-etiquetas-para-la-aplicación-de-metadatos",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "12.6 Uso de Etiquetas para la Aplicación de Metadatos",
    "text": "12.6 Uso de Etiquetas para la Aplicación de Metadatos\nLas etiquetas anotan contenedores con metadatos para una gestión más sencilla. Agrega etiquetas en un Dockerfile:\nLABEL \"version\"=\"1.0.0\"\nLABEL \"description\"=\"Contenedor de desarrollo.\"\nLABEL \"security.txt\"=\"https://example.com/security.txt\"\nVisualizar etiquetas:\ndocker inspect &lt;id_del_contenedor&gt;",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "advanced_docker_security.html#resumen-final",
    "href": "advanced_docker_security.html#resumen-final",
    "title": "12  Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas",
    "section": "12.7 Resumen Final",
    "text": "12.7 Resumen Final\nEn este capítulo, cubrimos:\n\nEl almacenamiento seguro y la gestión de secrets utilizando Docker Swarm.\nEl rol del registro Raft en mantener consistencia y seguridad.\nLa importancia de las etiquetas de Docker y los metadatos para la gestión eficiente y segura de imágenes.\n\nAl finalizar esta seccion deberias ser capaz de manejar los secrets de tus aplicaciones correctamente, sin embargo si deseas ampliar tu conocimiento sobre el tema tratado, se recomienda ingresar a:\n\nDocumentación de Secrets de Docker.\nVersionado Semántico.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Seguridad Avanzada en Docker – Secrets, Comandos Secretos y Etiquetas</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html",
    "title": "13  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "",
    "text": "13.1 Registro de Docker y registro de tiempo de ejecución de contenedores\nPara entender el comportamiento de una aplicación en producción, los desarrolladores y operadores confían en herramientas de registro, monitoreo y alertas, las cuales permiten identificar si el sistema funciona correctamente y facilitan la solución de problemas cuando surgen inconvenientes. Con la creciente complejidad de los sistemas, aumenta la necesidad de una observabilidad más profunda sin alterar el código, en este apartado se vera el cómo instrumentar aplicaciones y entornos para mejorar la observabilidad, incluyendo el uso de Kubernetes, CloudWatch, S3, Prometheus y Grafana para gestionar registros, métricas y alertas, así como explorar datos específicos de código y base de datos con Jaeger.\nCada contenedor Docker, ya sea que se ejecute localmente o en la nube, produce sus propios registros los cuales se puede consultar. en el caso de Kubernetes cada contenedor Docker en un pod genera registros, que el sistema almacena temporalmente hasta 10 MB por contenedor, estos registros se pueden consultar con la herramienta kubectl logs, pero son eliminados cuando un pod se elimina o un contenedor se reinicia, lo que impide su retención permanente, esto puede dificultar la solución de problemas si los registros necesarios ya no están disponibles. Por ello, es importante considerar soluciones que superen estas limitaciones y mejoren la gestión y retención de registros.\nUn sistema de gestión de registros ideal debe incluir características como la visualización centralizada de mensajes, baja latencia para acceder a eventos recientes, recopilación de registros de diversas fuentes (pods, nodos, despliegues y contenedores Docker en Kubernetes), una interfaz de búsqueda intuitiva con opciones para guardar consultas, visualización de histogramas interactivos para explorar datos, alertas basadas en el contenido de los registros y la posibilidad de configurar el tiempo de retención de los mensajes.\nAlgunos de los sistemas de gestion de registros de terceros, son:\nEn cuanto a proveedores en la nube, existen:",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#registro-de-docker-y-registro-de-tiempo-de-ejecución-de-contenedores",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#registro-de-docker-y-registro-de-tiempo-de-ejecución-de-contenedores",
    "title": "13  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "",
    "text": "Splunk\nElasticsearch\nLoggly\nPapertrail\n\n\n\nAWS CloudWatch\nGoogle Cloud Logging\nMicrosoft Azure Monitor Logs",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-liveness-readiness-y-startup-en-kubernetes",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#uso-de-las-sondas-de-liveness-readiness-y-startup-en-kubernetes",
    "title": "13  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "13.2 Uso de las sondas de Liveness, Readiness y Startup en Kubernetes",
    "text": "13.2 Uso de las sondas de Liveness, Readiness y Startup en Kubernetes\nKubernetes tiene varios tipos de controles de salud, llamados sondas , para garantizar que los contenedores que maneja Docker están en condiciones de procesar el tráfico. Los tipos de sondas abordan inquietudes como:\n\nLiveness: Determina si una aplicación puede procesar solicitudes\nReadiness: Determina si un contenedor está listo para recibir tráfico real, especialmente si depende de recursos externos que tienen que ser accesibles.\nStartup: Determina si un contenedor está listo para empezar a tomar los otros dos tipos de tráfico, destinado a aplicaciones heredadas de inicio lento para darles tiempo para iniciarse.\n\n\n13.2.1 Usar una sonda Liveness para ver si un contenedor puede responder\nA continuación, se muestra un fragmento de configuración YAML, el cual define una sonda de “liveness” para un contenedor en Kubernetes, utilizada para verificar si el contenedor está funcionando correctamente\nlivenessProbe:\nhttpGet:\npath: /\nport: http\nUna sonda de liveness es importante porque permite que Kubernetes detecte si el contenedor está en un estado no funcional. Si la sonda falla, Kubernetes reiniciará el contenedor automáticamente para intentar restaurar su funcionalidad.\n\n\n13.2.2 Usar una sonda Readiness para garantizar que un servicio pueda recibir trafico\nEl uso de una sonda de readiness en Kubernetes asegura que una aplicación esté completamente lista para manejar tráfico antes de ser incluida en el balanceador de carga del clúster.\nreadinessProbe:\nhttpGet:\npath: /api/v2/games/ready\nport: http\nEste fragmento de configuración YAML define una sonda de “readiness” en Kubernetes, que se utiliza para determinar si un contenedor está listo para aceptar tráfico.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#recopilación-de-métricas-y-envío-de-alertas-con-prometheus",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#recopilación-de-métricas-y-envío-de-alertas-con-prometheus",
    "title": "13  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "13.3 Recopilación de métricas y envío de alertas con Prometheus",
    "text": "13.3 Recopilación de métricas y envío de alertas con Prometheus\nPrometheus es una herramienta clave en Kubernetes para recopilar y analizar métricas del sistema. Recoge datos sobre el uso de CPU, almacenamiento y estado de las aplicaciones, entre otros, a través de endpoints como /metrics. Funciona consultando estos puntos y almacenando la información con etiquetas y marcas de tiempo para facilitar su búsqueda, también permite crear alertas y visualizar el rendimiento, ayudando a los operadores a monitorear y mejorar la salud del sistema. Si bien Prometheus puede representar gráficamente los resultados de las consultas por sí solo, los usuarios de Kubernetes suelen utilizar Grafana en conjunto con Prometheus para proporcionar gráficos más sofisticados y tableros de instrumentos.\n\n13.3.1 Recopilación de métricas\n\nModelo de recolección (Pull): Prometheus utiliza un modelo de “pull” para obtener datos, es decir, periódicamente consulta endpoints HTTP expuestos por las aplicaciones y servicios para recopilar métricas.\nEndpoint estándar: Generalmente, las métricas están disponibles en el endpoint /metrics.\nDatos recopilados: Incluyen el uso de CPU, memoria, almacenamiento, estado de las aplicaciones, entre otros.\nInstrumentación de aplicaciones Las aplicaciones se instrumentan para exponer sus métricas, esto se logra utilizando bibliotecas específicas de Prometheus disponibles para varios lenguajes de programación como Python, Java, entre otros.\nIntegración con Kubernetes: En un clúster de Kubernetes: Anotaciones: Recursos como pods y DaemonSets usan anotaciones para indicar a Prometheus qué endpoints consultar.\nNode Exporter: Un DaemonSet llamado node_exporter se ejecuta en cada nodo para exponer métricas específicas del sistema, como el uso del disco o la carga del CPU.\nEtiquetas y almacenamiento: Prometheus asocia cada métrica con: Un nombre descriptivo. Etiquetas en formato clave-valor Una marca de tiempo precisa a nivel de milisegundos.\n\nEstas características permiten almacenar métricas de manera eficiente y realizar consultas rápidas en su base de datos de series temporales.\n\n\n13.3.2 Envío de alertas\n\nAdministrador de alertas: Prometheus incluye Alertmanager, un componente que gestiona las alertas generadas a partir de las reglas definidas en Prometheus.\nReglas de alerta: Se configuran en archivos YAML y definen condiciones específicas para generar alertas.\nCanales de notificación: Alertmanager puede enviar alertas a múltiples canales, como correo electrónico, Slack, Microsoft Teams o PagerDuty.\nFlujo de trabajo de alertas Prometheus evalúa las métricas recolectadas en tiempo real según las reglas definidas, cuando una condición se cumple, Prometheus envía la alerta a Alertmanager, el cual agrupa, silencia o enruta las alertas a los destinatarios según las configuraciones definidas.\nVisualización de métricas para prevenir alertas: Herramientas como Grafana suelen integrarse con Prometheus para proporcionar dashboards interactivos, estos permiten monitorear tendencias y detectar posibles problemas antes de que se generen alertas.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#visualización-de-datos-operativos-con-grafana",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#visualización-de-datos-operativos-con-grafana",
    "title": "13  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "13.4 Visualización de datos operativos con Grafana",
    "text": "13.4 Visualización de datos operativos con Grafana\nGrafana se instala y está disponible a través de un LoadBalancer en Kubernetes, que en EKS utiliza un Elastic Load Balancer de AWS. Una vez que se ingresa a la consola de Grafana, se puede explorar los paneles y consultar datos con Prometheus, aunque algunos paneles, como el de “Kubernetes All nodes”, podrían no mostrar toda la información, para solucionar eso se puede agregar paneles de la comunidad con estadísticas más completas, para ello es necesario revisar el panel de “Kubernetes pods”, aqui se puede ajustae el rango de tiempo para observar datos de un día o una semana, además, se puede hacer zoom en áreas específicas para analizar detalles.\nGrafana ofrece una variedad de paneles tanto oficiales como de la comunidad en su sitio web, para añadir uno, se puede usar la opción “Importar” e ingresar un ID de panel o una URL. Algunos paneles recomendados son:\n\nCluster Monitoring para Kubernetes : Muestra el consumo de CPU, memoria y recursos de red por los pods.\nKubernetes Cluster (Prometheus) : Presenta métricas críticas del clúster.\n1 Node Exporter for Prometheus Dashboard ES : Proporciona métricas detalladas de CPU, disco y red del clúster.\nNode Exporter Full : Muestra todas las métricas posibles de Prometheus.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#monitoreo-del-rendimiento-de-aplicaciones-con-jaeger",
    "href": "Monitoring_Docker_Using_Prometheus_Grafana_Jaeger.html#monitoreo-del-rendimiento-de-aplicaciones-con-jaeger",
    "title": "13  Monitoreo de Docker usando Prometheus, Grafana y Jaeger",
    "section": "13.5 Monitoreo del rendimiento de aplicaciones con Jaeger",
    "text": "13.5 Monitoreo del rendimiento de aplicaciones con Jaeger\nJaeger es un marco de seguimiento de aplicaciones de código abierto que permite a los desarrolladores y operadores del sistema recopilar información de una aplicación en ejecución y determinar cómo la aplicación pasa su tiempo y cómo interactúa con otros componentes del sistema distribuido, utilizando la API OpenTracing.\n\n13.5.1 Componentes de Jaeger\nAlgunos de los componentes importantes que conforman el ecosistema de Jaeger son los siguientes:\n\nLas librerías cliente disponibles como paquetes o directamente desde GitHub\nLos agentes Jaeger, utilizados para escuchar los spans\nEl recolector, encargado de agregar los datos enviados desde los agentes\nJaeger query, para analizar los datos a través de una interfaz de usuario\nEl Ingester, que nos permite recopilar datos de temas Kafka y luego escribir los datos a servicios como AWS Elasticsearch.\n\nLo que vimos anteriormente es cómo instalar Jaeger localmente, sin embargo, también es posible desplegarlo en un entorno de Kubernetes utilizando Kubernetes Operator, que es un recurso especializado para gestionar la instalación y operación de aplicaciones complejas. Para instalar Jaeger en Kubernetes, se puede seguir las instrucciones del repositorio oficial y ejecutar los comandos kubectl proporcionados. Esto incluye la creación del espacio de nombres del operador y la configuración de los permisos adecuados a través de una vinculación de roles, lo que garantiza que Jaeger funcione correctamente en todos los espacios de nombres del clúster.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Monitoreo de Docker usando Prometheus, Grafana y Jaeger</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html",
    "href": "Understanding_Azure _DevOps_Pipelines.html",
    "title": "14  Azure DevOps Pipelines",
    "section": "",
    "text": "14.1 Introducción\nAzure DevOps Pipelines es una solución de automatización para la construcción, prueba e implementación de aplicaciones en entornos de desarrollo, prueba y producción. Su objetivo es optimizar el flujo de trabajo de desarrollo de software mediante la integración y entrega continua (CI/CD), reduciendo errores y acelerando los despliegues.\nEste informe explora los conceptos esenciales de Azure DevOps Pipelines, su implementación y mejores prácticas, proporcionando una guía detallada para comprender y utilizar eficazmente esta herramienta.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#implementación-cicd",
    "href": "Understanding_Azure _DevOps_Pipelines.html#implementación-cicd",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.2 Implementación CI/CD",
    "text": "14.2 Implementación CI/CD\nEl CI/CD (Integración y Entrega Continua) es un conjunto de prácticas de desarrollo de software que busca automatizar la integración de código, la ejecución de pruebas y el despliegue en producción.\n\n14.2.1 Integración Continua (CI)\nLa integración continua (CI) es una práctica de ingeniería de software en la que los desarrolladores de un equipo integran modificaciones de código en un repositorio central varias veces al día. Cuando una modificación de código se integra en una rama en particular (normalmente con una solicitud de incorporación de cambios, como se explicó en el capítulo anterior), se activa una nueva compilación para comprobar el código y detectar errores de integración rápidamente. Además, durante esta fase se ejecutan pruebas automáticas (si están disponibles) para comprobar si hay errores.\n\nBeneficios de CI:\n\n\nDetectar y corregir errores de integración de manera temprana.\nFacilitar la colaboración en equipos grandes.\nMantener un código base siempre en estado funcional.\n\n\n\n14.2.2 Entrega Continua (CD)\nEl CD es el proceso que viene después del proceso de CI. En este proceso, el resultado de la fase de CI se empaqueta y se entrega a la etapa de producción sin errores. Esto es extremadamente útil para que siempre tengamos una rama maestra que esté probada, sea consistente y esté lista para implementarse.\n\nFases clave de CD:\n\n\nDespliegue en Pre-Producción: Se ejecutan pruebas en un entorno similar al de producción.\nPruebas Automatizadas: Validaciones adicionales para prevenir errores en producción.\nDespliegue en Producción: Publicación final de la aplicación para los usuarios finales.\n\nEtapas Claves del CI/CD\nUn pipeline de CI/CD estándar incluye las siguientes fases:\n\nCommit: Los desarrolladores integran sus cambios al repositorio.\nBuild: Se compila el código y se generan artefactos ejecutables.\nTest: Se ejecutan pruebas unitarias y de integración.\nDespliegue en Producción: Se implementa el código en un entorno de producción estable.\n\nBeneficios del CI/CD: Entre los beneficios que ofrece CI/CD son los siguientes:\n\nCalidad de código mejorada y detección temprana de errores: al adoptar pruebas automatizadas, puede descubrir errores y problemas en una etapa temprana y solucionarlos en consecuencia.\nTrazabilidad completa: se realiza un seguimiento de todo el proceso de compilación, prueba e implementación y se puede analizar más adelante. Esto garantiza que pueda inspeccionar qué cambios se incluyen en una compilación en particular y el impacto que pueden tener en las pruebas o el lanzamiento finales.\nFases de prueba y lanzamiento más rápidas: automatización de la creación y prueba de su código base en cada nueva confirmación (o antes de un lanzamiento).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#azure-devops-pipelines",
    "href": "Understanding_Azure _DevOps_Pipelines.html#azure-devops-pipelines",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.3 Azure DevOps Pipelines",
    "text": "14.3 Azure DevOps Pipelines\nAzure Pipelines es un servicio basado en la nube que automatiza el proceso de construcción, prueba y despliegue de aplicaciones. Es compatible con cualquier lenguaje de programación y plataforma, lo que lo convierte en una solución flexible para cualquier equipo de desarrollo.\n\nCaracterísticas Principales:\n\n\nEs independiente de la plataforma y del lenguaje, lo que significa que puedes crear código en cualquier plataforma utilizando la base de código que desees\nSe puede integrar con diferentes tipos de repositorios como Azure Repos, GitHub, GitHub Enterprise, BitBucket, etc\nIntegración con contenedores Docker y Kubernetes.\nDefinición de pipelines mediante YAML o interfaz gráfica.\nSoporte para agentes alojados y auto-hospedados.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#tipos-de-agentes-de-compilacion-en-azure-pipelines",
    "href": "Understanding_Azure _DevOps_Pipelines.html#tipos-de-agentes-de-compilacion-en-azure-pipelines",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.4 Tipos de Agentes de Compilacion en Azure Pipelines",
    "text": "14.4 Tipos de Agentes de Compilacion en Azure Pipelines\nUn agente es un servicio que ejecuta los trabajos definidos en su canalización. La ejecución de estos trabajos puede ocurrir directamente en la máquina host del agente o en contenedores.. Existen dos tipos de agentes en Azure Pipelines:\n\n14.4.1 Agentes Microsoft-Hosted\nProporcionados por Microsoft, se ejecutan en entornos aislados y garantizan un entorno limpio para cada ejecución.\n\nVentajas:\n\n\nNo requiere configuración adicional.\nIncluye herramientas preinstaladas.\nAdecuado para proyectos sin dependencias personalizadas.\n\n\nLimitaciones:\n\n\nNo se pueden instalar herramientas personalizadas.\nSe restablece en cada ejecución.\n\n\n\n14.4.2 Agentes Self-Hosted\nSon agentes personalizados que se configuran en máquinas virtuales o servidores propios. En un agente autoalojado, puede instalar todo el software que necesita para sus compilaciones, y esto se conserva en cada ejecución de canalización. Un agente autoalojado puede estar en Windows, Linux, macOs o en un contenedor Docker.\n\nVentajas:\n\n\nControl total sobre el entorno.\nSoporte para configuraciones avanzadas.\nPuede ejecutarse en Docker.\n\n\nDesventajas:\n\n\nMayor complejidad de configuración y mantenimiento.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#cuándo-utilizar-un-agente-alojado-por-microsoft-o-uno-autoalojado",
    "href": "Understanding_Azure _DevOps_Pipelines.html#cuándo-utilizar-un-agente-alojado-por-microsoft-o-uno-autoalojado",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.5 Cuándo utilizar un agente alojado por Microsoft o uno autoalojado",
    "text": "14.5 Cuándo utilizar un agente alojado por Microsoft o uno autoalojado\n\nLos agentes hospedados por Microsoft suelen ser útiles cuando se tiene una base de código estándar y no se necesita un software o una configuración de entorno específicos para compilar el código. Si se encuentra en esta situación, se recomienda utilizar un agente hospedado por Microsoft, ya que no tiene que preocuparse por crear entornos.\nLos agentes alojados en servidores propios son la mejor opción cuando se necesita una configuración de entorno particular, cuando se necesita instalar un software o una herramienta en particular en el agente y cuando se necesita más potencia para las compilaciones. Los agentes alojados en servidores propios también son la mejor opción cuando se necesita preservar el entorno entre cada ejecución de las compilaciones.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#descripción-general-del-lenguaje-yaml",
    "href": "Understanding_Azure _DevOps_Pipelines.html#descripción-general-del-lenguaje-yaml",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.6 Descripción general del lenguaje YAML",
    "text": "14.6 Descripción general del lenguaje YAML\nYAML, acrónimo de YAML Ain’t Markup Language, es un lenguaje de programación legible para humanos que se utiliza para la serialización de datos y normalmente para gestionar definiciones de configuraciones para aplicaciones. Puede considerarse un superconjunto de JSON.\nCon Azure DevOps, YAML es extremadamente importante porque permite definir una canalización mediante una definición de script en lugar de una interfaz gráfica (que no se puede transferir entre proyectos)",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#creación-de-un-pipeline-en-azure-devops",
    "href": "Understanding_Azure _DevOps_Pipelines.html#creación-de-un-pipeline-en-azure-devops",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.7 Creación de un Pipeline en Azure DevOps",
    "text": "14.7 Creación de un Pipeline en Azure DevOps\nLos pipelines en Azure DevOps pueden definirse de dos maneras:\n\nInterfaz Clásica: El Editor Clásico de Azure DevOps permite a los usuarios configurar un pipeline mediante una interfaz gráfica, sin necesidad de escribir código YAML. Es una opción ideal para principiantes o proyectos donde se requiere una configuración rápida sin necesidad de versionamiento de los archivos del pipeline.\n\nPasos para crear un pipeline con el Editor Clásico\n\nAcceder a Azure DevOps: Iniciar sesión en Azure DevOps y seleccionar el proyecto en el que se desea crear el pipeline.\nIr a la sección de Pipelines: Navegar a Pipelines en el menú lateral y hacer clic en New Pipeline.\nSeleccionar la opción ‘Use the classic editor’: Esta opción permite la configuración visual del pipeline.\nElegir el repositorio: Seleccionar la fuente de código (Azure Repos, GitHub, BitBucket, etc.).\nSeleccionar una plantilla de pipeline: Se pueden elegir plantillas predefinidas para proyectos .NET, Node.js, Python, entre otros.\nConfigurar los pasos del pipeline: Agregar tareas como compilación, pruebas, despliegue y definir variables necesarias.\nGuardar y ejecutar el pipeline: Guardar la configuración y ejecutar el pipeline manualmente o configurar disparadores automáticos.\n\nUn ejemplo de pipeline en YAML:\ntrigger: main\npool: vmImage: ‘ubuntu-latest’\nsteps: script: echo “Ejecutando pipeline en Azure DevOps”\nEste pipeline se ejecuta cuando hay cambios en la rama main, utilizando una máquina virtual con Ubuntu.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#ejecución-de-trabajos-en-paralelo-en-una-canalización-de-azure",
    "href": "Understanding_Azure _DevOps_Pipelines.html#ejecución-de-trabajos-en-paralelo-en-una-canalización-de-azure",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.8 Ejecución de trabajos en paralelo en una canalización de Azure",
    "text": "14.8 Ejecución de trabajos en paralelo en una canalización de Azure\nDentro de Azure Pipeline, también se puede ejecutar trabajos en paralelo. Cada trabajo puede ser independiente de otros trabajos y también puede ejecutarse en un agente diferente. Esto permitirá acelerar el tiempo de compilación y mejorar el rendimiento del pipeline.\nComo ejemplo de cómo manejar trabajos paralelos en una canalización, considere una canalización simple donde debe ejecutar tres scripts de PowerShell llamados Tarea 1, Tarea 2 y Tarea final.La Tarea 1 y la Tarea 2 se pueden ejecutar en paralelo, mientras que la Tarea Final solo se puede ejecutar cuando se hayan completado las dos tareas anteriores",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#integración-con-github",
    "href": "Understanding_Azure _DevOps_Pipelines.html#integración-con-github",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.9 Integración con GitHub",
    "text": "14.9 Integración con GitHub\nGitHub es una de las plataformas más populares para la gestión de control de código fuente y, a menudo, es bastante común tener escenarios en los que el código se almacena dentro de un repositorio de GitHub y desea utilizar Azure DevOps para administrar CI/CD. Al usar Azure DevOps y el servicio Azure Pipeline, también puede crear canalizaciones para un repositorio almacenado en GitHub, lo que activa una canalización de compilación en cada confirmación en una rama dentro del repositorio de GitHub. Para ello, seguiremos estos pasos:\nPasos:\n\nInstalar la extensión Azure Pipelines en GitHub.\nAutorizar la conexión con Azure DevOps.\nConfigurar un pipeline que se active en cada commit.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#uso-de-contenedores-en-azure-pipelines",
    "href": "Understanding_Azure _DevOps_Pipelines.html#uso-de-contenedores-en-azure-pipelines",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.10 Uso de Contenedores en Azure Pipelines",
    "text": "14.10 Uso de Contenedores en Azure Pipelines\nAzure Pipelines permite ejecutar tareas dentro de contenedores para garantizar entornos de ejecución consistentes. Esto es particularmente útil para garantizar que las dependencias y configuraciones del entorno sean uniformes en todas las ejecuciones.\n\nVentajas del uso de contenedores en Azure Pipelines\n\n\nProporciona un entorno aislado y reproducible.\nPermite definir dependencias específicas sin afectar la máquina anfitriona.\nCompatible con Docker, Kubernetes y Azure Container Registry.\nFacilita la ejecución de pruebas y despliegues en entornos idénticos a producción.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  },
  {
    "objectID": "Understanding_Azure _DevOps_Pipelines.html#conclusión",
    "href": "Understanding_Azure _DevOps_Pipelines.html#conclusión",
    "title": "14  Azure DevOps Pipelines",
    "section": "14.11 Conclusión",
    "text": "14.11 Conclusión\nAzure DevOps Pipelines es una solución completa para la automatización de CI/CD, proporcionando herramientas para despliegues rápidos y confiables. Su integración con GitHub, soporte para contenedores y pipelines multietapa lo convierten en una opción ideal para proyectos modernos de desarrollo de software.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Azure DevOps Pipelines</span>"
    ]
  }
]