[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contenedores al Alcance de Todos",
    "section": "",
    "text": "1 Prefacio\nEste libro te enseñará a manejar y comprender contenedores con herramientas modernas como Docker y Podman. Aprenderás desde los fundamentos hasta el despliegue de aplicaciones en entornos reales, pasando por la construcción de imágenes, gestión de redes y almacenamiento, todo a través de ejemplos prácticos y proyectos aplicados. Sin embargo, este no es un manual introductorio típico. Mi objetivo es ayudarte a convertirte en un profesional capaz de utilizar contenedores no solo para ejecutar aplicaciones, sino para integrarlos en procesos de desarrollo y despliegue ágiles.\nLos capítulos del libro están organizados en torno a tres proyectos principales, diseñados para abarcar aspectos clave de Docker y Podman. Estos proyectos no solo cubren la construcción y gestión de contenedores, sino también prácticas avanzadas como la integración con CI/CD, optimización de recursos y resolución de problemas comunes. He seleccionado estos proyectos por dos razones: primero, porque representan el rango completo de funcionalidades de estas herramientas; segundo, porque están diseñados para ayudarte a abordar los desafíos reales del desarrollo y despliegue moderno de software.\nMás allá de las características técnicas, los contenedores resuelven problemas logísticos importantes en el desarrollo. Permiten crear entornos reproducibles, escalar aplicaciones de manera eficiente y minimizar errores relacionados con dependencias o configuraciones. A través de este libro, no solo aprenderás a usar Docker y Podman, sino también a integrar estas habilidades en tu trabajo como desarrollador, maximizando tu productividad y mejorando tu flujo de trabajo.\nEste libro está dirigido a los siguientes perfiles: - Estudiantes y profesionales interesados en aprender sobre contenedores desde cero. - Desarrolladores que buscan integrar prácticas modernas de DevOps y microservicios. - Ingenieros que desean optimizar procesos de despliegue y escalabilidad en la nube.\nHe diseñado este libro para que sea accesible y práctico, centrándome en conceptos aplicados y dejando de lado teorías avanzadas que pueden ser un obstáculo al inicio. Mi objetivo es proporcionarte las herramientas y el conocimiento para que puedas enfrentarte a problemas reales en el desarrollo de software.\nAprender a manejar contenedores es una habilidad esencial para cualquier profesional en tecnología hoy en día. Es como pasar de usar un sistema tradicional, donde todo está predeterminado, a un sistema donde tienes la flexibilidad y el control total para crear lo que necesitas. Como dijo Greg Snow al referirse a otro contexto, los contenedores son como un vehículo todoterreno que te llevará a lugares donde las herramientas tradicionales no pueden llegar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#convenciones-utilizadas-en-este-libro",
    "href": "index.html#convenciones-utilizadas-en-este-libro",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.1 Convenciones Utilizadas en Este Libro",
    "text": "1.1 Convenciones Utilizadas en Este Libro\n\nCursiva: Indica términos nuevos, URLs y nombres de archivos.\nTexto de ancho fijo: Representa comandos, nombres de variables o elementos de código.\nTexto en negrita: Muestra comandos que deben ser escritos literalmente por el lector.\n\nPara realizar comentarios o preguntas técnicas sobre este libro, por favor abre un issue en github.com/tu-repositorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Contenedores al Alcance de Todos",
    "section": "1.2 Agradecimientos",
    "text": "1.2 Agradecimientos\nQuiero agradecer a todas las personas que me han ayudado a escribir este libro, desde mis colegas y estudiantes que han probado este contenido, hasta quienes contribuyeron con ideas y retroalimentación. También agradezco a las comunidades de Docker y Podman por proporcionar recursos invaluables y fomentar el aprendizaje continuo. Finalmente, gracias a mi familia por su apoyo incondicional durante este proceso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefacio</span>"
    ]
  },
  {
    "objectID": "prework.html",
    "href": "prework.html",
    "title": "2  First steps with Polars",
    "section": "",
    "text": "2.1 Requisitos de Docker antes de instalar.\nocker destaca por su compatibilidad entre sistemas. Las máquinas virtuales o la virtualización de hardware clásica emulan un sistema operativo invitado entero, mientras que los contenedores Docker comparten el núcleo del sistema anfitrión, ejecutándose como procesos aislados en el espacio del usuario. En sus inicios, Docker se utilizaba exclusivamente en sistemas Linux o en sistemas operativos basados en Linux. Hoy en día, el software de código abierto se caracteriza por su completa independencia de los sistemas operativos. Docker utiliza el kernel local de Linux en las variantes de 64 bits de los sistemas operativos de Linux, los sistemas que no son de Linux utilizan simplemente una imagen del sistema Linux a través de un hypervisor o una máquina virtual.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First steps with Polars</span>"
    ]
  },
  {
    "objectID": "introduccion_docker.html",
    "href": "introduccion_docker.html",
    "title": "3  Introducción a Docker",
    "section": "",
    "text": "3.0.1 Introducción\nDocker surge como una solución innovadora al problema de la virtualización tradicional, ya que en el enfoque clásico, se utilizan máquinas virtuales (VMs), las cuales requieren de un sistema operativo completo para su creación y ejecución, además de que consumen una gran cantidad de espacio y recursos, incluso si solo se necesita ejecutar una tarea específica, por lo que este enfoque en la actualidad es ineficiente y poco flexible.\nDocker se centra en solucionar este problema mediante el uso de contenedores, definidos por archivos Dockerfile. Estos archivos especifican únicamente lo necesario para que una aplicación funcione, eliminando la necesidad de instalar sistemas operativos completos, basta con tener una imagen base y las dependencias necesarias; Docker optimiza el uso del espacio y acelera en gran medida el despliegue de aplicaciones.\nUna de las principales ventajas de Docker es su portabilidad, ya que permite que las aplicaciones se ejecuten de manera consistente en diferentes sistemas operativos y entornos, como desarrollo, pruebas y producción. Esto lo convierte en una herramienta fundamental para implementar arquitecturas modernas, como los microservicios, facilitando la gestión y escalabilidad de aplicaciones complejas.\n\n\n3.0.2 ¿Qué es Docker?\nDocker es una tecnología de virtualización basada en contenedores que permite empaquetar aplicaciones junto con sus dependencias y frameworks necesarios para su ejecución, esto garantiza que las aplicaciones funcionen de manera consistente y uniforme, sin importar el entorno en el que se ejecuten, resolviendo los problemas de compatibilidad y configuración de dependencias que suelen surgir al migrar entre sistemas operativos o entornos.\n\n\n3.0.3 Componente de Docker\nDocker engine: Es el motor de Docker y se encarga de la gestión de todos los contenedores que se ejecutan en Docker.\nDocker images: Es la plantilla donde se ecuentra la aplicación, la imagen base del sistema operativo y las dependencias necesarias para la ejecución de la aplicación, estas imágenes son reutilizables y permiten crear contenedores de manera rápida y eficiente.\nDocker container: Es la ejecución de una instancia de la imagen de Docker, donde cada contenedor opera en un entorno completamente aislado, compartiendo únicamente el kernel del sistema operativo anfitrión pero manteniendo independencia en cuanto a procesos, redes y almacenamiento.\nRedes: Las redes sirven para la comunicación entre los contenedores, permitiendo que se comuniquen entre sí o con el host, por lo que existen diferentes modelos de red que son las redes de puente, las redes de host y las redes de superposición.\nVolúmenes: Los volúmenes sirven para almacenar los datos que se desea que persistan en el tiempo, es decir cuando el contenedorer termine de ejecutarse, se reinicie o se elimine, esto es ideal para manejar aplicaciones que requieren de una base de datos o almacenamiento persistente.\nDocker Hub: Es el repositorio central que utiliza Docker para que los desarrolladores puedan compartir y descargar imágenes tanto públicas como privadas, lo que facilita la colaboración y la reutilización de imágenes.\n\n\n3.0.4 Diferencias entre Docker y Máquinas Virtuales\n\n3.0.4.1 Docker\n\nLos contenedores de Docker solo comparten el núcleo del sistema operativo host.\nLos contenedores son más ligeros.\nArrancan en segundos.\nSon más portables y fáciles de gestionar.\nPresentan menos sobrecarga sobre el hardware del host.\nPermiten la ejecución de múltiples contenedores en un mismo host.\nSon ideales para aplicaciones basadas en microservicios.\n\n\n\n3.0.4.2 Máquinas Virtuales\n\nLas máquinas virtuales necesitan de la virtuaización de todo el hardware del host.\nLas máquinas virtuales ocupan gran cantidad de espacio y recursos para su creación y ejecución.\nSu arranque es lento, por lo general tardan minutos.\nSon más complejas de administrar y su portabilidad es compleja.\nPresentan mayor sobrecarga sobre el hardware del host.\nSe puede ejecutar multiples máquinas virtuales en un mismo host, pero esto requiere de más recursos.\nSon ideales para aplicaciones con una arquitectura monolítica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a Docker</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html",
    "href": "understanding_cloud_concepts.html",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "4.1 Ecosistema del Cloud Computing\nEl concepto de cloud computing está transformando la manera en que las empresas operan, permitiéndoles acceder a recursos de cómputo y almacenamiento bajo demanda, escalar sin límites y adoptar modelos de precios flexibles. Esta tecnología ha revolucionado tanto a empresas emergentes como a grandes corporaciones.\nEl ecosistema de cloud computing consta de tres principales actores:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#ecosistema-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "",
    "text": "Consumidores de servicios: Usan aplicaciones y herramientas en la nube sin preocuparse por su ubicación o diseño.\nProveedores de servicios: Ofrecen infraestructura, aplicaciones y herramientas basadas en la nube.\nDiseñadores de servicios: Construyen herramientas o aplicaciones optimizadas para ecosistemas específicos de nube.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "href": "understanding_cloud_concepts.html#conceptos-fundamentales-del-cloud-computing",
    "title": "4  Comprendiendo la Nube",
    "section": "4.2 Conceptos Fundamentales del Cloud Computing",
    "text": "4.2 Conceptos Fundamentales del Cloud Computing\nEl cloud computing implica la provisión de recursos compartidos como aplicaciones, almacenamiento y plataformas de desarrollo a través de estándares y automatización. Los servicios comunes incluyen:\n\nAutomatización: Procesos gestionados automáticamente para optimizar la eficiencia.\nAutoservicio: Permite a los usuarios aprovisionar recursos por sí mismos.\nElasticidad: Capacidad de ajustar automáticamente recursos según las necesidades.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-nube",
    "href": "understanding_cloud_concepts.html#modelos-de-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.3 Modelos de Nube",
    "text": "4.3 Modelos de Nube\nExisten diferentes modelos de despliegue en la nube, cada uno adaptado a distintas necesidades empresariales:\n\n4.3.1 Nube Pública\n\nDefinición: Recursos compartidos y gestionados por un proveedor externo. Los usuarios pagan por el uso bajo demanda.\nCaracterísticas:\n\nEscalabilidad masiva y elasticidad automática.\nAcceso a servicios avanzados, como análisis de datos y aprendizaje automático.\nDisponibilidad global, ideal para empresas que requieren operaciones en múltiples regiones.\n\nCasos de uso: Aplicaciones de comercio electrónico, almacenamiento masivo, pruebas y desarrollo.\n\n\n\n4.3.2 Nube Privada\n\nDefinición: Recursos dedicados y gestionados por una sola organización, ya sea internamente o a través de un proveedor externo.\nCaracterísticas:\n\nControl total sobre los recursos.\nMayor seguridad y personalización.\nCumplimiento normativo y gobernanza específica.\n\nCasos de uso: Datos sensibles, aplicaciones con requisitos legales estrictos o sistemas heredados.\n\n\n\n4.3.3 Nube Híbrida\n\nDefinición: Combina nubes públicas y privadas, permitiendo la interoperabilidad y la transferencia de datos entre ambas.\nCaracterísticas:\n\nBalanceo de cargas de trabajo entre entornos.\nFlexibilidad para mover datos según necesidades de costo, rendimiento o seguridad.\n\nCasos de uso: Migraciones graduales hacia la nube, recuperación ante desastres, análisis de datos en múltiples ubicaciones.\n\n\n\n4.3.4 Multicloud\n\nDefinición: Uso simultáneo de múltiples nubes públicas para satisfacer distintas necesidades empresariales.\nCaracterísticas:\n\nEvita la dependencia de un solo proveedor.\nFlexibilidad para aprovechar lo mejor de cada plataforma.\nGestión centralizada para controlar costos y rendimiento.\n\nCasos de uso: Desarrollo de aplicaciones en plataformas específicas o maximización de servicios según región.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#modelos-de-entrega",
    "href": "understanding_cloud_concepts.html#modelos-de-entrega",
    "title": "4  Comprendiendo la Nube",
    "section": "4.4 Modelos de Entrega",
    "text": "4.4 Modelos de Entrega\nLos modelos de entrega en cloud computing son fundamentales para entender cómo se ofrecen los servicios a los usuarios. Cada uno proporciona un nivel distinto de abstracción y control:\n\n4.4.1 Infraestructura como Servicio (IaaS)\n\nDefinición: Provisión de recursos básicos, como servidores virtuales, almacenamiento y redes, sobre los cuales los usuarios pueden construir sus propias aplicaciones.\nCaracterísticas:\n\nControl total sobre el sistema operativo y las aplicaciones.\nAlta flexibilidad para personalizar entornos según las necesidades.\nPago por uso, permitiendo reducir costos operativos.\n\nEjemplos de servicios: Amazon EC2, Google Compute Engine, Microsoft Azure VMs.\nCasos de uso:\n\nMigración de centros de datos físicos a la nube.\nEscenarios de desarrollo y pruebas.\nImplementación de aplicaciones personalizadas.\n\n\n\n\n4.4.2 Plataforma como Servicio (PaaS)\n\nDefinición: Provisión de una capa de abstracción que incluye herramientas de desarrollo, middleware y bases de datos, optimizada para la creación y despliegue de aplicaciones.\nCaracterísticas:\n\nEntorno preconfigurado para desarrollo rápido.\nIntegración de herramientas como frameworks y APIs.\nGestión automatizada de recursos y actualizaciones.\n\nEjemplos de servicios: Google App Engine, Microsoft Azure App Service, Heroku.\nCasos de uso:\n\nDesarrollo de aplicaciones web y móviles.\nCreación de aplicaciones en entornos colaborativos.\nEscenarios donde se busca acelerar el tiempo de desarrollo.\n\n\n\n\n4.4.3 Software como Servicio (SaaS)\n\nDefinición: Provisión de aplicaciones completas accesibles a través de internet. Los usuarios no gestionan ni la infraestructura ni las plataformas subyacentes.\nCaracterísticas:\n\nFacilidad de uso y acceso desde cualquier dispositivo.\nModelos de suscripción mensual o anual.\nAlta disponibilidad y actualizaciones automáticas.\n\nEjemplos de servicios: Google Workspace, Salesforce, Zoom.\nCasos de uso:\n\nHerramientas de colaboración y productividad.\nGestión de relaciones con clientes (CRM).\nServicios de recursos humanos y contabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "href": "understanding_cloud_concepts.html#ciclo-de-vida-de-recursos-en-la-nube",
    "title": "4  Comprendiendo la Nube",
    "section": "4.5 Ciclo de Vida de Recursos en la Nube",
    "text": "4.5 Ciclo de Vida de Recursos en la Nube\nEn contraste con los centros de datos tradicionales, la nube permite a los usuarios:\n\nAlquilar recursos bajo demanda.\nPagar únicamente por el uso real.\nLiberar recursos automáticamente cuando ya no se necesitan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "href": "understanding_cloud_concepts.html#gestión-de-nubes-híbridas-y-multicloud",
    "title": "4  Comprendiendo la Nube",
    "section": "4.6 Gestión de Nubes Híbridas y Multicloud",
    "text": "4.6 Gestión de Nubes Híbridas y Multicloud\nUna nube híbrida efectiva debe integrar múltiples entornos de forma automatizada y bien gestionada. Los entornos multicloud requieren visibilidad, control y capacidad para mover datos y cargas de trabajo según convenga.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "href": "understanding_cloud_concepts.html#cambios-en-el-rol-del-centro-de-datos",
    "title": "4  Comprendiendo la Nube",
    "section": "4.7 Cambios en el Rol del Centro de Datos",
    "text": "4.7 Cambios en el Rol del Centro de Datos\nAunque los centros de datos no desaparecerán, la adopción de la nube les exige modernizarse. Las estrategias incluyen:\n\nVirtualización: Separar software de hardware para mejorar la eficiencia.\nNubes privadas: Crear entornos altamente automatizados con capacidades de autoservicio.\nNubes híbridas: Combinar servicios en la nube con infraestructura local.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Comprendiendo la Nube</span>"
    ]
  },
  {
    "objectID": "virtualbox and docker containers for developments.html",
    "href": "virtualbox and docker containers for developments.html",
    "title": "5  VirtualBox y Contenedores Docker para el Desarrollo",
    "section": "",
    "text": "5.0.1 Introducción\nDentro del desarrollo de software de la actualidad se requieren entornos flexibles, escalables y consistentes. La configuración manual para cada proyecto puede ser tedioso y con tendencia a errores, en especial cuando las dependencias del sistema o sus versiones de software son críticas. Para esto, existen herramientas como VirtualBox y Docker juegan un papel importante.\n\n\n5.0.2 VirtualBox:\nLa herramienta de VirtualBox nos proporciona un software de hipervisor el cual nos permite la ejecución de máquinas virtuales dentro de un sistema host o anfitrión. Cada una de estas máquinas virtuales imitan entornos completos, incluso el de los sistemas operativos, de configuraciones y de aplicaciones que se requieren para el desarrollo. Se puede usar virtualbox para realizar pruebas de software en múltiples sistemas operativos o para poner en aislamineto un entorno de desarrollo.\nGuest Additions\nDentro de los sistemas invitados como Windows y Linux, se puede instalar controladores que permitan integrar los sistemas operativos de invitado y host. Tales controladores se conocen como Guest Additions y se los puede bajar desde el sitio web de VirtualBox.\nSon instalables dentro de la máquina virtual como cualquier programa que se vaya a instalar para Windows o Linux. La integración con el host es bastante útil.\nInstalación VirtualBox\n\nDescargue VirtualBox desde el sitio web oficial.\nInstale el software utilizando el instalador proporcionado.\nInicie VirtualBox y verifique que se esté ejecutando correctamente.\n\n\n\n5.0.3 Contenedores Docker:\nLa tecnología Docker hace el uso de contenedores ligeros para poder empaquetar aplicaciones incluidas sus dependencias utilizando un solo entorno ejecutable. En contraparte con las máquinas virtuales, los contenedores tienen compartición del núcleo del sistema operativo anfitrión, permitiendoles ser más eficientes en términos de recursos. Docker ayuda a que los desarrolladores puedan crear entornos reproducibles y escalables en cuestión de segundos, haciendo fácil y fluida la colaboración y la integración continua.\nConfiguración Contenedor Docker Básico Docker nos proporciona una manera eficiente de empaquetar, enviar y poder ejecutar software. En esta parte, se analizaran los pasos básicos para crear un contenedor para el desarrollo.\n\nEscribiendo el Dockerfile:\n\nUn archivo Dockerfile específica el entorno de configuración y todos los comandos para poder tener nuestro contenedor, ejemplo:\n# Usso de ina imagen oficial de PHP\nFROM php:7.4-apache\n\n# Habilitar módulos de Apache requeridos\nRUN a2enmod userdir \\\n    && a2enmod php7.4\n\n# Copiar el archivo de configuración para Apache\nCOPY php.conf /etc/apache2/mods-available/php7.4.conf\n\n# Definir el entry point\nENTRYPOINT [\"/entrypoint.sh\"]\n\nConstruyendo el Docker Image:\n\nPara crear la imagen del contenedor se hace uso del script build.sh, ejemplo:\n#!/usr/bin/env bash\n\n# Se construye el Docker Image\n\ndocker build -t chapter2 .\n\nCorriendo el Docker Container:\n\nPara lanzar el contenedor, se hace uso del script run.sh, ejemplo:\n#!/usr/bin/env bash\n\ndocker run -d --name chapter2 chapter2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>VirtualBox y Contenedores Docker para el Desarrollo</span>"
    ]
  },
  {
    "objectID": "composing_systems_using_containers.html",
    "href": "composing_systems_using_containers.html",
    "title": "6  Componiendo sistemas utilizando contenedores.",
    "section": "",
    "text": "6.1 Archivos de configuracion para Docker Compose.\nAutor: Byron Gonzalez. ## Introduccion. En este capitulo se presenta la forma de definir y ejecutar aplicaciones multicontenedor utilizando Docker Compose, permitiendo una gestion mas sencilla de sistemas complejos de multiples servicios interconectados. ## Problema con los scripts sh. Utilizar varios archivos sh para crear diferentes servicios puede causar problemas en los puertos o en la inicializacion del servicio. Algunos problemas comunes son: - Permisos Insuficientes. Al copiar un script al contenedor, es posible que no contenga los permisos de ejecucion. Para ello se debe otorgar los servicios con: RUN chmod +x /path/to/script.sh - Formato de archivo incorrecto Muchas veces los scripts creados en windows pueden contener caracteres de fin de linea incompatibles con entornos de Unix o Linux. La forma de arreglarlo es convirtiendo el archivo a formato UNIX con dos2unix script .sh - Shell Incorrecto Algunos contenedores no usan bash por defecto en su lugar tienen sh. por lo que se debe asegurar de usar el shell correcto en el script (#!/bin/sh). - Variables de entorno no disponibles Los scripts pueden depender de variables que no estan configuradas en el contenedor, en este caso se debe declarar las variables en el docker-compose.yml o pasarlas como parametros al script.\nEstos archivos son en formato .yml los contenidos son en YAML. El archivo se llama docker-compose.yml Dentro de este se deben seguir las siguientes directivas clave. Primero se define la version. Como parte principar se debe definir cuales de las diferentes versiones se va usar ya que en estas se pueden encontrar distintas funciones que se pueden necesitar. Ejemplo: version: ‘3.9’ El bloque de servicios o services se contiene las definiciones de los servicios, estos deben poseer un nombre y configuracion especifica. En el caso de las directivas comunes en un servicio se empieza por el build que especifica el contexto para construir la imagen. Ejemplo: build: context: . dockerfile: Dockerfile\nLa parte de image se especifica el imagen que el serviciio va a usar. Ejemplo: image: nginx:latest\nEn ports se mapean los puertos internos del contenedor a los puertos externos del host. Ejemplo: ports: -“8080:80”\nLa parte de volumes se monta los directorios o archivos del host dentro del contenedor. Ejemplo: volumes: -./data:/app/data Dentro de enviroment se define las variables de entorno para el contenedor. Ejemplo: environment: -MYSQL_ROOT_PASSWORD=root La definicion de depends_on especifica las depedencias entre servicios, garantizado que uno se inicie antes que otro. Ejemplo: depends_on: -db Ejemplo de un docker-compose completo: version: ‘3.9’ services: web: image: nginx:latest ports: - “8080:80” (Mapea el puerto 80 del contenedor al puerto 8080 del host) volumes: - ./web:/usr/share/nginx/html (Monta el directorio local) ./web al contenedor depends_on: - db (El servicio web depende del servicio db) networks: -app_network db: image: mysql:8.0 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: myapp volumes: -db_data:/var/lib/mysql (Almacena datos de MySQL en un volumen) networks: -app_network volumes: db_data: (Define un volumen persistente para MySQL) networks: app_network: (Define una red personalizada para conectar los servicios) driver: bridge Dentro del servicio web se usa la imagen oficial de nginx, se expone el puerto 8080 del host, se monta el directorio local ./web para servir archivos HTML estaticos y depende del servicio db, asegurandose de que este se inicie primero. En la zona de dbse usa la imagen de MYSQL, se configura la base de datos mediante las variables de entorno, se almacena los datos en un volumen persistente db_data. Dentro de la zona de los volumenes se permite persistir datos (como los de MYSQL) para que no se pierdan al reiniciar o en un fallo de los contenedores. Por ultimo en las redes se conectan ambos servicios a una red interna llamada app_network, lo que permite la comunicacion entre ellos sin exponerse todos los puertos al host.\nLos comandos escenciales para gestionar el compose son: - docker-compose up (Usa el archivo docker compose.yml para construir e iniciar los servicios). - docker-compose up -d (Inicia los contenedores en segundo plano) - docker-compose ps (Verificar el estado de los contenedores activos) - docker-compose restart (Reinicia los servicios) - docker-compose down (Agrega y elimina los servicios) ## Redes internas Las redes internas privadas son importantes debido a la comunicacion entre los distintos a contenedores a crear. Se debe definir lel hostIp. el host de mongo y el host de redis como variables especialmente en los archivos sh. estp con el fin de ejecutarlos usando docker run ya que el DNS local de Docker no trabaja con sh. Al momento de la gestion automatica de redes internas se tiene las ventajas de un red interna por defecto para los servicios evitando errores con otros contenedores o redes en el sistema, junto tambien que se evitan conflictos de puertos. Y al usar sus nombres de servicio como hostnames se evita problemas de nombres. Se crean diferentes partes dentro del yml. para crear redes de mejor forma como una seccion de networks. Ejemplo: version: ‘3.9’ services: web: image: nginx networks: - frontend db: image: postgres networks: - backend networks: frontend: driver: bridge backend: driver: bridge\nUna de las formas mas comunes es separar la redes de frontend y backend para que no se comuniquen de forma directa. Junto a esto se debe especificar rangos de subred. Ejemplo:\nnetworks: custom_network: driver: bridge ipam: config: -subnet: “192.168.1.0/24”\nEspecificar los servicios necesarios que van a acceder, utilizar redes overlay para comunicar servicios distribuidos en varios nodos. Tener nombres claros para futuras actualizaciones o mejoras. ## Gestion de puertos Se emplean estrategias para asignar los distintos puertos a los host para evitar los conflictos con los servicios ya existentes. El uso de mapeo para los puertos internos a los externos del host. En docker cada contenedor posee su propia red aislada pero muchas veces se requiere exponer servicios del contenedor al host para que accesibles desde fuera. Esto se realiza con la directiva ports. Ejemplo: services: web: image: nginx:latest ports: - “8080:80” ( 8080 Puerto del host donde sera accesible el servicio y 80 puerto interno del contenedor donde esta configurado el servicio). Para evitar conflictos de puerto se usa: - Uso de puertos dinamicos Si no se requiere un puerto especifico del host, Docker puede asignar uno automaticamente. Ejemplo: ports: -“80” De esta forma se asigna un puerto aleatorio disponible en el host y lo enlaza con el puerto especificado (80) en el contenedor. Se usa el comando docker ps para saber el puerto asignado. - Planificacion de puertos Definir un rango especifico de puertos para cada servicio y asegurarse de que no entren en conflicto unos con otros mientras los de mas servicios estan en ejecucion. La herramienta como netstat o lsof se usa para visualizar los puertos ocupados en el host. - Asignacion de puertos por red En aplicaciones con multiples contenedores, en lugar de exponer los puertos al host, permite que los contenedores se comuniquen internamente en su red. Ejemplo: services: web: image: nginx:latest ports: - “8080:80” db: image: postgres:latest ports: - “5432:5432” networks: -backend -networks: -backend: -driver: bridge En este ejemplo el servicio web se comunica con la db internamente en la red backend, sin exponer el puerto 5432 al host. ## Variables de entorno Las variables de entorno permite la parametrizacion de las configuracion para que sean reutilizables y flexibles. Dentro de estas se pueden definir los puertos, nombres de contenedores, rutas de volumenes o contraseñas. Tambien nos presenta al uso de archivos .env para almacenar variables sensibles o configuraciones especificas.\nEjemplo: MYSQL_USER=root MYSQL_PASSWORD=secret MYSQL_DB=mydatabase PORT=8080\nEstas pueden ser accedidas mediante el archivo docker-compose.yml Ejemplo: Se usa el signo de dolar junto a la variable. version: ‘3.9’ services: db: image: mysql:latest environment: MYSQL_USER:{MYSQL_USER} MYSQL_PASSWORD:{MYSQL_PASSWORD} MYSQL_DATABASE:{MYSQL_DB] ports: -“${PORT}:3306” Cuando se ejecuta el comando docker-compose-up.yml se busca el archivo .env en el mismo directorio. Se debe mantener el archivo .env fuera del control de versiones para proteger los datos. Y utilizar distintos archivos para los distintos entornos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Componiendo sistemas utilizando contenedores.</span>"
    ]
  },
  {
    "objectID": "composing_systems_using_containers.html#despliegue-en-diferentes-entornos",
    "href": "composing_systems_using_containers.html#despliegue-en-diferentes-entornos",
    "title": "6  Componiendo sistemas utilizando contenedores.",
    "section": "6.2 Despliegue en diferentes entornos",
    "text": "6.2 Despliegue en diferentes entornos\nConfiguracion de multiples archivos compose para entornos de desarrollo, pruebas y produccion. En aplicaciones en el mundo laboral las configuraciones varian en base al entorno. Ejemplo: En desarrollo se usan imagenes locales, bd en contenedores y logs detallados. En produccion se usan imagenes optimizadas, bases de datos gestionadas y configuraciones seguras. Dentro de la carga puede crearse un archivo llamado docker-compose.override.yml el cual puede tener configuraciones adicionales o reemplazar distintos valores del archivo principal. Este permite mantener configuraciones especificas sin modificar el archivo docker compose, es ideal para los cambios en desarrollo como montar directorios locales o habilitar el modo de depuracion.\nEjemplo:\nservices: web: volumes: -./local_code:/app environment: DEBUG: “true”",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Componiendo sistemas utilizando contenedores.</span>"
    ]
  },
  {
    "objectID": "composing_systems_using_containers.html#depuracion-y-monitoreo",
    "href": "composing_systems_using_containers.html#depuracion-y-monitoreo",
    "title": "6  Componiendo sistemas utilizando contenedores.",
    "section": "6.3 Depuracion y Monitoreo",
    "text": "6.3 Depuracion y Monitoreo\nUso de logs para el diagnostico de problemas como al inicio o en la ejecucion de los servicios y permite la identificacion de comunicacion entre los contenedores. Docker-compose.logs Los comandos basicos dentro de estas son: Docker-compose logs (Muestra los logs de los contenedores en ejecucion). Docker-compose logs &lt; service-name &gt; (Muestra los logs de un servicio en especifico). –tail &lt; N &gt; muestra solo las ultimas N lineas. -f o –follow sigue los logs en tiempo real.\nIntegracion de herramientas externas para monitorear el rendimiento de los servicios. En el caso de las aplicaciones grandes se utilizan las herramientas de: Prometheus y Grafana para tener un mejor uso de la CPU, memoria y red en contenedores. Elk Stack (Elastic Search, Logstach, Kibana) para el almacenamiento y analisis de los logs de los servicios, facilita la busqueda de errores en grandes volumenes de datos. Docker Desktop interfaz grafica para las estadisticas basicas de los contenedores.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Componiendo sistemas utilizando contenedores.</span>"
    ]
  },
  {
    "objectID": "scaling_and_load_testing_docker_applications.html",
    "href": "scaling_and_load_testing_docker_applications.html",
    "title": "7  Escalado y Pruebas de Carga de Aplicaciones Docker",
    "section": "",
    "text": "#Autor:Pool Ochoa\nEl escalado y las pruebas de carga son esenciales para garantizar que las aplicaciones en contenedores puedan manejar el tráfico creciente de manera eficiente y continuar funcionando bajo presión. Este proceso es particularmente relevante para infraestructuras basadas en Kubernetes, donde se pueden implementar estrategias de escalado tanto manuales como automáticas.\n\n7.0.1 Escalado en Kubernetes\nKubernetes permite escalar las aplicaciones en dos niveles principales:\n1. Escalado de Pods: Incrementar o reducir el número de réplicas de una aplicación según la demanda.\n2. Escalado del Clúster: Ajustar el número de nodos disponibles en el clúster para manejar los pods adicionales cuando los recursos se limitan.\nPara automatizar el escalado, Kubernetes ofrece herramientas como:\n- Cluster Autoscaler: Escala los nodos del clúster según la carga actual.\n- Horizontal Pod Autoscaler (HPA): Ajusta el número de pods basándose en métricas como el uso de CPU.\n- Vertical Pod Autoscaler (VPA): Modifica dinámicamente las solicitudes de CPU y memoria de los pods para optimizar los recursos.\n\n\n7.0.2 Pruebas de Carga\nLas pruebas de carga evalúan cómo responde una aplicación bajo diferentes niveles de tráfico. Estas pruebas permiten identificar cuellos de botella y garantizar que los mecanismos de escalado funcionen como se espera. Herramientas como Apache Bench (ab) y k6 son comunes para realizar estas pruebas.\n\n\n7.0.3 Ejemplo 1: Escalado Horizontal de Pods\n\nConfigurar el HPA en Kubernetes con un comando como:\nkubectl autoscale deployment app-deployment --cpu-percent=50 --min=2 --max=10\nAquí, el número de pods de la aplicación se ajustará automáticamente entre 2 y 10, según el uso de CPU.\nEjecutar una prueba de carga con Apache Bench para simular tráfico:\nab -n 1000 -c 50 http://app-url/\nEsto genera 1000 solicitudes concurrentes para evaluar si los pods adicionales se crean al aumentar el uso de CPU.\n\n\n\n7.0.4 Ejemplo 2: Pruebas de Escalabilidad con k6\n\nEscribir un script de carga en JavaScript para simular usuarios concurrentes:\nimport http from 'k6/http';\n\nexport default function() {\n    http.get('http://app-url/');\n}\nEjecutar el script con 50 usuarios virtuales durante 30 segundos:\ndocker run --rm -i loadimpact/k6 run --vus 50 --duration 30s - &lt; script.js\nEsto mide el rendimiento de la aplicación y verifica si el Cluster Autoscaler añade nodos para manejar el incremento de pods.\n\nCon estas estrategias, puedes optimizar el desempeño de aplicaciones contenedorizadas y garantizar una experiencia de usuario confiable.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Escalado y Pruebas de Carga de Aplicaciones Docker</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html",
    "href": "deploying_docker_compose.html",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "",
    "text": "8.1 Requisitos para su implementación.\nEl escenario de implementación práctico más simple posible de una aplicación empaquetada con Docker implica ejecutar Docker Compose en un solo host, sin embargo, tiene algunas desventajas importantes en términos de rendimiento y disponibilidad.\nPara continuar con la implementación, necesitará una computadora que ejecute un sistema operativo Linux moderno de la misma arquitectura que su sistema de desarrollo, con suficiente memoria, procesador y capacidad de almacenamiento para ejecutar su aplicación.\nDeberá tener alguno de estos sistemas operativos linux que admitan Docker:  - Red Hat\n- Ubuntu 16.04 o superior\n- Amazon Linux 2\n- Debian\no alguna distribución centrada en Docker como Container Linux o CoreOS.\nAdemás, antes de configurar el software en el host, debe asegurarse de que tenga una dirección IP estable. A veces, se las denomina direcciones IP estáticas o direcciones IP elásticas en un contexto de AWS.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "href": "deploying_docker_compose.html#implementación-mediante-archivos-de-configuración-y-scripts-de-soporte.",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "8.2 Implementación mediante archivos de configuración y scripts de soporte.",
    "text": "8.2 Implementación mediante archivos de configuración y scripts de soporte.\nPara implementar nuestra aplicación en un servidor de producción, utilizaremos una combinación de comandos simples y scripts de soporte que inician o actualizan el conjunto de contenedores en ejecución. Comencemos por analizar en detalle los dos archivos más importantes necesarios para la implementación: Dockerfile y docker­compose.yml.\nEste es un ejemplo de Dockerfile basado en la producción de un juego, deberás adaptar tu Dockerfile según las necesidades de tu aplicación: FROM alpine:20191114\nRUN apk update &&\napk add nodejs nodejs-npm\nRUN addgroup -S app && adduser -S -G app app\nRUN mkdir -p /app/public /app/server\nADD src/package.json* /app/\nWORKDIR /app\nRUN npm -s install\nCOPY src/public/ /app/public/\nCOPY src/server/ /app/server/\nCOPY src/.babelrc /app/\nRUN npm run compile\nUSER app\nEXPOSE 3000\nENTRYPOINT [“npm”, “start”]\n\nEste es un ejemplo de un archivo de docker-compose:\nversion: ‘3’\nservices:\nshipit-clicker-web-v2:\nbuild: .\nenvironment:\n- APP_ID=shipit-clicker-v2\n- OPENAPI_SPEC=/api/v1/spec\n- OPENAPI_ENABLE_RESPONSE_VALIDATION=false\n- PORT=3000\n- LOG_LEVEL={LOG_LEVEL:-debug}\n- REQUEST_LIMIT=100kb\n- REDIS_HOST=\\({REDIS_HOST:-redis} \\\n- REDIS_PORT=\\){REDIS_PORT:-6379}\n- SESSION_SECRET=${SESSION_SECRET:-mySecret-v2}\n\nAhora, es necesario definir una configuración de red para el contenedor principal para luego vincularlos a los demás contenedores. Un ejemplo es: ports: - {PORT:-3006}:3000\nnetworks:\n- private-redis-shipit-clicker-v2\nlinks:\n- redis\ndepends_on:\n- redis\n\nAhora bien, al ejecutar un sitio en producción, es posible que deba realizar algunas operaciones con frecuencia como reiniciarlo o actualizarlo. Para resolver esto puede agregar scripts con el objetivo de automatizar procesos, los más comunes son aquellos para reiniciar la aplicación y implementar cambios.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#implementación",
    "href": "deploying_docker_compose.html#implementación",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "8.3 Implementación",
    "text": "8.3 Implementación\nPara iniciar los servicios en segundo plano, use el siguiente comando: $ docker-compose up -d\nVerifique que los servicios se están ejecutando con: $ docker-compose ps\nCompruebe si los registros del sistema muestran algún error: $ docker-compose logs\nMientras no veas una secuencia de mensajes de error en los registros, deberías poder acceder al sitio web en la dirección IP del servidor (por ejemplo, en http://192.0.2.10)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "href": "deploying_docker_compose.html#limitaciones-de-implementación-en-un-solo-host",
    "title": "8  Desplegar aplicaciones con Docker Compose.",
    "section": "8.4 Limitaciones de implementación en un solo host",
    "text": "8.4 Limitaciones de implementación en un solo host\nSi el contenedor del servidor de base de datos o el contenedor del servicio web fallan y no se pueden reiniciar automáticamente, el sitio no funcionará y será necesaria una intervención manual. La solución puede ser tan simple como conectarse por SSH y reiniciar el servidor. Pero, a veces, un solo servidor tendrá tan poca memoria que deberá reiniciarse manualmente desde una consola de nivel superior o incluso apagar y encender manualmente.\nDependiendo de su proveedor de alojamiento, el sistema operativo base con el que comience y cómo estén configurados los contenedores Docker, puede experimentar inestabilidad que sea difícil de rastrear. Tal vez su host se reinicie con frecuencia debido a que la red del proveedor detecta hardware inestable o condiciones de red inestables. Tal vez haya configurado su sistema operativo para instalar actualizaciones automáticas y aplicarlas provoque períodos de interrupciones. Tal vez la aplicación crezca en la memoria hasta que provoque una falla de algún tipo.\nSi ha alojado su aplicación en un único servidor físico o virtual, debe asegurarse de realizar copias de seguridad del sistema con regularidad, la pérdida del host podría provocar que se pierda toda la información.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Desplegar aplicaciones con Docker Compose.</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html",
    "href": "sharing_containers_used_docker_hub.html",
    "title": "9  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "9.1 ¿Qué es Docker Hub?\nDocker Hub es una plataforma centralizada que permite a los desarrolladores almacenar, compartir y gestionar imágenes de contenedores. Es el repositorio oficial de Docker, donde se pueden encontrar imágenes públicas y privadas, facilitando la colaboración y la reutilización de contenedores en diferentes entornos.\nDocker Hub es un servicio basado en la nube que proporciona un registro de imágenes de Docker. Permite a los desarrolladores:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#qué-es-docker-hub",
    "title": "9  Compartir Contenedores Usando Docker Hub",
    "section": "",
    "text": "Almacenar Imágenes: Guardar imágenes de contenedores en un lugar centralizado.\nCompartir Imágenes: Hacer que las imágenes estén disponibles para otros desarrolladores.\nAutomatizar Builds: Configurar pipelines de CI/CD para construir y desplegar imágenes automáticamente.\nGestionar Repositorios: Organizar imágenes en repositorios públicos o privados.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#beneficios-de-usar-docker-hub",
    "title": "9  Compartir Contenedores Usando Docker Hub",
    "section": "9.2 Beneficios de Usar Docker Hub",
    "text": "9.2 Beneficios de Usar Docker Hub\n\nColaboración: Facilita el trabajo en equipo al permitir compartir imágenes de contenedores fácilmente.\nReutilización: Permite reutilizar imágenes existentes, ahorrando tiempo y esfuerzo en la configuración de entornos.\nDistribución: Facilita la distribución de aplicaciones y servicios en diferentes entornos y plataformas.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "href": "sharing_containers_used_docker_hub.html#pasos-para-compartir-contenedores-en-docker-hub",
    "title": "9  Compartir Contenedores Usando Docker Hub",
    "section": "9.3 Pasos para Compartir Contenedores en Docker Hub",
    "text": "9.3 Pasos para Compartir Contenedores en Docker Hub\n\nCrear una Cuenta en Docker Hub: Regístrate en Docker Hub para crear una cuenta gratuita.\nIniciar Sesión desde la Línea de Comandos: Usa el comando docker login para iniciar sesión en Docker Hub desde tu terminal.\nConstruir una Imagen de Docker: Crea una imagen de Docker usando un Dockerfile y el comando docker build.\nEtiquetar la Imagen: Etiqueta la imagen con tu nombre de usuario de Docker Hub y el nombre del repositorio.\nSubir la Imagen a Docker Hub: Usa el comando docker push para subir la imagen etiquetada a Docker Hub.\nCompartir la Imagen: Comparte el enlace del repositorio de Docker Hub con otros desarrolladores para que puedan descargar y usar la imagen.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "href": "sharing_containers_used_docker_hub.html#ejemplo-práctico",
    "title": "9  Compartir Contenedores Usando Docker Hub",
    "section": "9.4 Ejemplo Práctico",
    "text": "9.4 Ejemplo Práctico\nA continuación, se muestra un ejemplo práctico de cómo compartir una imagen de contenedores en Docker Hub:\n\nConstruir la Imagen: sh docker build -t myapp:late  st .\nEtiquetar la Imagen: sh docker tag myapp:latest your-dockerhub-username/myapp:latest\nIniciar Sesión en Docker Hub: sh docker login\nSubir la Imagen: sh docker push your-dockerhub-username/myapp:latest\nCompartir el Enlace: Comparte el enlace https://hub.docker.com/r/your-dockerhub-username/myapp con otros desarrolladores.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  },
  {
    "objectID": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "href": "sharing_containers_used_docker_hub.html#consideraciones-de-seguridad",
    "title": "9  Compartir Contenedores Usando Docker Hub",
    "section": "9.5 Consideraciones de Seguridad",
    "text": "9.5 Consideraciones de Seguridad\n\nImágenes Privadas: Si no deseas que tus imágenes sean públicas, puedes configurar repositorios privados en Docker Hub.\nAutenticación: Asegúrate de usar autenticación segura y gestionar tus credenciales de Docker Hub de manera adecuada.\nActualizaciones: Mantén tus imágenes actualizadas para incluir las últimas mejoras y parches de seguridad.\n\nAl finalizar este capítulo, tendrás las habilidades necesarias para compartir tus contenedores con otros desarrolladores y utilizar imágenes de contenedores de la comunidad, mejorando así tu flujo de trabajo y la colaboración en proyectos.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Compartir Contenedores Usando Docker Hub</span>"
    ]
  }
]